{
  "/docs/agents/ruby-agent/api-guides/ruby-custom-metrics": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-07T14:44:58Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.17075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-07T06:24:01Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.35512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-07T17:20:39Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.69047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-07T14:44:58Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.17075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-07T06:24:01Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.35512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.79245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/third-party-instrumentation": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-07T14:44:58Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.170746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-07T06:24:01Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.35512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-07T17:20:39Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.69047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.50887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-07T05:34:40Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.7627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-07T11:39:29Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.57816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-agent-attributes": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.50885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-07T05:34:40Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.76266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby attribute examples",
        "Contents",
        "Capture request parameters",
        "Exclude sensitive data while capturing request parameters",
        "Capture only specific request parameters",
        "Capture Resque job arguments",
        "Capture Sidekiq job arguments",
        "Disabling all attributes",
        "Selecting specific destinations",
        "Selecting values and destinations",
        "For more help"
      ],
      "title": "Ruby attribute examples",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "040a2acaf99cfce727dfe88e69dc0511fbe16d48",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-attribute-examples/",
      "published_at": "2021-10-07T11:42:25Z",
      "updated_at": "2021-03-11T10:09:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some examples of using attributes with the New Relic Ruby agent. Contents Capture request parameters Capturing request parameters is not enabled by default. The following configuration will turn on parameter capture for the default destinations: transaction_tracer, transaction_events, and error_collector. To limit the destinations see the Selecting specific destinations example. Configuration: attributes.include: request.parameters.* Copy Request parameters are prefixed with the string request.parameters, and nested parameters have keys to reflect that nesting. For example, a user with a location attribute nested below a profile would have a key ofrequest.parameters.user.profile.location. Similarly, attributes that are members of collections will have keys with indices that reflect the membership. If a user had multiple phone numbers, keys would appear as follows: request.parameters.phone_numbers.0, request.parameters.phone_numbers.1, etc. Exclude sensitive data while capturing request parameters There may be situations where you would like to omit sensitive information from request parameters, such as passwords or credit card numbers. The following configuration will accomplish that: Configuration: attributes.include: request.parameters.* attributes.exclude: [request.parameters.password, request.parameters.credit_card_no] Copy Capture only specific request parameters To capture only specific request parameters, you can simply pass a list to attributes.include: Configuration: attributes.include: [request.parameters.user_id, request.parameters.shard_id] Copy Capture Resque job arguments By default Resque job arguments are not captured. To enable this functionality use the configuration below. attributes.include: job.resque.args.* Copy Note: Arguments to Resque jobs are positional and the keys generated reflect this. For example a job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1 Capture Sidekiq job arguments By default Sidekiq job arguments are not captured. To enable this functionality use the configuration below. attributes.include: job.sidekiq.args.* Copy Note: Arguments to Sidekiq jobs are positional and the keys generated reflect this. For example a job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1 Disabling all attributes In this example, attributes are disabled, so the include and exclude lists will be ignored and all attributes will be filtered out. Configuration: attributes.enabled: false attributes.include: request.parameters.* Copy Input keys: foo, bar, request.parameters.foo, request.parameters.bar Copy Output for destinations: transaction_tracer: none error_collector: none transaction_events: none browser_monitoring: none Copy Selecting specific destinations In this example: Attributes are disabled for transaction traces. The include and exclude lists will be ignored, and all attributes will be filtered out for this destination. Attributes are also disabled for browser monitoring by default. Request parameters (prefixed with request.parameters.) are off by default for all destinations. As a result, only bar is sent in traced errors and transaction events. Configuration: attributes.enabled: true transaction_tracer.attributes.enabled: false attributes.exclude: foo Copy Input keys: foo, bar, request.parameters.foo, request.parameters.bar Copy Output for destinations: transaction_tracer: none error_collector: bar transaction_events: bar browser_monitoring: none Copy Selecting values and destinations In this example, specific input keys are selected for certain output destinations and excluded from others. The lang.oo.python key will be excluded only from transaction traces. The lang and lang.functional keys will be excluded from all destinations. Configuration: browser_monitoring.attributes.enabled: true attributes.exclude: lang* attributes.include: lang.oo.* transaction_tracer.attributes.exclude: lang.oo.python Copy Input keys: lang, lang.functional, lang.oo.ruby, lang.oo.python Copy Output for destinations: transaction_tracer: lang.oo.ruby error_collector: lang.oo.ruby, lang.oo.python transaction_events: lang.oo.ruby, lang.oo.python browser_monitoring: lang.oo.ruby, lang.oo.python Copy For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Ruby agent attributes (Ruby-specific attributes available as of version 3.12.0) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Collect custom attributes (enabling custom attributes by agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.05324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>attribute</em> examples",
        "sections": "<em>Ruby</em> <em>attribute</em> examples",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " browser_monitoring: lang.oo.<em>ruby</em>, lang.oo.python Copy For more help Additional documentation resources include: <em>Agent</em> <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) <em>Ruby</em> <em>agent</em> <em>attributes</em> (<em>Ruby</em>-specific <em>attributes</em> available as of version 3.12.0) Enabling"
      },
      "id": "6044041f28ccbc3e672c60be"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-attribute-examples": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.50885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-07T05:34:40Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.76266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-07T11:39:29Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.57816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/delayedjob-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-07T16:45:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.52011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-07T12:36:04Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.52553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes": [
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-07T16:45:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.52011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-07T12:36:04Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.52553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-07T12:50:07Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.15894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/rake-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-07T16:45:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.52011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-07T12:36:04Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.52553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/resque-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-07T16:45:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.52011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-07T12:50:07Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.15894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-07T12:36:04Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.52553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-10-07T12:50:07Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.15894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/configuration/connect-hosts-your-account": [
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-07T05:34:40Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.22278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.39334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.1927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    }
  ],
  "/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby": [
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-07T05:34:40Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.22278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.39334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.1927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    }
  ],
  "/docs/agents/ruby-agent/configuration/ruby-agent-configuration": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.39331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.19269,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.92592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " tracing, you will need to update your <em>configuration</em>. Manual Rack instrumentation Earlier versions of the <em>Ruby</em> <em>agent</em> supported manually instrumenting Rack middlewares via the NewRelic::<em>Agent</em>::Instrumentation::Rack module. This instrumentation is deprecated in <em>Ruby</em> <em>agent</em> versions 3.9.0 or higher"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    }
  ],
  "/docs/agents/ruby-agent/features/cross-application-tracing-ruby": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93367,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.51669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/developer-mode": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38342,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/garbage-collection": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38342,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/http-client-tracing-ruby": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.51667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/message-queues": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93361,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93361,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/record-deployments-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.51666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/ruby-vm-measurements": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.93358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.38336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-07T14:28:04Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.14738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/metal-controller-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/mongo-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.5572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/rack-metal-support": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/sequel-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/apm-agent-security-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.75403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-07T13:35:59Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.35666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-07T08:52:06Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.30466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby": [
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-07T13:35:59Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.35663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-07T08:52:06Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.30464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-07T05:34:39Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.807625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-7x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-07T13:35:59Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.35663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-07T08:52:06Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.30464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-8x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.75397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-07T08:52:06Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.30463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-07T05:34:39Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.80762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/new-relics-github-repository": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.75397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-07T13:35:59Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.3566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-07T08:52:06Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.30463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.75394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-07T13:35:59Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.35657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-07T05:34:39Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.80762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/index": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.79501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-07T11:44:09Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.8101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.65674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent-gae-flexible-environment": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.25203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.458084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.1199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.25203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.458084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.1199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-heroku": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.25203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.458084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.1199,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.45805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.11988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-10-07T13:40:51Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.04672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    }
  ],
  "/docs/agents/ruby-agent/installation/uninstall-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.45805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.11988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/update-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.25197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-07T12:36:29Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.45804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.11986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/rack-middlewares": [
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.5572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.48602,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-07T00:30:11Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.42873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-07T12:37:17Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.6252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-07T13:38:56Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.5572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/control-when-ruby-agent-starts": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/generating-logs-troubleshooting-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.342865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/incompatible-gems": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.342865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-appears-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.478004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-unicorn": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.478004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-log-file-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/not-installing-new-relic-supported-grape": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.342834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/passenger-troubleshooting": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44136,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.342834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/ruby-agent-audit-log": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.44134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/systemstackerror-stack-level-too-deep": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.477905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.441315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-deprecated-api-calls": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.441284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-private-api-calls-public-tracer-api": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-07T13:17:45Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.47788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-07T05:35:59Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.441284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-07T12:50:52Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.34281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Troubleshooting</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.68073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident <em>Intelligence</em> Before setting up Incident <em>Intelligence</em>, note"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "image": "https://docs.newrelic.com/static/82d53ad1a17b876fc5a92f51e5c01a54/ae694/whats_up_accelerated_decisions.png",
      "url": "https://docs.newrelic.com/whats-new/2020/10/applied-intelligence-now-features-accelerated-suggested-decisions/",
      "sections": [
        "Applied Intelligence now features accelerated suggested decisions"
      ],
      "published_at": "2021-10-08T11:34:26Z",
      "title": "Applied Intelligence now features accelerated suggested decisions",
      "updated_at": "2021-03-11T00:20:00Z",
      "type": "docs",
      "external_id": "3366f3f7d7258c27c856967f1a8d2a90c00f2342",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Incident Intelligence continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested correlation decisions that merge incidents to reduce alert noise further. Suggested decisions use machine learning to tailor correlations based on your data. Usually, we can create suggestions after a few weeks of use and data ingestion. However, if you’re an existing New Relic user, we can now leverage your historical New Relic Alerts data to bring you tailored suggested decision logic in a matter of days. You won’t need to perform any additional configuration—choose the alert policies you want to feed in for correlation as usual, and we’ll take care of the rest. The more policies you add, and the more data we have access to, the better suggestions you’ll receive. Be sure to set up your New Relic alerts source to take advantage of this new capability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.382034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "sections": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "body": "Incident <em>Intelligence</em> continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested <em>correlation</em> <em>decisions</em> that merge incidents to reduce alert noise further. Suggested <em>decisions</em> use machine learning to tailor correlations based on your data. Usually, we can"
      },
      "id": "60446abe196a672c4c960f90"
    },
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-07T13:22:18Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.39901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Query for when <em>application</em> traffic drops",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": " a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = &#x27;{{entity.name}}&#x27; since 1 hour ago. Copy Full variables list by category We&#x27;ll be updating this table frequently as we make updates to <em>Applied</em> <em>Intelligence</em>. Key Name Display Name alert&#x2F;account_id"
      },
      "id": "603e7a6528ccbcad47eba77f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.78778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.19617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-07T15:46:39Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.03262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.19617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-07T15:46:39Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.03262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.96436,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.78757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.19617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.96434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.78757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.19617,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-07T15:46:39Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.03262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.78748,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-07T15:46:39Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.03262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.96432,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Incident workflows",
        "BETA FEATURE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-07T09:54:04Z",
      "updated_at": "2021-09-14T11:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.10873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " The <em>Workflows</em> feature is located under the <em>Alerts</em> &amp; AI menu. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI, in the left navigation under Enrich and Respond click <em>Workflow</em>, then click Add a <em>workflow</em>. Tip The maximum <em>workflows</em> you can add per environment is 1000 Name your <em>workflow</em>. This field is mandatory and needs"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.70981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.12637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the <em>alert</em>. Allowable content for the metric field depends on the type value chosen. There are two product categories : <em>Alerts</em> conditions"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-07T13:22:18Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 295.89822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "BETA FEATURE This feature is currently in beta. With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.70975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.12624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the <em>alert</em>. Allowable content for the metric field depends on the type value chosen. There are two product categories : <em>Alerts</em> conditions"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-07T01:26:55Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.41293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " cost. When an anomaly is detected, you can view it in the <em>Applied</em> <em>Intelligence</em> anomalies feed, or we&#x27;ll send notifications directly to your Slack channel or a webhook. How it works <em>Proactive</em> <em>Detection</em> uses the following methods to <em>detect</em> anomalies in your app data: <em>Proactive</em> <em>Detection</em> monitors metric"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.63763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.07726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Expanded anomaly detection",
        "Important",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-10-07T05:14:04Z",
      "updated_at": "2021-09-14T10:33:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This feature is a limited release. We’ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what you’ll want to be notified about ahead of time. Anomaly detection helps you distinguish between what’s typical performance in your system and where you’re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities you’d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as they’re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection won’t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If you’re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If it’s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.7139,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Get started with anomaly <em>detection</em> To get started with expanded anomaly <em>detection</em>: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em> &gt; Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload"
      },
      "id": "60b5124064441ff965e2cb01"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.63763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-07T02:47:36Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.07726,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1696.782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the <em>alert</em>. Allowable content for the metric field depends on the type value chosen. There are two product categories : <em>Alerts</em> conditions"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1692.1472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1610.0641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our REST API (v2) allows you to configure settings for <em>alerts</em>. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/alert-custom-violation-descriptions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.41055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.67276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.1055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.0592,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96664,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.41022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.9665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.41006,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/select-product-targets-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.0437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> activity: Events, violations, <em>incidents</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04358,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.0433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/apm-metric-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.9651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.49086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.78232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10373,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "Violation event attributes",
        "What is a violation event?",
        "Important",
        "BETA FEATURE"
      ],
      "title": "Violation event attributes",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "4c7da02e30f309b8bc6ac1bc3c49d3b610f3d9eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes/",
      "published_at": "2021-10-07T07:07:12Z",
      "updated_at": "2021-10-07T07:07:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see Alerts concepts. What is a violation event? The violation of a condition generates a violation event. This event has various attributes (metadata) attached to it and different attributes can be used by different features. Important The violation event is a concept used to determine alerting features. While you can query some of its associated attributes via NerdGraph, you cannot directly query the violation event. Violation event attributes This table shows violation event attributes. The violation event data type is collected in NrAiIncident. BETA FEATURE NrAiIncident is still in development, so may be subject to unannounced changes, but we encourage you to try it out! You may be wondering why we're using NrAiIncident as the name for the violation event data type. Although we currently refer to these events as \"violations,\" they'll be called \"incidents\" in our new, upcoming naming scheme. This name prepares for and reflects our future intentions. All attributes are available for use in a description. Read about attributes available for muting rules. Attribute Description accountId The ID of the account where the violation occurred. Available for muting rules. aggregationDuration The active condition's aggregation window. closeCause If applicable, what caused the incident to close. Available values: CONDITION_DELETED, POLICY_DELETED, EVALUATOR, EXPIRED, CONDITION_MODIFIED, LOSS_OF_SIGNAL, USER, TARGET_REMOVED, and CONDITION_DISABLED. closeTime If applicable, the timestamp when the incident was closed. closeViolationsOnExpiration If true, open violations on the signal are closed if the signal is lost. Default is false. To use this field, an expirationDuration must be specified. conditionId The ID of the condition that triggered the violation. Available for muting rules. conditionName The name of the condition that triggered the violation. Available for muting rules. degradationTime The timestamp when the targeted metric started to breach the active condition’s threshold. description The contents of the active condition’s Violation Description field. NRQL or Infrastructure conditions only. entity.guid The targeted entity's globally unique identifier, if available. entity.name The targeted entity's name, if available. entity.type The targeted entity's type, if available. evaluationOffsetSeconds The active condition's evaluation offset. A time delay (in seconds) to ensure data points are placed in the correct aggregation window. If you use the Delay/timer setting in the UI, it clears evaluationOffsetSeconds and uses Delay/timer instead. evaluationType The reason the violation was opened. Available values: Threshold (the condition threshold was breached) Expiration (the entity's signal was lost) event The record's event type. Available values: Open and Close. expirationDuration The active condition's signal loss time window. incidentID The unique identifier of the violation. muted Shows whether the active condition was muted at the time of the violation event. mutingRuleID The unqiue identifier of the muting rule that caused the violation to be muted. nrqlEventType The type of data targeted by a NRQL condition. In this context, this refers to any NRQL-queryable data type. Available for muting rules. nrqlQuery The full string of the NRQL query. Can be used for sub-string matching on attributes in the WHERE clause. Available for muting rules. openTime The timestamp when the violation was opened. operator The violation threshold's operator, such as =, <, or >. For signal loss violations, this is an empty string. policyId The ID of the policy that triggered the violation. Available for muting rules. policyName The name of the policy that triggered the violation. Available for muting rules. priority The level of the violation: warning or critical. recoveryTime The timestamp when the active condition's targeted metric stops breaching the threshold. runbookUrl The runbook URL for the condition that triggered the violation. Available for muting rules. tags.* Arbitrary key-value metadata, or tags, associated with the violation. tags. is the prefix and * is the metadata/tag name. For details on how to use this, see the documentation for muting rules or description. Available for muting rules. targetName The name of the violation’s target. This can be an entity or a query. Available for muting rules. threshold The active condition's threshold value. thresholdDuration The active condition's threshold time window. thresholdOccurrences Shows whether for at least or at least once in occurrence values are being used in the active condition's threshold. Available values: all or any. timestamp The event's wall clock time using an epoch timestamp. title The incident's title. type The incident's type. Available value: Incident. valueFunction The active condition's aggregation function. Used in APM, browser, and mobile alert condition types. violationTimeLimitSeconds The active condition's violation time limit setting. violationUuId Deprecated. Do not use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.94131,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see <em>Alerts</em> concepts. What is a violation event? The violation of a condition generates a violation event. This event has various"
      },
      "id": "6130c05428ccbc6d0d56a834"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.57422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.78217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.57404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.78198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.57382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "Violation event attributes",
        "What is a violation event?",
        "Important",
        "BETA FEATURE"
      ],
      "title": "Violation event attributes",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "4c7da02e30f309b8bc6ac1bc3c49d3b610f3d9eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes/",
      "published_at": "2021-10-07T07:07:12Z",
      "updated_at": "2021-10-07T07:07:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see Alerts concepts. What is a violation event? The violation of a condition generates a violation event. This event has various attributes (metadata) attached to it and different attributes can be used by different features. Important The violation event is a concept used to determine alerting features. While you can query some of its associated attributes via NerdGraph, you cannot directly query the violation event. Violation event attributes This table shows violation event attributes. The violation event data type is collected in NrAiIncident. BETA FEATURE NrAiIncident is still in development, so may be subject to unannounced changes, but we encourage you to try it out! You may be wondering why we're using NrAiIncident as the name for the violation event data type. Although we currently refer to these events as \"violations,\" they'll be called \"incidents\" in our new, upcoming naming scheme. This name prepares for and reflects our future intentions. All attributes are available for use in a description. Read about attributes available for muting rules. Attribute Description accountId The ID of the account where the violation occurred. Available for muting rules. aggregationDuration The active condition's aggregation window. closeCause If applicable, what caused the incident to close. Available values: CONDITION_DELETED, POLICY_DELETED, EVALUATOR, EXPIRED, CONDITION_MODIFIED, LOSS_OF_SIGNAL, USER, TARGET_REMOVED, and CONDITION_DISABLED. closeTime If applicable, the timestamp when the incident was closed. closeViolationsOnExpiration If true, open violations on the signal are closed if the signal is lost. Default is false. To use this field, an expirationDuration must be specified. conditionId The ID of the condition that triggered the violation. Available for muting rules. conditionName The name of the condition that triggered the violation. Available for muting rules. degradationTime The timestamp when the targeted metric started to breach the active condition’s threshold. description The contents of the active condition’s Violation Description field. NRQL or Infrastructure conditions only. entity.guid The targeted entity's globally unique identifier, if available. entity.name The targeted entity's name, if available. entity.type The targeted entity's type, if available. evaluationOffsetSeconds The active condition's evaluation offset. A time delay (in seconds) to ensure data points are placed in the correct aggregation window. If you use the Delay/timer setting in the UI, it clears evaluationOffsetSeconds and uses Delay/timer instead. evaluationType The reason the violation was opened. Available values: Threshold (the condition threshold was breached) Expiration (the entity's signal was lost) event The record's event type. Available values: Open and Close. expirationDuration The active condition's signal loss time window. incidentID The unique identifier of the violation. muted Shows whether the active condition was muted at the time of the violation event. mutingRuleID The unqiue identifier of the muting rule that caused the violation to be muted. nrqlEventType The type of data targeted by a NRQL condition. In this context, this refers to any NRQL-queryable data type. Available for muting rules. nrqlQuery The full string of the NRQL query. Can be used for sub-string matching on attributes in the WHERE clause. Available for muting rules. openTime The timestamp when the violation was opened. operator The violation threshold's operator, such as =, <, or >. For signal loss violations, this is an empty string. policyId The ID of the policy that triggered the violation. Available for muting rules. policyName The name of the policy that triggered the violation. Available for muting rules. priority The level of the violation: warning or critical. recoveryTime The timestamp when the active condition's targeted metric stops breaching the threshold. runbookUrl The runbook URL for the condition that triggered the violation. Available for muting rules. tags.* Arbitrary key-value metadata, or tags, associated with the violation. tags. is the prefix and * is the metadata/tag name. For details on how to use this, see the documentation for muting rules or description. Available for muting rules. targetName The name of the violation’s target. This can be an entity or a query. Available for muting rules. threshold The active condition's threshold value. thresholdDuration The active condition's threshold time window. thresholdOccurrences Shows whether for at least or at least once in occurrence values are being used in the active condition's threshold. Available values: all or any. timestamp The event's wall clock time using an epoch timestamp. title The incident's title. type The incident's type. Available value: Incident. valueFunction The active condition's aggregation function. Used in APM, browser, and mobile alert condition types. violationTimeLimitSeconds The active condition's violation time limit setting. violationUuId Deprecated. Do not use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.94101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see <em>Alerts</em> concepts. What is a violation event? The violation of a condition generates a violation event. This event has various"
      },
      "id": "6130c05428ccbc6d0d56a834"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.17189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/tag-information-not-showing-entity-infra-alert-condition": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04227,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 204.17178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "Nested aggregation NRQL <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/provide-runbook-instructions-alert-activity": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.9641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.4901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.67018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.0571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "REST API calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; <em>GET</em> &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Violation event attributes",
        "What is a violation event?",
        "Important",
        "BETA FEATURE"
      ],
      "title": "Violation event attributes",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "4c7da02e30f309b8bc6ac1bc3c49d3b610f3d9eb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes/",
      "published_at": "2021-10-07T07:07:12Z",
      "updated_at": "2021-10-07T07:07:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see Alerts concepts. What is a violation event? The violation of a condition generates a violation event. This event has various attributes (metadata) attached to it and different attributes can be used by different features. Important The violation event is a concept used to determine alerting features. While you can query some of its associated attributes via NerdGraph, you cannot directly query the violation event. Violation event attributes This table shows violation event attributes. The violation event data type is collected in NrAiIncident. BETA FEATURE NrAiIncident is still in development, so may be subject to unannounced changes, but we encourage you to try it out! You may be wondering why we're using NrAiIncident as the name for the violation event data type. Although we currently refer to these events as \"violations,\" they'll be called \"incidents\" in our new, upcoming naming scheme. This name prepares for and reflects our future intentions. All attributes are available for use in a description. Read about attributes available for muting rules. Attribute Description accountId The ID of the account where the violation occurred. Available for muting rules. aggregationDuration The active condition's aggregation window. closeCause If applicable, what caused the incident to close. Available values: CONDITION_DELETED, POLICY_DELETED, EVALUATOR, EXPIRED, CONDITION_MODIFIED, LOSS_OF_SIGNAL, USER, TARGET_REMOVED, and CONDITION_DISABLED. closeTime If applicable, the timestamp when the incident was closed. closeViolationsOnExpiration If true, open violations on the signal are closed if the signal is lost. Default is false. To use this field, an expirationDuration must be specified. conditionId The ID of the condition that triggered the violation. Available for muting rules. conditionName The name of the condition that triggered the violation. Available for muting rules. degradationTime The timestamp when the targeted metric started to breach the active condition’s threshold. description The contents of the active condition’s Violation Description field. NRQL or Infrastructure conditions only. entity.guid The targeted entity's globally unique identifier, if available. entity.name The targeted entity's name, if available. entity.type The targeted entity's type, if available. evaluationOffsetSeconds The active condition's evaluation offset. A time delay (in seconds) to ensure data points are placed in the correct aggregation window. If you use the Delay/timer setting in the UI, it clears evaluationOffsetSeconds and uses Delay/timer instead. evaluationType The reason the violation was opened. Available values: Threshold (the condition threshold was breached) Expiration (the entity's signal was lost) event The record's event type. Available values: Open and Close. expirationDuration The active condition's signal loss time window. incidentID The unique identifier of the violation. muted Shows whether the active condition was muted at the time of the violation event. mutingRuleID The unqiue identifier of the muting rule that caused the violation to be muted. nrqlEventType The type of data targeted by a NRQL condition. In this context, this refers to any NRQL-queryable data type. Available for muting rules. nrqlQuery The full string of the NRQL query. Can be used for sub-string matching on attributes in the WHERE clause. Available for muting rules. openTime The timestamp when the violation was opened. operator The violation threshold's operator, such as =, <, or >. For signal loss violations, this is an empty string. policyId The ID of the policy that triggered the violation. Available for muting rules. policyName The name of the policy that triggered the violation. Available for muting rules. priority The level of the violation: warning or critical. recoveryTime The timestamp when the active condition's targeted metric stops breaching the threshold. runbookUrl The runbook URL for the condition that triggered the violation. Available for muting rules. tags.* Arbitrary key-value metadata, or tags, associated with the violation. tags. is the prefix and * is the metadata/tag name. For details on how to use this, see the documentation for muting rules or description. Available for muting rules. targetName The name of the violation’s target. This can be an entity or a query. Available for muting rules. threshold The active condition's threshold value. thresholdDuration The active condition's threshold time window. thresholdOccurrences Shows whether for at least or at least once in occurrence values are being used in the active condition's threshold. Available values: all or any. timestamp The event's wall clock time using an epoch timestamp. title The incident's title. type The incident's type. Available value: Incident. valueFunction The active condition's aggregation function. Used in APM, browser, and mobile alert condition types. violationTimeLimitSeconds The active condition's violation time limit setting. violationUuId Deprecated. Do not use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.9407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The violation of a condition generates a violation event, which passes important information downstream. For more about the definition of violations and other terms, see <em>Alerts</em> concepts. What is a violation event? The violation of a condition generates a violation event. This event has various"
      },
      "id": "6130c05428ccbc6d0d56a834"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.9638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.48984,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.4653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for <em>violations</em> based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.01877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> activity: Events, <em>violations</em>, incidents",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "&quot;: { &quot;expiration_duration&quot;: &quot;string&quot;, &quot;open_violation_on_expiration&quot;: boolean, &quot;close_<em>violations</em>_on_expiration&quot;: boolean } } }&#x27; Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, <em>New</em> <em>Relic</em> evaluates the following query against the terms[threshold] value once per"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "NRQL conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert condition types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window duration",
        "Delay/timer",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-07T00:35:22Z",
      "updated_at": "2021-10-07T00:35:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier condition types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL conditions produce a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL conditions, the equivalent property of a signal is the aggregation duration window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple aggregation functions Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL conditions. These queries will work for static and baseline condition types. The outlier condition type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy NRQL conditions and query order of operations By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition types NRQL condition types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 15 seconds to 15 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods. For the cadence aggregation method, the implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your delay/timer setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert condition types When you create a NRQL alert, you can choose from different types of conditions: NRQL alert condition types Description Static This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) condition types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, use the advanced signal settings to control streaming alert data and avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window duration Delay/timer Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window duration You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 15 seconds and 15 minutes, in 15-second increments. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Delay/timer You can adjust the delay/timer to coordinate our streaming alerting algorithm with your data's behavior. If it takes your data is sparse or inconsistent, you may want to use the event timer aggregation method. For the cadence method, the total supported latency is the product of the aggregation window duration added to the delay/timer. If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using the event flow method with the default settings. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you use the event timer method. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.96368,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "Create NRQL <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> <em>conditions</em>. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.4068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.48972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions": [
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 265.40665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL <em>conditions</em> to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.4896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> entity <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create <em>conditions</em> for policies To add <em>conditions</em> to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.00528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> <em>conditions</em> API field names",
        "sections": "<em>Alerts</em> <em>conditions</em> API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create <em>conditions</em> for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> <em>conditions</em>: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46506,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> activity: Events, violations, <em>incidents</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.04135,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.46492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.25607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "<em>Alert</em> activity: Events, violations, <em>incidents</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/delete-alert-notification-channels": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.6694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.1022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.05646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.66928,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.05637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/notification-channels-control-where-send-alerts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.66928,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.05637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/test-alert-notification-channels": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_delay",
        "aggregation_method",
        "aggregation_timer",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "signal[aggregation_window]",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-08T11:29:05Z",
      "updated_at": "2021-10-08T11:29:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of New Relic Alerts conditions: APM External services NRQL Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. Used for: NRQL conditions aggregation_method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics). CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer value. The timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. Used for: NRQL conditions aggregation_timer The length of time in seconds to wait after each data point is received, to ensure the entire batch is processed. Required when using the EVENT_TIMER aggregation_method type. Used for: NRQL conditions aggregation_window Streaming alerts gather data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based on their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is false. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects that will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma-separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset Deprecated in favor of aggregation_delay. The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 2 minutes. Used with event flow and cadence aggregation methods. signal[aggregation_window] One of three data aggregation methods: event flow, event timer, and cadence. The default is Event flow. signal[aggregation_window] The amount of time before aggregated data is evaluated. Default is 1 minute. Used with Event timer aggregation method. signal[aggregation_window] The duration in which data is collected together before being evaluated. Default is 1 minute. terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.66916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions API field names",
        "sections": "<em>Alerts</em> conditions API field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes five types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Streaming alerts: key terms and concepts",
        "Why it matters",
        "Streaming alerts process and descriptions",
        "Choose your aggregation method",
        "Event flow detail",
        "Event timer detail",
        "Cadence",
        "Streaming alerts tools",
        "Tip",
        "Window duration",
        "Delay/timer",
        "Loss of signal detection",
        "Gap filling"
      ],
      "title": "Streaming alerts: key terms and concepts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "144c7f0721ec2acb1e8ac8aa06142911ea552aef",
      "image": "https://docs.newrelic.com/static/39158bd84483adf9516bb7ff5058c9bd/d30ee/streaming-alerts.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/",
      "published_at": "2021-10-08T10:15:12Z",
      "updated_at": "2021-10-08T10:15:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The streaming alerts platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into New Relic. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the streaming algorithm. There are three methods for aggregating the data filtered through your NRQL condition: Event flow (default) Event timer Cadence Why it matters Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you. Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see Streaming alerts process and descriptions. As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the NRQL query's WHERE clause. Instead of evaluating that data immediately for violations, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated. Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then evaluates the data point using the NRQL condition in order to determine whether it meets the violation threshold criteria. Even if a data point meets the criteria for a violation, a violation may not be triggered. A violation is only triggered when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points are in violation for an entire threshold duration, we'll send you a notification based on your policy settings. All of these configurable delays give you more control over how you're alerted on sporadic and missing data. Streaming alerts process and descriptions Process Description Streaming data All data coming into New Relic. WHERE clause Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter. Aggregation methods One of three methods that control how data is collected before it's evaluated. They are: Event flow (Default) Event timer Cadence Aggregation window Data with timestamps that fall within this window will be aggregated and then evaluated. Delay/timer A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs. Aggregated data Data in the aggregated window is collapsed to a single data point for alert evaluation. Evaluation The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point. Threshold duration A specific duration that determines if a violation is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, a violation occurs. When a data point lacks data, a custom value is inserted to fill the gap. Choose your aggregation method You can choose between three different aggregation methods, depending on your needs. Event flow (default) works best for data that comes in frequently and mostly in order. Event timer works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs. Cadence is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps. Event flow detail Event flow starts aggregating data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time. For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated. Event timer detail Like event flow, event timer only starts aggregating data when data arrives. When a data point arrives, a timer starts to count down. If no data arrives before the timer counts down, the data is evaluated. When a data point arrives before the timer has completed counting down, the timer is reset. For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later. If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0. If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point. For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly. Cadence We recommend you use one of the other two methods. Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive. Streaming alerts tools Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. They are: Window duration Delay/timer Loss of signal detection Gap filling Tip This article covers these tools at a conceptual level. You'll find direct instructions on how to use these tools in Create NRQL alert conditions. Window duration In order to make loss of signal detection more effective and to reduce unnecessary notifications, you can customize aggregation windows to the duration that you need. An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window. You can set your aggregation window to anything between 15 seconds and 15 minutes, in 15-second increments. The default is 1 minute. Delay/timer The delay/timer setting controls how long the condition should wait before aggregating the data in the aggregation window. The event flow and cadence methods use delay. Event timer uses timer. The delay default is 2 minutes. The timer default is 1 minute and has a minimum value of 5 seconds. Loss of signal detection Loss of signal occurs when no data matches the NRQL condition over a specific period of time. A loss of signal is caused by different things. The WHERE clause in your NRQL query can filter out data before it's evaluated for violations. It could also mean a service or entity is offline or a periodic job has failed to run and no data is being sent to New Relic. In order to avoid unnecessary notifications, you can choose how long to wait before you're notified by a loss of signal violation. You can use loss of signal detection to open violations and be notified when a signal is lost. Alternately, you can use a loss of signal to close violations for ephemeral services or sporadic data, such as error counts. Gap filling Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with None, the last value received, or a static value. The default is None. Gaps in streaming data can be caused by network or host issues, a signal may be sparse, or some signals, such as error counts, may only have data when something is wrong. By filling the gaps with known values, the alert evaluation process can process those gaps and determine how they should affect the loss of signal evaluation. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss and gap filling, see this Explorers Hub post.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.10193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "sections": "Streaming <em>alerts</em>: key terms <em>and</em> concepts",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The streaming <em>alerts</em> platform checks for violations based on data that’s present or missing in your stream of data, or signal, coming into <em>New</em> <em>Relic</em>. You can use NRQL conditions to control what part of the signal you want to be notified about. Your NRQL condition filters the data that&#x27;s processed"
      },
      "id": "6130c054e7b9d269edb6f21d"
    },
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-07T10:06:34Z",
      "updated_at": "2021-10-07T10:06:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is streamed, set the aggregation_method to EVENT_FLOW and use the default settings of 1 for aggregation_window and 2 for aggregation_timer. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.05626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>alerts</em>",
        "sections": "Create <em>new</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with plugins from <em>New</em> <em>Relic</em>&#x27;s Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: <em>Alerts</em> Policies &gt; GET &gt; List) The required"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    }
  ]
}