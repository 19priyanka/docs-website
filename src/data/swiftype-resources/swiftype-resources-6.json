{
  "/docs/agents/ruby-agent/api-guides/ruby-custom-metrics": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.24594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-01T12:09:34Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.639206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-01T12:11:13Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.61797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.24591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-01T12:09:34Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.639206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-10-01T08:12:02Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.77113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/third-party-instrumentation": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.24591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-10-01T12:09:34Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.639206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-10-01T12:11:13Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.61797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.68423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.26285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-01T12:12:25Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.57709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-agent-attributes": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.68423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.26285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Agent attributes",
        "Attribute destination flow",
        "Types of attributes",
        "Destinations for attributes",
        "Viewing request attributes",
        "Limits",
        "Agent-specific attributes"
      ],
      "title": "Agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Agent data"
      ],
      "external_id": "088fa6cfe4cd8dd8f6ee9462a0181497904caf42",
      "image": "https://docs.newrelic.com/static/28e38366587e506dc64423df1bff8073/8c557/screen-tx-trace-attributes.png",
      "url": "https://docs.newrelic.com/docs/agents/manage-apm-agents/agent-data/agent-attributes/",
      "published_at": "2021-10-01T15:38:24Z",
      "updated_at": "2021-09-14T09:18:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. You can view these key-value pairs in some places in the UI, or by querying that data using NRQL. New Relic gives users the ability to customize exactly which attributes will be sent to each of these destinations. You can also collect custom attributes to send additional data to New Relic. Attribute destination flow This diagram illustrates how an agent decides to send attributes to each destination. Agent attribute collection: An agent makes three different decisions when sending an attribute to any New Relic destination based on the relevant property settings. Property names and syntax vary by agent. (The properties in this diagram are specific to the PHP agent, but the general flow is the same for all agents. Property names and syntax vary by agent.) Types of attributes Attributes can be collected in a variety of ways: Message property attributes: These are the properties set on a message received from a queue or topic. HTTP request attributes: These are the parameters for an HTTP request. User attributes: These are attributes provided by the user through each agent's API. Agent attributes: These are attributes captured by the agent; for example, httpResponseCode and httpResponseMessage. Destinations for attributes Collected attributes appear in these locations: Collected attributes Location Transaction traces Each minute transaction traces collect data for your slowest individual HTTP requests. These traces will report attributes collected during the transaction. Traced errors If a transaction results in an error, these traced errors will be reported to APM. A traced error will contain attributes collected during the transaction. Transaction events APM transactions will contain attributes collected during the transaction. Insights page views Browser page views will contain attributes collected during the transaction. However, attributes collected at the end of a transaction may not appear on PageView events. This destination is also called browser monitoring. Span events Span events collected for distributed tracing will contain attributes collected during the span. The following agents support the addition of custom user attributes to span events: Java agent 5.13.0 and above Go agent 3.6.0 and above .NET agent 8.25 and above Node agent 6.10.0 and above PHP agent 9.12.0.268 and above Python agent 5.8.0.136 and above Ruby agent 6.8.0 and above Transaction segments Each segment in a transaction trace will contain attributes recorded for that segment. Viewing request attributes Request attributes are associated with specific transaction traces, browser traces, and errors in APM and dashboards. You can see the attributes recorded with a request when viewing the individual trace or error. Custom attributes can be queried via NRQL exactly like any other attribute. APM > (select an app) > Monitoring > Transactions > (select a transaction) > (select a trace): Here is an example from the Ruby agent of the Request attributes and Custom attributes for a transaction trace. Exact attributes depend on your agent and on your attribute configuration. Limits User attributes, request attributes, and message queue parameters are limited by count and size. Parameter Limitations Transaction Limited to 64 user attributes Attribute key Limited to 256 bytes each If the key is more than 256 bytes, then the attribute will not be recorded. Attribute value Limited to 256 bytes each If the value is greater than 256 bytes, then the attribute value will be truncated. Agent-specific attributes Each APM agent collects custom attributes. The supported attributes depend on the specific agent: C SDK Go Java .NET Node.js PHP Python Ruby",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.676315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> <em>attributes</em>",
        "sections": "<em>Agent</em> <em>attributes</em>",
        "tags": "<em>Agents</em>",
        "body": " an attribute to any New Relic destination based on the relevant property settings. Property names and syntax vary by <em>agent</em>. (The properties in this diagram are specific to the PHP <em>agent</em>, but the general flow is the same for all <em>agents</em>. Property names and syntax vary by <em>agent</em>.) Types of <em>attributes</em>"
      },
      "id": "603eb9db28ccbc127aeba79e"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-attribute-examples": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.6842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.26282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> configuration",
        "sections": "<em>Ruby</em> <em>agent</em> configuration",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " the capture_params setting, the <em>Ruby</em> <em>agent</em> will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the <em>attributes</em>.include setting instead. For more information, see the <em>Ruby</em> attribute examples. config_path Type String Default (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-10-01T12:12:25Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.57709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/delayedjob-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-01T12:13:22Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.57376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-01T12:14:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.5435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.14528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Background</em> <em>jobs</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " by the New Relic <em>Ruby</em> <em>agent</em> include: <em>Background</em> <em>jobs</em> Supported Deprecated Delayed_<em>Job</em> 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes": [
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-01T12:14:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.5435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.14526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Background</em> <em>jobs</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " by the New Relic <em>Ruby</em> <em>agent</em> include: <em>Background</em> <em>jobs</em> Supported Deprecated Delayed_<em>Job</em> 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-01T20:57:08Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.64848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/rake-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-01T12:13:22Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.57376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-01T12:14:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.5435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.14526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Background</em> <em>jobs</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " by the New Relic <em>Ruby</em> <em>agent</em> include: <em>Background</em> <em>jobs</em> Supported Deprecated Delayed_<em>Job</em> 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/resque-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-01T12:13:22Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.57376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-10-01T12:14:10Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.5435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.14525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Background</em> <em>jobs</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " by the New Relic <em>Ruby</em> <em>agent</em> include: <em>Background</em> <em>jobs</em> Supported Deprecated Delayed_<em>Job</em> 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-10-01T12:13:22Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.57376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.14525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Background</em> <em>jobs</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " by the New Relic <em>Ruby</em> <em>agent</em> include: <em>Background</em> <em>jobs</em> Supported Deprecated Delayed_<em>Job</em> 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-10-01T20:57:08Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.64848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/configuration/connect-hosts-your-account": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.13544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.08253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    }
  ],
  "/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.1354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-01T03:09:28Z",
      "updated_at": "2021-09-27T15:28:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.23215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>configuration</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "You can configure the New Relic <em>Ruby</em> <em>agent</em> with settings in a <em>configuration</em> file, environment variables, or programmatically with server-side <em>configuration</em>. This document summarizes the <em>configuration</em> options available for the <em>Ruby</em> <em>agent</em>. If the default value for a <em>configuration</em> option is (Dynamic"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.0825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    }
  ],
  "/docs/agents/ruby-agent/configuration/ruby-agent-configuration": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 143.1354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "-check that your <em>Ruby</em> <em>agent</em> <em>configuration</em> file (config&#x2F;newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the <em>Ruby</em> <em>agent</em>&#x27;s plugin folder (vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em>&#x2F;newrelic.yml). Look for new <em>configuration</em> options that are not in your config&#x2F;newrelic.yml file. Update"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.0825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " cross application tracing, such as for a non-standard middleware framework, see the <em>configuration</em> information in this document. Requirements Follow these requirements to use cross application tracing with the <em>Ruby</em> <em>agent</em>: Make sure the requests being instrumented use a supported HTTP client library"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.4133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: <em>Configure</em> logs in context",
        "sections": "<em>Ruby</em>: <em>Configure</em> logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": " distributed tracing. Use <em>Ruby</em> <em>agent</em> version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for <em>Ruby</em>. Standard <em>Ruby</em> on Rails <em>configuration</em> Rails logging is controlled by two components: A logger you can customize by setting"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/features/cross-application-tracing-ruby": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.27127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-01T08:13:24Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.56256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/developer-mode": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.27127,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/garbage-collection": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.27124,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/http-client-tracing-ruby": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-01T08:13:24Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.562546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/message-queues": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/features/record-deployments-ruby-agent": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.27115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Developer mode",
        "Caution",
        "Security considerations",
        "Tip",
        "Installation",
        "Known issues",
        "Requires Rails 2.3 or higher",
        "Incompatible with Pow",
        "Using Developer mode",
        "Troubleshooting",
        "Disappearing requests",
        "Undefined method path for Rack::Request",
        "ActiveRecord reloads"
      ],
      "title": "Developer mode",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "5b907e0c610c1d22da2df34aaa999ab2c4513e96",
      "image": "https://docs.newrelic.com/static/6e3d86f6f17361e63f52edf965fa1afa/91e7e/screen-breakdown-chart.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/developer-mode/",
      "published_at": "2021-10-01T08:13:24Z",
      "updated_at": "2021-09-14T10:20:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Caution Developer mode is deprecated and no longer supported as of Ruby agent version 4.1.0. The New Relic Ruby agent includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made by the controller actions as they are invoked on the Rails instance. The free Developer mode gives you some of the same in-depth transaction visibility you get with New Relic's transaction traces feature. However, it works only in a single Rails instance, and it has much higher overhead than the production version. It is not recommended for use beyond a developer's desktop sandbox. Security considerations The Ruby agent's Developer mode, which is on by default when the RAILS_ENV == \"development\", does not communicate with the New Relic collector in any way. Pie charts are rendered using Google Charts, which involves an HTTP post of aggregate data. Tip The Ruby agent's Production mode, which is on by default when the RAILS_ENV == \"production\" and RAILS_ENV == \"staging\", does communicate with the New Relic site. For more information, see Security. Installation To install Developer mode, install Ruby agent as a plugin or gem. You may also need to set developer_mode to true in your newrelic.yml for the RAILS_ENV in which you are working. Developer mode is on by default only when RAILS_ENV = development. While a newrelic.yml file will be created as part of the installation, it is not necessary to have a valid license key. Known issues Known issues with Developer mode include: Requires Rails 2.3 or higher Developer mode in recent agents only works on Rails 2.3 or higher. It is rack based, and earlier versions of the framework did not incorporate rack. The developer edition installs a middleware in your app that responds to any URL prepended with /newrelic; for example, /newrelic, /newrelic/files/images/foo.png, etc. In some cases the /newrelic URL gets captured by an earlier middleware. In this situation, disable the Developer mode route and include the middleware yourself: At the beginning of the file, in config.ru: require 'newrelic_rpm' require 'new_relic/rack/developer_mode' use NewRelic::Rack::DeveloperMode Copy Incompatible with Pow Developer mode is not supported from Pow, a zero-config Rack server for Mac OS X. Using Developer mode If you run your application on your desktop using thin, WEBrick, or something similar, open the URL /newrelic on your server to see the Developer mode user interface. Caution If you are using Passenger, Unicorn, or other forking application servers on your desktop, you may notice some odd behavior with disappearing data if your application server launches multiple instances. Refer to the Troubleshooting tips, which follow. Developer Mode Breakdown Chart Troubleshooting Troubleshooting tips for Developer mode: Disappearing requests If you have this problem with Unicorn or other multi-worker dispatchers, try limiting the number of workers to 1. Undefined method path for Rack::Request Some users may see an undefined method path for #<Rack::Request>. If you are using Rails version 2.3.2, then you are mostly likely running into a problem with the way the Rack dependency was defined in the Rails package. Either upgrade to 2.3.3 (or higher), or define Rack version 1.0.1 as a dependency in your Gemfile. ActiveRecord reloads Developer mode reloads ActiveRecord method definitions for every reload and reports the time spent defining the methods (such as define_attribute_method). This does not happen in production. To get real results to compare, add the following to the development environment: config.cache_classes = true Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.56252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Caution Developer mode is deprecated and no longer supported as of <em>Ruby</em> <em>agent</em> version 4.1.0. The New Relic <em>Ruby</em> <em>agent</em> includes Developer mode, a built-in UI for examining details about web transactions in your application. With Developer mode, you can examine the library and database calls made"
      },
      "id": "603ebde128ccbc8391eba74a"
    }
  ],
  "/docs/agents/ruby-agent/features/ruby-vm-measurements": [
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.27115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.50577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Cross application tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Important As of version 8.0.0 of the <em>Ruby</em> <em>agent</em>, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Record deployments with the Ruby agent",
        "Assign an application name",
        "Record with the command line",
        "Record with Capistrano 3.x",
        "Record with Capistrano 2.x",
        "If agent was installed with New Relic gem",
        "If agent was installed as Rails plugin",
        "Customize your Capistrano configuration",
        "Override Capistrano settings",
        "Deploy to staging"
      ],
      "title": "Record deployments with the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "06c806cf9f3dc512c45fd672d220702f55a2944c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/record-deployments-ruby-agent/",
      "published_at": "2021-10-01T08:16:11Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the Ruby agent. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your production environment. You can also customize the rails_env variable for other environments, such as staging. Assign an application name To assign an application name: Download the latest version of the Ruby agent. Set the app_name in your newrelic.yml file to a meaningful name. This will assign instances in the given environment the label given by app_name when browsing your data in the New Relic user interface. The deployment upload script will use that label to associate an app with the deployment. Record with the command line If you installed the Ruby agent as a gem, you can record deployments directly by using the newrelic executable: newrelic deployments Copy Depending on your environment, you may need to run: $bundle exec newrelic deployment Copy You can use several optional values with newrelic. The description is short text. deployments [OPTIONS] [description] OPTIONS: -a, --appname=name Set the application name. Default is app_name setting in newrelic.yml -e, --environment=name Override the (RAILS|RUBY)_ENV setting -u, --user=USER Specify the user deploying. -r, --revision=REV Specify the revision being deployed -c, --changes Read in a change log from the standard input -h Print this help Copy When using the -c option, you can pipe the change log into the script. If not piping when using the -c option, select control-D to signify the end of file (EOF). Record with Capistrano 3.x The New Relic Ruby agent contains a Capistrano recipe that can record app deployments. After assigning your app name, edit your Capistrano files to communicate with the agent: At the top of your Capfile, add the following line: require 'new_relic/recipes' Copy In your deploy.rb file, include: after \"deploy:updated\", \"newrelic:notice_deployment\" Copy Record with Capistrano 2.x You can record Capistrano 2.x deployments with the New Relic agent: Tell Capistrano to load New Relic's recipes: If agent was installed with New Relic gem Add this at the top of your deploy.rb file: require 'new_relic/recipes' Copy If agent was installed as Rails plugin In your Capfile, add the following line above load deploy.rb (if it is not already there): Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) } Copy Add the following hooks to your deploy.rb file: # Notify New Relic of deployments. # This goes out even if the deploy fails, sadly. after \"deploy\", \"newrelic:notice_deployment\" after \"deploy:migrations\", \"newrelic:notice_deployment\" after \"deploy:cold\", \"newrelic:notice_deployment\" Copy The next time you run cap deploy, the agent notifies New Relic of the deployment, and all time series charts will show the deployment event. Customize your Capistrano configuration If Capistrano is running the deployment notification recipe on a remote build machine,the build machine must have your New Relic License key. You can either copy a valid newrelic.yml file to the build machine (possibly using a Capistrano Before Hook) or call set :newrelic_license_key, 'YOUR_LICENSE_KEY' in your Capistrano configuration. You can customize some deployment information by using Capistrano variables. If defined, these will override the defaults. These apply to both Capistrano 2 and 3. Capistrano 2 and 3 variables Description newrelic_appname The app where the deployment will appear. By default this comes from the definition in the newrelic.yml file for the given rails_env. If you set this value from the command line, you can only specify one application name. If you set this value in newrelic.yml, only the first application name will be used. newrelic_changelog The change log, which is determined by running the svn/git log command from the local working directory where the Capistrano command was issued. newrelic_desc Descriptive text that appears with the deployment. Default is empty. newrelic_license_key The New Relic license key to use. By default this comes from the definition in the newrelic.yml file for the given rails_env. This is not the same as your REST API key. newrelic_revision The revision recorded for the deployment. Recommendation: If you are using Subversion, consider including the tag or branch name in addition to the revision. newrelic_user The user to associate with the deployment. Override Capistrano settings In any version of Capistrano, you can override settings in your deploy.rb: set :newrelic_user, \"username\" Copy To override settings with Capistrano 2.x: From the command line: cap production deploy -Snewrelic_desc=\"Deploying beta Krakatau release\" Copy This example will prompt for content that will appear in the deployment's change log: set(:newrelic_changelog) do Capistrano::CLI.ui.ask \"Enter a summary of changes: \" end Copy Deploy to staging By default, the newrelic_rpm gem comes with Capistrano tasks to record all deployments in your production environment. If you have a separate staging application, you can change the rails_env variable setting so that staging deployments are recorded in the staging app instead of the production app. To identify deployments to your staging environment, use Capistrano or the command line. Deploy to staging Comments Capistrano multistage If you are using Capistrano multistage, add this line to config/deploy/staging.rb: set :rails_env, \"staging\" Copy Capistrano 2.x If you are using Capistrano 2.x, add this information from the command line: cap -s rails_env=staging deployment_task_name Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.88455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "sections": "Record deployments with the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> allows you to send information about application deployments by using the REST API or a Capistrano recipe (versions 2.x and 3.x) distributed with the <em>Ruby</em> <em>agent</em>. You can then view deployments in the New Relic UI. By default, all deployment information is recorded in your"
      },
      "id": "603eb906196a671067a83df1"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/metal-controller-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.02841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.89111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.76392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/mongo-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.02841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.89111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.74081,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/rack-metal-support": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.02841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.89111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.76392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/sequel-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.02835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.89111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.76392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/apm-agent-security-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.86539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-01T08:20:10Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.57521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.6097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby": [
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-01T08:20:10Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.57516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.60968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-01T08:19:08Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.33497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-7x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.91232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-01T08:20:10Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.65111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.64859,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-8x-guide": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.91228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.64857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-01T08:19:08Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.39122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/new-relics-github-repository": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.91228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-01T08:20:10Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.65106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-10-01T08:20:09Z",
      "updated_at": "2021-09-14T20:51:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 3.0.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent are listed below. Please note that Grape, Padrino, and Sinatra are not supported for Ruby 3.0+. Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Yajl-Ruby:1.1.0 or higher Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.64857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.91223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation: Instrument transactions"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Tip",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-10-01T08:20:10Z",
      "updated_at": "2021-09-27T15:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Tip Older versions of Mocha can cause issues with the updated add_method_tracer. Mocha version 1.2.0 fixes this bug, so if after upgrading agent versions, you run into errors in your test suite such as: NoMethodError: super: no superclass method 'instance_method' for <ExampleClass> Copy and happen to have Mocha version < 1.2.0 installed, try increasing the Mocha version to 1.2.0 or above. We have only seen error this come up in a test environment calling Mocha methods. However, we recommend you verify the functionality of your application when troubleshooting. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.65102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-10-01T08:19:08Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.39122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    }
  ],
  "/docs/agents/ruby-agent/index": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.5096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "These instructions are for installing the <em>Ruby</em> <em>agent</em> as a Rails plugin. For most use cases, you should instead install the <em>agent</em> gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the <em>Ruby</em> <em>agent</em> as a gem in order to have better control over versions"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.19472,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.24847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent-gae-flexible-environment": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.55258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.672714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.316696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.55258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.672714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.316696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-heroku": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.55258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.672714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.316696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin": [
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.672676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.316666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-10-01T08:14:48Z",
      "updated_at": "2021-09-27T15:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.19.0 or higher. Excon instrumentation relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus only have partial distributed tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Cross application tracing does not support requests made via the Hydra mechanism. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial distributed tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism do not have cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.19466,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide distributed tracing for requests between"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/installation/uninstall-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.55255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.672676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.316666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/installation/update-ruby-agent": [
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.5525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> <em>installation</em>: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about <em>installation</em>, configuration, troubleshooting, and known issues) <em>Ruby</em> <em>agent</em> <em>installation</em> (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Cross application tracing in Ruby",
        "Important",
        "Requirements",
        "Middleware installation",
        "Configuration",
        "Cross application trace measurements",
        "From calling app to target host",
        "Receiving host",
        "Get distributed tracing"
      ],
      "title": "Cross application tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "e21e62e9c3329708a8d0e20dfd3871b510d4f9b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/cross-application-tracing-ruby/",
      "published_at": "2021-10-01T12:15:32Z",
      "updated_at": "2021-09-27T15:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing improves on cross application tracing and is recommended for large, distributed systems. Cross application tracing is deprecated in favor of distributed tracing. If you need to continue using cross application tracing, such as for a non-standard middleware framework, see the configuration information in this document. Requirements Follow these requirements to use cross application tracing with the Ruby agent: Make sure the requests being instrumented use a supported HTTP client library. Install or update to the latest Ruby agent (version 3.5.5.38 or higher). Follow the requirements for middleware installation. Middleware installation Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the Ruby agent will install the middleware automatically. If you use a different Rack-based framework, manually add the NewRelic::Rack::AgentHooks middleware to your stack. Configuration Cross application tracing can be controlled by a configuration flag. As of version 8.0.0 of the Ruby agent, the default for cross_application_tracer.enabled is false, even when unspecified. To enable cross application tracing, you must set this flag to true amd set distributed_tracing.enabled to false. cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy For versions below 8.0.0, cross application can be configured using the following setting. cross_application_tracer: enabled: true Copy Cross application trace measurements The external measurement (from the calling application) will always be larger than the internal measurement (from the called application). The external measurement is collected by New Relic's instrumentation of the HTTP client library (such as Net::HTTP). The internal measurement is taken by New Relic's instrumentation of the web framework (such as Rails) in the called application. Here are some of the major components included in the external measurement that are not included in the internal measurement: From calling app to target host DNS time to resolve the target hostname Time to establish a new TCP connection with the target host (TCP 3-way handshake plus SSL negotiation, if SSL is in use) Time spent in the HTTP client library to prepare and serialize the HTTP request Network latency to send the request across the wire to the target host Receiving host Time for the front-end web server on the receiving host to process the request and send it to the back-end web server on the receiving host Time for the request to be parsed in the back-end web server on the receiving host Time for the request to \"percolate\" through Rack middlewares on the receiving host Time for the web framework to route the request to the appropriate controller action Once the web framework has routed it to the appropriate controller action, this is where the internal measurement happens. Then: Time for the request to \"percolate\" back up through the Rack middlewares Network latency to write the response back to the requesting server Time on the requesting host for the HTTP response to be parsed by the HTTP client library Some of these components are easier to control than others. For example, to capture timings for the Receiving host items above, make sure you have request queue monitoring set up on the receiving application. Get distributed tracing As of version 8.0.0 of the Ruby agent, distributed tracing is on by default. Distributed tracing is an improvement on cross application tracing and is recommended for large, distributed systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.67264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Cross application tracing in <em>Ruby</em>",
        "sections": "Middleware <em>installation</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": ". Install or update to the latest <em>Ruby</em> <em>agent</em> (version 3.5.5.38 or higher). Follow the requirements for middleware <em>installation</em>. Middleware <em>installation</em> Cross application tracing works with Rack, and therefore requires Rails 2.3 or greater, or another compatible framework. If you use Rails, the <em>Ruby</em>"
      },
      "id": "603eb84ae7b9d23a202a07d1"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.31663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "<em>Install</em> the <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/rack-middlewares": [
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.92828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.79898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.77591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.92828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.79898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation": [
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Important",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-10-01T08:21:23Z",
      "updated_at": "2021-09-27T15:24:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Distributed traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's cross application tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you are using Sinatra, have disabled middleware instrumentation as described above, and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. Important As of version 8.0.0, cross application tracing is deprecated in favor of distributed tracing. When enabled, distributed tracing is automatically configured for all rack-based apps without the need for an additional middleware. If you would like to continue using cross application tracing, you will need to update your configuration. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.08585,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-10-01T08:17:40Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.80066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    },
    {
      "sections": [
        "Redis instrumentation",
        "Tip",
        "Interaction with newrelic-redis",
        "Important",
        "Capture Redis command arguments"
      ],
      "title": "Redis instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "9923fcd7dd89191c620a9490fb89cd8ca4bf31e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation/",
      "published_at": "2021-10-01T08:21:22Z",
      "updated_at": "2021-03-16T08:03:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent automatically instruments the Redis gem (gem version 3.0.0 or higher). After you install the agent and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart on the APM Summary page will show color-coded Redis information. Tip Redis instrumentation requires Ruby agent version 3.13.0 or higher. Interaction with newrelic-redis The third-party newrelic-redis gem provides Redis instrumentation support as an add-on to New Relic's Ruby agent. If the Ruby agent detects newrelic-redis, it will not install the built-in Redis instrumentation and will record a log message like this at startup: INFO : Not installing New Relic supported Redis instrumentation because the third party newrelic-redis gem is present Copy To use New Relic's built-in Redis instrumentation and view Redis information in the UI, remove the newrelic-redis gem. Important Removing the newrelic-redis gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. Capture Redis command arguments By default, the Ruby agent only captures Redis command names. To capture Redis command arguments, use this configuration: transaction_tracer: record_redis_arguments: true Copy The agent limits the number of characters and arguments collected from each transaction trace node. The agent truncates items that exceed these limits.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.7775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Redis <em>instrumentation</em>",
        "sections": "Redis <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> automatically instruments the Redis <em>gem</em> (<em>gem</em> version 3.0.0 or higher). After you install the <em>agent</em> and generate traffic for your app, you can view Redis operations on the APM Summary page, on the Databases page, and in transaction traces. For example, the main chart"
      },
      "id": "603ed7a628ccbca064eba784"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/control-when-ruby-agent-starts": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52512,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/generating-logs-troubleshooting-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/incompatible-gems": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.5257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.330734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-appears-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.5257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.330734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-unicorn": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.3239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-log-file-ruby": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.3239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/not-installing-new-relic-supported-grape": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.3239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/passenger-troubleshooting": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/ruby-agent-audit-log": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/systemstackerror-stack-level-too-deep": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-deprecated-api-calls": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.33041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-private-api-calls-public-tracer-api": [
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-10-01T22:26:23Z",
      "updated_at": "2021-09-27T15:14:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.52554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source code The <em>Ruby</em> <em>agent</em> is open"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Ruby agent installation: Rails plugin",
        "Contents",
        "Install the New Relic Rails plugin",
        "Important",
        "Update the configuration file",
        "Update the newrelic.yml file",
        "Update the Ruby agent",
        "Tip",
        "Uninstall the Rails plugin",
        "For more help"
      ],
      "title": "Ruby agent installation: Rails plugin",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bc8a6181852e7ae08fc0cd808b6e0e9d5279bb49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin/",
      "published_at": "2021-10-01T22:27:06Z",
      "updated_at": "2021-09-27T15:58:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These instructions are for installing the Ruby agent as a Rails plugin. For most use cases, you should instead install the agent gem. Contents Install the New Relic Rails plugin Important New Relic strongly recommends installing the Ruby agent as a gem in order to have better control over versions and dependencies. To install the Rails plugin from Github, use the following commands for Rails versions 2 or higher: script/plugin install git://github.com/newrelic/newrelic-ruby-agent.git mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent Copy This will export the Rails plugin into your application's vendor/plugins directory. If you cannot install the Rails plugin directly from the git URL, you can clone the repository into the vendor/plugins directory. Update the configuration file After installing the agent, copy the newrelic.yml file into the config subdirectory of your application. You can download a fresh newrelic.yml that includes your license key from the Account settings when logged in to New Relic. Important As part of the installation process, change the default application name to a meaningful name. Update the newrelic.yml file Whenever you update the agent, double-check that your Ruby agent configuration file (config/newrelic.yml) is up to date: Open the default newrelic.yml file that lives in the Ruby agent's plugin folder (vendor/plugins/newrelic-ruby-agent/newrelic.yml). Look for new configuration options that are not in your config/newrelic.yml file. Update the Ruby agent When using Subversion with the Rails plugin, be sure to remove the old agent plugin before reinstalling. Tip Use the gem if possible. svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"removing old version of newrelic\" Copy Then, to install the latest Ruby agent plugin: script/rails plugin install git://github.com/newrelic/newrelic-ruby-agent.git vendor/plugins/newrelic-ruby-agent mv vendor/plugins/rpm vendor/plugins/newrelic-ruby-agent svn add vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins -m \"upgrading newrelic to version X.X.X\" Copy Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor/plugins/newrelic-ruby-agent svn commit vendor/plugins Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.32378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "sections": "<em>Ruby</em> <em>agent</em> installation: Rails plugin",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Uninstall the Rails plugin To uninstall the Rails plugin: svn rm vendor&#x2F;plugins&#x2F;newrelic-<em>ruby</em>-<em>agent</em> svn commit vendor&#x2F;plugins Copy For more help Additional documentation resources include: New Relic for <em>Ruby</em> (compatibility and requirements, general information about installation, configuration, <em>troubleshooting</em>, and known issues) <em>Ruby</em> <em>agent</em> installation (using the New Relic <em>Ruby</em> gem and configuration file)"
      },
      "id": "603eb6f4196a67251da83d95"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-06T21:50:42Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, no additional configuration is required. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.3303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em>: Configure logs in context",
        "sections": "<em>Ruby</em>: Configure logs in context",
        "tags": "Logs in context for <em>Ruby</em>",
        "body": "Logs in context for the <em>Ruby</em> <em>agent</em> connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your <em>Ruby</em> app To enable logs"
      },
      "id": "612d460128ccbc17bf56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.76018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident <em>Intelligence</em> Before setting up Incident <em>Intelligence</em>, note"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.61719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Query for when <em>application</em> traffic drops",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": " a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = &#x27;{{entity.name}}&#x27; since 1 hour ago. Copy Full variables list by category We&#x27;ll be updating this table frequently as we make updates to <em>Applied</em> <em>Intelligence</em>. Key Name Display Name alert&#x2F;account_id"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Incident workflows",
        "BETA FEATURE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-01T22:33:02Z",
      "updated_at": "2021-09-14T11:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.20955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": ": enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, <em>change</em>_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates"
      },
      "id": "603e967664441f7e6f4e889b"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.26773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.54057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.23615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.54057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.23615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-01T22:30:01Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.00545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.26758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.54056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.23615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.26758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.54056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.23615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 367.2674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.54053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "sections": "Proactive Detection with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies automatically correlated with other data sources via <em>Incident</em> <em>Intelligence</em>. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you&#x27;ll need to ask your IT administrator to install the <em>Applied</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-10-01T22:30:01Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.00545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Incident workflows",
        "BETA FEATURE",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-10-01T22:33:02Z",
      "updated_at": "2021-09-14T11:14:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 298.3774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " The <em>Workflows</em> feature is located under the <em>Alerts</em> &amp; AI menu. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI, in the left navigation under Enrich and Respond click <em>Workflow</em>, then click Add a <em>workflow</em>. Tip The maximum <em>workflows</em> you can add per environment is 1000 Name your <em>workflow</em>. This field is mandatory and needs"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.54346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Alerts best practices",
        "Recommended alerts",
        "Organize your policies",
        "Set your condition thresholds and violations",
        "Important",
        "Decide what happens when there's no signal",
        "Use non-null values when there's no signal",
        "Define your incident preferences",
        "Select your notification channels",
        "Understand muting rules",
        "What's next?"
      ],
      "title": "Alerts best practices",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Alerts and Applied Intelligence"
      ],
      "external_id": "44a12c229fe5c2f17fcaca2bc9d6ff87b4554b8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices/",
      "published_at": "2021-10-01T21:35:14Z",
      "updated_at": "2021-10-01T21:35:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Improve your Alerts coverage by implementing the following recommendations and get the most out of your alerts configuration. Read on to learn the best practices for: Policies Notification channels Incident preferences Thresholds and violations Muting rules Recommended alerts Use recommended alerts conditions conditions if you are new to Alerts or if you want suggestions that optimize your alert coverage. Organize your policies A policy is a container for similar conditions. If you’re new to Alerts, learn how to create, edit, or find policies. Organize your policy's scope to a single entity when possible. Assign your policy to the essential team or teams that need to be notified when an incident occurs. This way, you keep policies centralized and focused. If a team is monitoring several groups of the same entity type, combine those entity clusters (like servers) together into one policy. This way, your team can be notified from one policy rather than navigating several policies at once. You can use Alerts to monitor all of your entities. Consider your role and priorities when assigning yourself to a policy. For example: Software developers may need notifications for both front-end and back-end performance, such as webpage response time and page load JavaScript errors. Operations personnel may need notifications for poor back-end performance, such as server memory and load averages. The product owner may need notifications for positive front-end performance, such as improved end user Apdex scores or sales being monitored in dashboards. Set your condition thresholds and violations Set meaningful threshold levels to optimize Alerts for your business. Here are some suggested guidelines: Action Recommendations Set threshold levels Avoid setting thresholds too low. For example, if you set a CPU condition threshold of 75% for 5 minutes on your production servers, and it routinely goes over that level, this will increase the likelihood of un-actionable alerts or false positives. Experimenting with settings You do not need to edit files or restart software, so feel free to make quick changes to your threshold levels and adjust as necessary. Adjust settings Adjust your conditions over time. As you use our products to help you optimize your entity's performance, tighten your thresholds to keep pace with your improved performance. If you are rolling out something that you know will negatively impact your performance for a period of time, loosen your thresholds to allow for this. Disable settings You can disable any condition in a policy. This is useful, for example, if you want to continue using other conditions in the policy while you experiment with other metrics or thresholds. In most of our products (except Infrastructure), the color-coded health status indicator in the user interface changes as the alerting threshold escalates or returns to normal. This allows you to monitor a situation through our UI before a critical threshold passes, without needing to receive specific notifications about it. There are two violation thresholds: critical (red) and warning (yellow). Define these thresholds with different criteria, keeping in mind the suggestions above. Important Warning violations do not open incidents. A critical violation can open incidents, but you must define that decision through your incident preferences. Decide what happens when there's no signal Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. You can configure loss of signal settings by condition in the UI or configure loss of signal via the NerdGraph API. Use non-null values when there's no signal By default, gaps in data signals are filled with null values. In cases where you need to be able to create conditions based on those data gaps, you can fill gaps with a custom value or the last known value. You can configure this setting by condition in the UI or configure gap filling values via NerdGraph Define your incident preferences Decide when you get incident notifications so you can respond to incidents when they happen. If you’re new to Alerts, learn more about your incident preferences options. The default incident preference setting combines all conditions within a policy into one incident. Change your default incident preference setting to increase or decrease the number of incidents and incident notifications you receive. Each team within your organization will have different needs. Ask your team two important questions when deciding your incident preferences: Do we want to be notified every time something goes wrong? Do we want to group all similar notifications together and be notified once? When a policy and its conditions have a broader scope (like managing the performance of several entities), increase the amount of incidents you receive. You will need more notifications because two incidents will not necessarily relate to each other. When a policy and its conditions have a focused scope (like managing the performance of one entity), opt for the default incident preference. You will need less notifications when two incidents are related to each other or when the team is already notified and fixing an existing problem. Decide how you get incident notifications by using our notification channel best practices. Select your notification channels Tailor notifications to the most useful channel and policy so you can avoid alert fatigue and help the right personnel receive and respond to incidents they care about in a systematic way. If you’re new to Alerts, learn how to set up notification channels. Notify teams and individuals who needs to stay updated on or resolve a problem when an incident arises. To stay updated, select a notification channel that is less intrusive, like email. For vital notifications and incident responses, select a notification channel that is more intrusive, like PagerDuty or Slack. Do not rely on email for quick notifications in case of delays. Understand muting rules Mute alerts during routine events, such as maintenance or planned downtime. You can also silence a policy, a specific entity, and a condition when needed. Incidents can still be opened, but you won't be notified. If you're new to Alerts, learn how to create and manage muting rules. What's next? To learn more about using alerts: Learn about the API. Read technical details about min/max limits and rules. Read more about about when you might want to use loss-of-signal and gap-filling settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.71893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> best practices",
        "sections": "<em>Alerts</em> best practices",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Improve your <em>Alerts</em> coverage by implementing the following recommendations and get the most out of your <em>alerts</em> configuration. Read on to learn the best practices for: Policies Notification channels <em>Incident</em> preferences Thresholds and violations Muting rules Recommended <em>alerts</em> Use recommended <em>alerts</em>"
      },
      "id": "603ed04a28ccbc3ddeeba7b4"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "BETA FEATURE",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-10-01T22:30:54Z",
      "updated_at": "2021-09-14T20:01:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.37265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "BETA FEATURE This feature is currently in beta. With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.54333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Alerts best practices",
        "Recommended alerts",
        "Organize your policies",
        "Set your condition thresholds and violations",
        "Important",
        "Decide what happens when there's no signal",
        "Use non-null values when there's no signal",
        "Define your incident preferences",
        "Select your notification channels",
        "Understand muting rules",
        "What's next?"
      ],
      "title": "Alerts best practices",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Alerts and Applied Intelligence"
      ],
      "external_id": "44a12c229fe5c2f17fcaca2bc9d6ff87b4554b8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices/",
      "published_at": "2021-10-01T21:35:14Z",
      "updated_at": "2021-10-01T21:35:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Improve your Alerts coverage by implementing the following recommendations and get the most out of your alerts configuration. Read on to learn the best practices for: Policies Notification channels Incident preferences Thresholds and violations Muting rules Recommended alerts Use recommended alerts conditions conditions if you are new to Alerts or if you want suggestions that optimize your alert coverage. Organize your policies A policy is a container for similar conditions. If you’re new to Alerts, learn how to create, edit, or find policies. Organize your policy's scope to a single entity when possible. Assign your policy to the essential team or teams that need to be notified when an incident occurs. This way, you keep policies centralized and focused. If a team is monitoring several groups of the same entity type, combine those entity clusters (like servers) together into one policy. This way, your team can be notified from one policy rather than navigating several policies at once. You can use Alerts to monitor all of your entities. Consider your role and priorities when assigning yourself to a policy. For example: Software developers may need notifications for both front-end and back-end performance, such as webpage response time and page load JavaScript errors. Operations personnel may need notifications for poor back-end performance, such as server memory and load averages. The product owner may need notifications for positive front-end performance, such as improved end user Apdex scores or sales being monitored in dashboards. Set your condition thresholds and violations Set meaningful threshold levels to optimize Alerts for your business. Here are some suggested guidelines: Action Recommendations Set threshold levels Avoid setting thresholds too low. For example, if you set a CPU condition threshold of 75% for 5 minutes on your production servers, and it routinely goes over that level, this will increase the likelihood of un-actionable alerts or false positives. Experimenting with settings You do not need to edit files or restart software, so feel free to make quick changes to your threshold levels and adjust as necessary. Adjust settings Adjust your conditions over time. As you use our products to help you optimize your entity's performance, tighten your thresholds to keep pace with your improved performance. If you are rolling out something that you know will negatively impact your performance for a period of time, loosen your thresholds to allow for this. Disable settings You can disable any condition in a policy. This is useful, for example, if you want to continue using other conditions in the policy while you experiment with other metrics or thresholds. In most of our products (except Infrastructure), the color-coded health status indicator in the user interface changes as the alerting threshold escalates or returns to normal. This allows you to monitor a situation through our UI before a critical threshold passes, without needing to receive specific notifications about it. There are two violation thresholds: critical (red) and warning (yellow). Define these thresholds with different criteria, keeping in mind the suggestions above. Important Warning violations do not open incidents. A critical violation can open incidents, but you must define that decision through your incident preferences. Decide what happens when there's no signal Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. You can configure loss of signal settings by condition in the UI or configure loss of signal via the NerdGraph API. Use non-null values when there's no signal By default, gaps in data signals are filled with null values. In cases where you need to be able to create conditions based on those data gaps, you can fill gaps with a custom value or the last known value. You can configure this setting by condition in the UI or configure gap filling values via NerdGraph Define your incident preferences Decide when you get incident notifications so you can respond to incidents when they happen. If you’re new to Alerts, learn more about your incident preferences options. The default incident preference setting combines all conditions within a policy into one incident. Change your default incident preference setting to increase or decrease the number of incidents and incident notifications you receive. Each team within your organization will have different needs. Ask your team two important questions when deciding your incident preferences: Do we want to be notified every time something goes wrong? Do we want to group all similar notifications together and be notified once? When a policy and its conditions have a broader scope (like managing the performance of several entities), increase the amount of incidents you receive. You will need more notifications because two incidents will not necessarily relate to each other. When a policy and its conditions have a focused scope (like managing the performance of one entity), opt for the default incident preference. You will need less notifications when two incidents are related to each other or when the team is already notified and fixing an existing problem. Decide how you get incident notifications by using our notification channel best practices. Select your notification channels Tailor notifications to the most useful channel and policy so you can avoid alert fatigue and help the right personnel receive and respond to incidents they care about in a systematic way. If you’re new to Alerts, learn how to set up notification channels. Notify teams and individuals who needs to stay updated on or resolve a problem when an incident arises. To stay updated, select a notification channel that is less intrusive, like email. For vital notifications and incident responses, select a notification channel that is more intrusive, like PagerDuty or Slack. Do not rely on email for quick notifications in case of delays. Understand muting rules Mute alerts during routine events, such as maintenance or planned downtime. You can also silence a policy, a specific entity, and a condition when needed. Incidents can still be opened, but you won't be notified. If you're new to Alerts, learn how to create and manage muting rules. What's next? To learn more about using alerts: Learn about the API. Read technical details about min/max limits and rules. Read more about about when you might want to use loss-of-signal and gap-filling settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.71887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> best practices",
        "sections": "<em>Alerts</em> best practices",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Improve your <em>Alerts</em> coverage by implementing the following recommendations and get the most out of your <em>alerts</em> configuration. Read on to learn the best practices for: Policies Notification channels <em>Incident</em> preferences Thresholds and violations Muting rules Recommended <em>alerts</em> Use recommended <em>alerts</em>"
      },
      "id": "603ed04a28ccbc3ddeeba7b4"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-10-01T08:27:25Z",
      "updated_at": "2021-09-14T07:18:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.77518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " cost. When an anomaly is detected, you can view it in the <em>Applied</em> <em>Intelligence</em> anomalies feed, or we&#x27;ll send notifications directly to your Slack channel or a webhook. How it works <em>Proactive</em> <em>Detection</em> uses the following methods to <em>detect</em> anomalies in your app data: <em>Proactive</em> <em>Detection</em> monitors metric"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.00253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-01T22:37:31Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.94275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Expanded anomaly detection",
        "Important",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-10-01T22:33:01Z",
      "updated_at": "2021-09-14T10:33:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This feature is a limited release. We’ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what you’ll want to be notified about ahead of time. Anomaly detection helps you distinguish between what’s typical performance in your system and where you’re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities you’d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as they’re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection won’t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If you’re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If it’s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.66113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Get started with anomaly <em>detection</em> To get started with expanded anomaly <em>detection</em>: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em> &gt; Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload"
      },
      "id": "60b5124064441ff965e2cb01"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 311.00238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic <em>Proactive</em> <em>Detection</em> anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-01T22:37:31Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.94273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required from you"
      },
      "id": "603ea67c64441ffd1c4e8860"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1727.0417,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Alerts best practices",
        "Recommended alerts",
        "Organize your policies",
        "Set your condition thresholds and violations",
        "Important",
        "Decide what happens when there's no signal",
        "Use non-null values when there's no signal",
        "Define your incident preferences",
        "Select your notification channels",
        "Understand muting rules",
        "What's next?"
      ],
      "title": "Alerts best practices",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Alerts and Applied Intelligence"
      ],
      "external_id": "44a12c229fe5c2f17fcaca2bc9d6ff87b4554b8b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alerts-best-practices/",
      "published_at": "2021-10-01T21:35:14Z",
      "updated_at": "2021-10-01T21:35:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Improve your Alerts coverage by implementing the following recommendations and get the most out of your alerts configuration. Read on to learn the best practices for: Policies Notification channels Incident preferences Thresholds and violations Muting rules Recommended alerts Use recommended alerts conditions conditions if you are new to Alerts or if you want suggestions that optimize your alert coverage. Organize your policies A policy is a container for similar conditions. If you’re new to Alerts, learn how to create, edit, or find policies. Organize your policy's scope to a single entity when possible. Assign your policy to the essential team or teams that need to be notified when an incident occurs. This way, you keep policies centralized and focused. If a team is monitoring several groups of the same entity type, combine those entity clusters (like servers) together into one policy. This way, your team can be notified from one policy rather than navigating several policies at once. You can use Alerts to monitor all of your entities. Consider your role and priorities when assigning yourself to a policy. For example: Software developers may need notifications for both front-end and back-end performance, such as webpage response time and page load JavaScript errors. Operations personnel may need notifications for poor back-end performance, such as server memory and load averages. The product owner may need notifications for positive front-end performance, such as improved end user Apdex scores or sales being monitored in dashboards. Set your condition thresholds and violations Set meaningful threshold levels to optimize Alerts for your business. Here are some suggested guidelines: Action Recommendations Set threshold levels Avoid setting thresholds too low. For example, if you set a CPU condition threshold of 75% for 5 minutes on your production servers, and it routinely goes over that level, this will increase the likelihood of un-actionable alerts or false positives. Experimenting with settings You do not need to edit files or restart software, so feel free to make quick changes to your threshold levels and adjust as necessary. Adjust settings Adjust your conditions over time. As you use our products to help you optimize your entity's performance, tighten your thresholds to keep pace with your improved performance. If you are rolling out something that you know will negatively impact your performance for a period of time, loosen your thresholds to allow for this. Disable settings You can disable any condition in a policy. This is useful, for example, if you want to continue using other conditions in the policy while you experiment with other metrics or thresholds. In most of our products (except Infrastructure), the color-coded health status indicator in the user interface changes as the alerting threshold escalates or returns to normal. This allows you to monitor a situation through our UI before a critical threshold passes, without needing to receive specific notifications about it. There are two violation thresholds: critical (red) and warning (yellow). Define these thresholds with different criteria, keeping in mind the suggestions above. Important Warning violations do not open incidents. A critical violation can open incidents, but you must define that decision through your incident preferences. Decide what happens when there's no signal Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. You can configure loss of signal settings by condition in the UI or configure loss of signal via the NerdGraph API. Use non-null values when there's no signal By default, gaps in data signals are filled with null values. In cases where you need to be able to create conditions based on those data gaps, you can fill gaps with a custom value or the last known value. You can configure this setting by condition in the UI or configure gap filling values via NerdGraph Define your incident preferences Decide when you get incident notifications so you can respond to incidents when they happen. If you’re new to Alerts, learn more about your incident preferences options. The default incident preference setting combines all conditions within a policy into one incident. Change your default incident preference setting to increase or decrease the number of incidents and incident notifications you receive. Each team within your organization will have different needs. Ask your team two important questions when deciding your incident preferences: Do we want to be notified every time something goes wrong? Do we want to group all similar notifications together and be notified once? When a policy and its conditions have a broader scope (like managing the performance of several entities), increase the amount of incidents you receive. You will need more notifications because two incidents will not necessarily relate to each other. When a policy and its conditions have a focused scope (like managing the performance of one entity), opt for the default incident preference. You will need less notifications when two incidents are related to each other or when the team is already notified and fixing an existing problem. Decide how you get incident notifications by using our notification channel best practices. Select your notification channels Tailor notifications to the most useful channel and policy so you can avoid alert fatigue and help the right personnel receive and respond to incidents they care about in a systematic way. If you’re new to Alerts, learn how to set up notification channels. Notify teams and individuals who needs to stay updated on or resolve a problem when an incident arises. To stay updated, select a notification channel that is less intrusive, like email. For vital notifications and incident responses, select a notification channel that is more intrusive, like PagerDuty or Slack. Do not rely on email for quick notifications in case of delays. Understand muting rules Mute alerts during routine events, such as maintenance or planned downtime. You can also silence a policy, a specific entity, and a condition when needed. Incidents can still be opened, but you won't be notified. If you're new to Alerts, learn how to create and manage muting rules. What's next? To learn more about using alerts: Learn about the API. Read technical details about min/max limits and rules. Read more about about when you might want to use loss-of-signal and gap-filling settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1479.1722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> best practices",
        "sections": "<em>Alerts</em> best practices",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " conditions conditions if you are new to <em>Alerts</em> or if you want suggestions that optimize your <em>alert</em> coverage. Organize your policies A policy is a container for similar conditions. If you’re new to <em>Alerts</em>, learn how to create, edit, or find policies. Organize your policy&#x27;s scope to a single entity"
      },
      "id": "603ed04a28ccbc3ddeeba7b4"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1458.1537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> conditions. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/alert-custom-violation-descriptions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload": [
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-01T12:18:15Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.08112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.02057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-09-14T11:13:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.2092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> condition",
        "sections": "Custom metric examples for <em>alert</em> <em>notifications</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for <em>alert</em> <em>notifications</em> If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to <em>alert</em> on received and transmitted network stats), visit the <em>New</em> <em>Relic</em> Explorers Hub."
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22908,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.6223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.6223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22902,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/select-product-targets-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.6221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-09-14T11:13:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.63556,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "sections": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> <em>conditions</em> page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.14786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.6641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> conditions",
        "sections": "Create baseline <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.52023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> condition",
        "sections": "Use the <em>Alerts</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ", but will roll up into <em>incidents</em> that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by <em>New</em> <em>Relic</em>"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-01T03:03:26Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-01T03:03:25Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-01T00:20:29Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-01T03:03:26Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-01T03:03:25Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-01T00:20:29Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-01T03:03:26Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-10-01T03:02:18Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-01T00:20:29Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-10-01T03:03:26Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our <em>Graph</em>QL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-01T03:03:25Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45245,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-10-01T03:02:18Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our <em>Graph</em>QL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts": [
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-10-01T03:03:25Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-10-01T00:20:29Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-10-01T03:02:18Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.45197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/apm-metric-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62177,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.2287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.5382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-09-14T11:13:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.63548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "sections": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> <em>conditions</em> page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-01T03:10:28Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-10-01T03:04:43Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-01T03:10:28Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-10-01T03:04:43Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-10-01T03:10:28Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts": [
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-10-01T03:04:44Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-10-01T03:04:43Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.80641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.53445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.66382,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> conditions",
        "sections": "Create baseline <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.51996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> condition",
        "sections": "Use the <em>Alerts</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a condition’s thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit conditions with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/tag-information-not-showing-entity-infra-alert-condition": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.5344,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.66379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> conditions",
        "sections": "Create baseline <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.51993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> condition",
        "sections": "Use the <em>Alerts</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a condition’s thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit conditions with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/provide-runbook-instructions-alert-activity": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.01965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-10-01T22:37:31Z",
      "updated_at": "2021-09-14T07:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 171.531,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " with Incident <em>Intelligence</em> As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate incident events and reduce noise in your environment. With it, you can <em>get</em> an overview of all your issues, see suggested responders, and configure your own correlation logic. To <em>get</em> <em>started</em>, see"
      },
      "id": "603ea67c64441ffd1c4e8860"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Aporia (MLOps)",
        "Integrate Aporia with New Relic",
        "Monitor your machine learning models with Aporia",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-10-01T22:30:55Z",
      "updated_at": "2021-10-01T22:30:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. json { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. python import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Aporia (MLOps) By integrating Incident Intelligence with your Aporia machine-learning models, you can monitor your machine learning model performance. Integrate Aporia with New Relic Aporia allows you to connect alerts generated by Aporia’s monitors to New Relic’s Incident Intelligence engine and the predictions data in order to create a comprehensive monitoring dashboard in New Relic for your models. Step Details Log in into Aporia’s Console On the navbar on the left, click on Integrations and choose New Relic. Log in into your New Relic account Log into one.newrelic.com and click on Explorer. On the upper hand corner, on the main navigation menu, click on +Add more data. Click on Aporia In the search bar, type Aporia or scroll down to the MLOps Integration section and click on the Aporia icon. Get an API Key Once you click on the Aporia icon, follow step one by clicking Select or Create API key, under Prediction data. You’ll need to create a new API key or use an existing one. Copy and Paste the Token in Aporia Copy the token by clicking on the copy icon next to the API key. On Aporia’s dashboard, under the New Relic Integration page, paste the token under New Relic Insert Token and click Save. Verify the tokens In the Aporia dashboard, click on the Verify Tokens button to verify both tokens are working properly. Green check marks or red error marks should appear to indicate the status. Monitor your machine learning models with Aporia Now that you’ve integrated New Relic and Aporia, you can monitor your data using New Relic dashboards with automated charts created by Aporia. Step Details Go to the integration dashboard Once you’ve verified your tokens and confirmed the integration is set up correctly, return to the New Relic integration dashboard and click on See your data. This will redirect you to an automatically generated dashboard displaying data reported to Aporia in New Relic. Analyze Aporia's dashboard Aporia’s dashboard contains six charts: The Most Active Models chart and the Most Active Model Versions chart display the different models and versions that reported predictions in the selected timeframe. The Model Inferences graph displays the number of unique predictions reported for each model and version. The Average Numeric Inferences chart displays the average value numeric predictions reported for each model and version. The Numeric Inferences Heatmaps chart displays a histogram of the numeric predictions reported for each model and version. The Categorical Inferences charts display the different unique values and their frequencies of categorical predictions reported for each model and version. 3 . Filter data Click on the ... button and click on edit. On the right nav bar, under User as filter*, enable Filter the current dashboard and click Save**. Set up alert notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart widget, then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.86646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with Incident <em>Intelligence</em>",
        "sections": "<em>Get</em> <em>started</em> with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". To <em>get</em> data from <em>New</em> <em>Relic</em> Proactive Detection anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em>"
      },
      "id": "603ea62e64441f119f4e883f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22836,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes": [
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-10-01T22:36:47Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 192.82053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition <em>violations</em> are closed",
        "sections": "How <em>alert</em> condition <em>violations</em> are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> <em>violations</em> will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.14716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-10-01T03:05:59Z",
      "updated_at": "2021-08-26T05:25:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: NRQL alert conditions Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.49924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> conditions",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> <em>violations</em>"
      },
      "id": "6130c01e196a679fa84948f5"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.62112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.2283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions": [
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.22824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> <em>conditions</em>",
        "sections": "Create baseline <em>alert</em> <em>conditions</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> <em>conditions</em> give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    },
    {
      "sections": [
        "Set thresholds for an alert condition",
        "What is a threshold?",
        "View and set thresholds",
        "Use the Alerts API",
        "Set optional warning level",
        "Loss of signal (NRQL only)",
        "Set time intervals",
        "Set URL for runbook instructions"
      ],
      "title": "Set thresholds for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "dca23ef873646fff8184d0d1f339bb6b2d53cda5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/",
      "published_at": "2021-10-01T00:20:30Z",
      "updated_at": "2021-09-27T14:34:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you create a condition, you set thresholds that determine what will open a violation. This document explains what thresholds are and how to set them. What is a threshold? For a condition, thresholds are the settings that determine what opens a violation. Depending on a policy's incident preference, a violation may result in: The creation of an incident. Notifications being sent. Examples of thresholds: An application’s average web response time is greater than 5 seconds for 15 minutes. An application’s error rate per minute hits 10% or higher at least once in an hour. An application’s AJAX response time deviates a certain amount from its expected baseline behavior. Besides a mandatory critical threshold level, you can also set thresholds for a less serious warning level, which doesn't generate an incident or send a notification. View and set thresholds Thresholds are set during the process of creating a condition: Goal Instructions Set thresholds for a new condition Set thresholds as part of the process of creating a condition. View and update thresholds for existing conditions To view a condition’s thresholds: find that condition in the UI. To update thresholds, select a condition’s thresholds and make changes. To learn more about specific alert condition types (like baseline and NRQL), see Types of conditions. Details about other functionality and rules: Use the Alerts API You can list and edit conditions with the Alerts API. Set optional warning level You can set thresholds for two levels: critical (required) and warning (optional). Threshold level Details Critical (red) Required. When a violation occurs, it will send notifications depending on incident preference settings. Warning (yellow) Optional. Doesn't open incidents or generate notifications, but will roll up into incidents that are already open. Use a warning threshold if you want to monitor when a system behavior is concerning or noteworthy but not important enough to require a notification. Loss of signal (NRQL only) A loss of signal is a period of time when no data is received by New Relic. This could be the result of an entity or service going offline, an issue with an agent or collector, or networking problems in a data center or the internet. You can use loss of signal detection to create a new violation and notification if a signal stops and you expect a service to be stable. You may also want to use this to determine when an ephemeral service stops and set the action to close any open violations that exist for this condition. To learn more about signal loss, gap filling, and how to request access to these features, see this announcement. Set time intervals Different condition types have different minimum time intervals. For example, some condition types have a minimum time interval of 5 minutes (for example, APM metric alert conditions), and others have a minimum time interval of 1 minute (for example, NRQL alert conditions). The same happens with the maximum time interval, where the amount is 120 minutes. Set URL for runbook instructions For how to set this via the UI, see Runbook instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.53775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "sections": "Set thresholds for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a <em>condition’s</em> thresholds and make changes. To learn more about specific <em>alert</em> condition types (like baseline and NRQL), see Types of <em>conditions</em>. Details about other functionality and rules: Use the <em>Alerts</em> API You can list and edit <em>conditions</em> with the <em>Alerts</em> API. Set optional warning level You can set"
      },
      "id": "6130beec64441fc22f424353"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-09-14T11:13:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.63536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "sections": "Define custom metrics for an <em>alert</em> <em>condition</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> <em>conditions</em> page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.1471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View events from their products",
        "View health status from product entities (targets)",
        "View events and activity lists from products",
        "Tip",
        "View event violations",
        "View all event types"
      ],
      "title": "View events from their products",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert incidents"
      ],
      "external_id": "4451bca9fa3a3dc738fafd0099409c8e90df4658",
      "image": "https://docs.newrelic.com/static/17ca06d35c7d290e100b436c4e9dbe9d/8c557/crop-apm-index-health_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-08-26T05:37:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can view events and other activity for a specific entity from the New Relic One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity list. For instructions on how to view these details in Infrastructure, see the Infrastructure documentation. View health status from product entities (targets) To view information about the current status for an entity (alert condition target): From the menu bar, select the product (APM, Browser, etc.). The right side of the screen shows all of the violations for the entities listed. one.newrelic.com > APM : This example shows the violations for all of the APM applications for a specific account. The color-coded health states indicate Critical (red) conditions. View events and activity lists from products You can view a list of events and other activity from the index for the selected product. By selecting an event from the list, you can go directly to the selected entity's Summary page, where you can view detailed information. one.newrelic.com: Here's an example of a Summary of Application activity. It includes errors and violations. Depending on the product, the recent events and activity list also may appear on the selected entity's Overview page. Tip Exception: The index for dashboards and Synthetic monitoring doesn't include a list of recent events and other activity. View event violations To view an index of events resulting in condition violations across all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click Violations. The Violations index provides summary information about alerting events across all products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation (if available), select the Target. To view the condition that triggered the violation, select the Condition. To view incident details, select the Incident ID. View all event types To view an index of events for all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click All events. The All events index provides summary information about alerting events across available products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation, select its name from the Description. To view the condition that triggered the violation, select the condition's name from the Description. To view incident details, select the Incident ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.5521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View events <em>and</em> activity lists from products",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can view events and other activity for a specific entity from the <em>New</em> <em>Relic</em> One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity"
      },
      "id": "6130beec28ccbc673b56a861"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.66364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> conditions",
        "sections": "Create baseline <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents": [
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "View events from their products",
        "View health status from product entities (targets)",
        "View events and activity lists from products",
        "Tip",
        "View event violations",
        "View all event types"
      ],
      "title": "View events from their products",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert incidents"
      ],
      "external_id": "4451bca9fa3a3dc738fafd0099409c8e90df4658",
      "image": "https://docs.newrelic.com/static/17ca06d35c7d290e100b436c4e9dbe9d/8c557/crop-apm-index-health_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products/",
      "published_at": "2021-10-01T05:45:08Z",
      "updated_at": "2021-08-26T05:37:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can view events and other activity for a specific entity from the New Relic One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity list. For instructions on how to view these details in Infrastructure, see the Infrastructure documentation. View health status from product entities (targets) To view information about the current status for an entity (alert condition target): From the menu bar, select the product (APM, Browser, etc.). The right side of the screen shows all of the violations for the entities listed. one.newrelic.com > APM : This example shows the violations for all of the APM applications for a specific account. The color-coded health states indicate Critical (red) conditions. View events and activity lists from products You can view a list of events and other activity from the index for the selected product. By selecting an event from the list, you can go directly to the selected entity's Summary page, where you can view detailed information. one.newrelic.com: Here's an example of a Summary of Application activity. It includes errors and violations. Depending on the product, the recent events and activity list also may appear on the selected entity's Overview page. Tip Exception: The index for dashboards and Synthetic monitoring doesn't include a list of recent events and other activity. View event violations To view an index of events resulting in condition violations across all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click Violations. The Violations index provides summary information about alerting events across all products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation (if available), select the Target. To view the condition that triggered the violation, select the Condition. To view incident details, select the Incident ID. View all event types To view an index of events for all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click All events. The All events index provides summary information about alerting events across available products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation, select its name from the Description. To view the condition that triggered the violation, select the condition's name from the Description. To view incident details, select the Incident ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.55208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View events <em>and</em> activity lists from products",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can view events and other activity for a specific entity from the <em>New</em> <em>Relic</em> One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity"
      },
      "id": "6130beec28ccbc673b56a861"
    },
    {
      "sections": [
        "Create baseline alert conditions",
        "How it works",
        "Set baseline thresholds",
        "Faceted baseline conditions",
        "Baseline rules and settings",
        "Rules governing creation of baseline",
        "Baseline direction: select upper or lower ranges",
        "Preview chart: select 2 or 7 days"
      ],
      "title": "Create baseline alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "65e2bc791307efb5654c29e78754f7d88890db29",
      "image": "https://docs.newrelic.com/static/3be661b029a5f41d3da75175a0259fb9/c1b63/new-relic-baseline-alerts-direction-image-examples_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions/",
      "published_at": "2021-10-01T05:47:17Z",
      "updated_at": "2021-09-27T15:28:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use baseline conditions to define violation thresholds that adjust to the behavior of your data. Baseline alerting is useful for creating conditions that: Only notify you when data is behaving abnormally. Dynamically adjust to changing data and trends, including daily or weekly trends. In addition, baseline alerting works well with new applications when you do not yet have known behaviors. How it works When you choose a data source (for example, an APM metric) for a baseline condition, we'll use the past values of that data to dynamically predict the data's near-future behavior. The line of that predicted future behavior for that value is called a baseline. It appears as a dotted black line on the preview chart in the baseline condition UI. You'll use the baseline alert condition UI to: Adjust how sensitive the condition is to fluctuations in the data source. Set the behavior that will trigger a violation (for example: \"deviating for more than five minutes\"). Set whether you want the condition to check for upper violations, lower violations, or both. When your data escapes the predicted \"normal\" behavior and meets the criteria you've chosen, you'll receive a notification. Set baseline thresholds one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: Baseline alert conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline condition, go to one.newrelic.com > AI & Alerts > Policies > (create or select policy) > Create alert condition: When you start to create a condition, choose one of the following data sources: NRQL: Create a NRQL condition and then choose baseline APM: Application metric baseline Browser: Metric baseline Here are some tips for setting baseline thresholds: Set the baseline direction to monitor violations that happen either above or below the baseline. Set the preview chart to either 2 days or 7 days of displayed data. (Not applicable for NRQL alert conditions.) Use the slider bar to adjust the Critical threshold sensitivity, represented in the preview chart by the light gray area around the baseline. The tighter the band around the baseline, the more sensitive it is and the more violations it will generate. Optional: You can create a Warning threshold (the darker gray area around the baseline). For NRQL alerts, see the allowed types of NRQL queries. If the alert condition applies to multiple apps, you can select a choice from the dropdown above the chart to use different metrics. (Not applicable for NRQL alert conditions.) Faceted baseline conditions NRQL alerts conditions support faceted baselines. In the chart legend, click a time series to scope it to a single facet. Once you've run a faceted NRQL query for a baseline condition, you can scope your results to a single baseline. Click Return to full timeseries list to go back to seeing all your facets. The single time series shows the baseline, threshold band, and one or more violation regions, if there are any. Baseline rules and settings Here are some details about how the UI works: Rules governing creation of baseline The algorithm for baseline conditions is mathematically complex. Here are some of the major rules governing its predictive abilities: Data trait Baseline rules Age of data On initial creation, the baseline is calculated using between 1 to 4 weeks of data, depending on data availability and baseline type. After its creation, the algorithm will take into account ongoing data fluctuations over a long time period, although greater weight is given to more recent data. For data that has only existed for a short time, the baseline will likely fluctuate a good deal and not be very accurate. This is because there is not yet enough data to determine its usual values and behavior. The more history the data has, the more accurate the baseline and thresholds will become. Consistency of data For metric values that remain in a consistent range or that trend slowly and steadily, their more predictable behavior means that their thresholds will become tighter around the baseline. Data that is more varied and unpredictable will have looser (wider) thresholds. Regular fluctuations For shorter-than-one-week cyclical fluctuations (such as weekly Wednesday 1pm deployments or nightly reports), the baseline algorithm looks for these cyclical fluctuations and attempts to adjust to them. Baseline direction: select upper or lower ranges You can choose whether you want the condition to violate for behavior that goes above the baseline (\"upper\") or that goes below the baseline (\"lower\"), or that goes either above or below. You choose these with the Baseline direction selector. Example use cases for this: You might use the Upper setting for a data source like error rate, because you generally are only concerned if it goes up, and aren't concerned if it goes down. You might use the Lower setting for a data source like throughput, because sudden upward fluctuations are quite common, but a large sudden downswing would be a sign of a problem. Here are examples of how large fluctuations in your data would be treated under the different baseline direction settings. The red areas represent violations. Preview chart: select 2 or 7 days Not applicable for NRQL alert conditions. When setting thresholds, the preview chart has an option for displaying Since 2 days ago or Since 7 days ago. These selections are not the time period used to compute the baseline; they are only the time range used for a preview display. For more about the time range used to calculate the baseline, see the algorithm rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.6636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create baseline <em>alert</em> conditions",
        "sections": "Create baseline <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". Set baseline thresholds one.newrelic.com &gt; AI &amp; <em>Alerts</em> &gt; Policies &gt; (create or select policy) &gt; Create <em>alert</em> condition: Baseline <em>alert</em> conditions give you the ability to set intelligent, self-adjusting thresholds that only generate violations when abnormal behavior is detected. To create a baseline"
      },
      "id": "6130bf2928ccbc832a56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/delete-alert-notification-channels": [
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-01T12:18:15Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.08089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.01944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-10-01T05:43:56Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.66869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications": [
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-01T12:18:15Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.08087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.01936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-10-01T05:43:56Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.66867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/notification-channels-control-where-send-alerts": [
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-01T12:18:15Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.08087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.01936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-10-01T05:43:56Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.66867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/test-alert-notification-channels": [
    {
      "sections": [
        "Manage alert notification channels",
        "Tip",
        "Reference for updating channels",
        "View email channels",
        "Add or update email channels",
        "Create more channels",
        "Add or remove policies assigned to a channel",
        "Assign a channel to a policy",
        "Change a channel's name",
        "Check for policies assigned to a user",
        "Check how many policies are assigned to a channel",
        "View assigned alert policies",
        "Delete a channel",
        "Basic process"
      ],
      "title": "Manage alert notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "521bed5aa6fdcea5c1cffd11d01e6dad19bc7c40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/update-alert-notification-channels/",
      "published_at": "2021-10-01T12:18:15Z",
      "updated_at": "2021-09-08T15:38:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To keep alert notifications consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a new channel entirely, and more. Tip Your selected channel type determines the communication method that appears. For example, if your channel type is email, then the channel will include an email address value. For more information, see channel types. Reference for updating channels Here's a quick reference for updating channels which also includes links to more detailed information and procedures. View email channels Alerts automatically includes the email addresses for all users in the selected account as individual notification channels. If the account is a child account, the list shows only the users on the child account, not the users in the parent account. To view or search the list of user names and emails: Go to one.newrelic.com, in the top nav click Alerts & AI, then click Notification channels. In the search field, search for 'user'. Add or update email channels Users can't unsubscribe from email notifications. The account Owner or Admin must remove them from the policy's notification channel. To add or update account users as notification channels for a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, and then choose the policy you want to change. Optional: You can update notification channels for specific users. On the Notification channels page, select a user, select any policy subscription already associated with the user as applicable to view policy details. Click Notification channels, then follow standard procedures to add notification channels. Click Update policy. Create more channels To create a new notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Click New notification channel. Add or remove policies assigned to a channel To add or remove policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Choose a channel, and then click Alert policies. From the selected policy, use the windows to select, remove, or clear all notification channels. Assign a channel to a policy To add a notification channel to one or more policies: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies. Choose a policy, click Notification channels, and then click Add notification channels. Choose a channel, and then click Update policy. Change a channel's name To rename an existing notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details, change the name (maximum 64 characters) based on the channel type if applicable, and then save. Check for policies assigned to a user To check whether an account user has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. Optional: Search by \"user\" to browse users or a specific username or email. Choose the user, then click Alert policies. Check how many policies are assigned to a channel To check whether a notification channel has any policies assigned: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. The Policy subscriptions column lists how many policies are assigned to the channel. View assigned alert policies To view the policies assigned to a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, choose a channel, and then click Alert policies. OR To view the notification channels assigned to a policy: Go to one.newrelic.com, in the top nav click Alerts & AI, click Policies, choose a policy, then click Notification channels. Delete a channel To delete a notification channel: Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels. In the list, click the Delete icon. Basic process Go to one.newrelic.com, in the top nav click Alerts & AI, click Notification channels, then choose a channel. From the Channel details page, make any necessary changes, and then save. The user interface shows a Last modified time stamp for any changes to policies, including their conditions and notification channels.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.08086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>alert</em> <em>notification</em> channels",
        "sections": "Manage <em>alert</em> <em>notification</em> channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "To keep <em>alert</em> <em>notifications</em> consistent with your business needs, manage your channels. When you make updates, you can rename a channel, add policies to an existing channel, create a <em>new</em> channel entirely, and more. Tip Your selected channel type determines the communication method that appears"
      },
      "id": "603eca45e7b9d2d1d82a0806"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-10-01T12:16:15Z",
      "updated_at": "2021-10-01T12:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remaining events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.01929,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-10-01T05:43:56Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.66867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    }
  ]
}