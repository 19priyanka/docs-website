{
  "/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.23065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-09-02T06:09:40Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.46581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    },
    {
      "sections": [
        "Third party instrumentation",
        "Contents",
        "Finding third-party extensions",
        "Extensions as gems",
        "Starting transactions",
        "add_transaction_tracer",
        "perform_action_with_newrelic_trace",
        "Nodes in transaction traces",
        "add_method_tracer",
        "Custom Datastores",
        "NewRelic::Agent::Datastores.trace",
        "NewRelic::Agent::Datastores.wrap",
        "NewRelic::Agent::Datastores.notice_sql",
        "Caution",
        "NewRelic::Agent::Datastores.notice_statement",
        "Testing your extension",
        "NewRelic::Agent.require_test_helper",
        "assert_metrics_recorded",
        "in_web_transaction/in_background_transaction",
        "with_config",
        "Tip",
        "Multiverse: Test against multiple gem versions"
      ],
      "title": "Third party instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "57bcc0d905afa6233b74207ec38808fdf5cc97ef",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/third-party-instrumentation/",
      "published_at": "2021-09-02T02:57:44Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document details how to instrument third-party gems with the Ruby agent, as well as some best practices for interacting with the agent. This is useful if you are using a gem that the Ruby agent does not instrument by default, or if you are a gem author who wants to add instrumentation for your library. Contents Finding third-party extensions Anyone can write a gem that builds on top of the Ruby agent. New Relic maintains a repository called extends_newrelic_rpm to track these extensions and to provide links to other gems that build the Ruby agent. These extensions are not supported by New Relic. New Relic gathers these links as a service to our customers. Issues with those gems should be reported to the respective projects on GitHub. Extensions as gems New Relic encourages third-party extensions to be maintained as gems, with one gem per instrumented library. For example, newrelic-redis provides instrumentation for the redis gem. Starting transactions If your library provides code which should be represented as a full transaction in New Relic (for example: a web request or background job that isn't instrumented by the Ruby agent), then use one of these mechanisms for starting a transaction. add_transaction_tracer The simplest way to get a transaction started is to call add_transaction_tracer on the method. This assumes that NewRelic::Agent::Instrumentation::ControllerInstrumentation is included in your class. class CustomBackgroundJob include NewRelic::Agent::Instrumentation::ControllerInstrumentation def transaction # execute a transaction end add_transaction_tracer :transaction end Copy perform_action_with_newrelic_trace Sometimes you need slightly more control over the transaction that New Relic generates. When that happens, you can use perform_action_with_newrelic_trace. Some of the parameters you can override include the transaction name and category (whether it's a web transaction or a background transaction). class CustomBackgroundJob include NewRelic::Agent::Instrumentation::ControllerInstrumentation def transaction perform_action_with_newrelic_trace(:name => \"custom_name\", :category => :task) do # your work here... end end end Copy See the full documentation of perform_action_with_newrelic_trace for further information on parameters and usage. Nodes in transaction traces You may want to add timing information to New Relic about calls to a method, but it does not represent a full transaction. New Relic recommends adding a method tracer to accomplish this. add_method_tracer require 'new_relic/agent/method_tracer' class Foo include ::NewRelic::Agent::MethodTracer def generate_image # ... end add_method_tracer :generate_image, 'Custom/generate_image' end Copy The above example results in metrics being recorded for the name 'Custom/generate_image', as well as an entry in transaction traces that includes the method call. Custom Datastores The Ruby agent provides special functionality for recording calls to Datastores. These are intended to support both SQL and NoSQL databases, and provide a consistent interface for use by third-party gems. Metrics recorded via the NewRelic::Agent::Datastores module functions will show up in the Databases UI in New Relic. NewRelic::Agent::Datastores.trace trace is the simplest way to record Datastore for a method. class FauxDB def find # FauxDB lookup end NewRelic::Agent::Datastores.trace self, :find, \"FauxDB\" end Copy The first parameter is the class to instrument, the second the method to find, the third the datastore product name. An optional operation name can be included as the final parameter, otherwise the method name is used to represent the operation in metrics. Note that Datastore metrics recorded with this interface do not allow for adding a collection/table name. For that, see the wrap method below. NewRelic::Agent::Datastores.wrap wrap allows for recording Datastore metrics with additional collection/table information in the metric names. It also provides a callback for operations such as noticing slow statements. class FauxDB def find(table) NewRelic::Agent::Datastores.wrap(\"FauxDB\", \"find\", table) do # FauxDB lookup end end end Copy If you want to record additional information about your datastore call, you can use the optional callback parameter on wrap: class FauxDB def find(query) callback = Proc.new do |result, scoped_metric, elapsed| NewRelic::Agent::Datastores.notice_sql(query, scoped_metric, elapsed) end NewRelic::Agent::Datastores.wrap(\"FauxDB\", \"find\", \"items\", callback) do # execute query end end end Copy NewRelic::Agent::Datastores.notice_sql This helper method records slow SQL queries for presentation in transaction traces and slow SQL pages. SQL is filtered and obfuscated based on the user's settings. NewRelic::Agent::Datastores.notice_sql(query, scoped_metric, elapsed) Copy Non-SQL queries should never be sent through notice_sql.Use notice_statement instead. Caution New Relic's Transaction Tracing and Slow SQL features will attempt to apply obfuscation to the passed queries, but it is possible for a query format to be unsupported and result in exposing user information embedded within captured queries. NewRelic::Agent::Datastores.notice_statement This helper method records statements for slow datastore calls to transaction traces. These are not obfuscated. NewRelic::Agent::Datastores.notice_statement(statement, elapsed) Copy SQL queries should never be sent through notice_statement. Use notice_sql instead. Caution This method will properly ignore statements when the user has turned off capturing queries, but it is not able to obfuscate arbitrary data! Ensure all data passed to this method is safe to transmit to New Relic in order to prevent exposing user information embedded in captured queries. Testing your extension You can write automated tests when you author a gem that extends New Relic. The test helpers used by the agent itself are available to simplify some common testing tasks. NewRelic::Agent.require_test_helper The test methods documented in this section can be accessed by calling this from your test code (most commonly a test_helper.rb file) NewRelic::Agent.require_test_helper Copy assert_metrics_recorded This method is the primary way to ensure your expected metrics are recorded by the Ruby agent. refute_metrics_recorded is also available. In the simplest form, assert_metrics_recorded can be called like this: assert_metrics_recorded([\"MetricA\", \"MetricB\"]) Copy Metrics with specific values can be asserted via this syntax: assert_metrics_recorded('MetricA' => { :call_count => 1, :total_call_time => 1.0 }) Copy in_web_transaction/in_background_transaction These methods simulate running in web or background transaction. in_web_transaction do # Perform work to test behavior in transaction end Copy with_config Configuration of the agent can be changed for testing via with_config. It takes a hash which is applied to the other configuration values in agent. with_config(:enabled => false) do # Check what happens when agent's disabled end Copy Tip This method doesn't help for testing installation of instrumentation, as those config values are typically checked when instrumentation happens on require, and isn't influenced by the setting change in a test. Multiverse: Test against multiple gem versions If you need to test your extension against multiple gem versions, you can use Multiverse, a part of the Ruby agent's own testing code. For examples of Multiverse testing, see the suites directory in the agent files. To configure Multiverse for your own gem: Require tasks/multiverse in Rakefile. To enable the rake test:multiverse command, add the following to your Rakefile: require \"tasks/multiverse\" Copy Create the Multiverse test directory. Multiverse tests require a specific file layout. Create a directory named test/multiverse/YOUR_PROJECT with the following file locations: test/multiverse/YOUR_PROJECT test/multiverse/YOUR_PROJECT/Envfile test/multiverse/YOUR_PROJECT/config/newrelic.yml test/multiverse/YOUR_PROJECT/FILE_WITH_A_TEST.rb Copy Configure your Envfile. Use the Envfile to declare sets of gem dependencies for your Multiverse tests. For example, your Envfile might look like this: gemfile <-RB gem 'your-project', '~> 1.0.0' gem 'rack' gem 'newrelic_rpm' gem 'newrelic_your-project', path: '../../..' RB gemfile <-RB gem 'your-project', '~> 2.1.0' gem 'rack' gem 'newrelic_rpm' gem 'newrelic_your-project', path: '../../..' RB Copy Tip Include the gem lines for newrelic_rpm and rack to ensure your Multiverse tests work. Detect dependencies. If necessary, ensure your extension's instrumentation is loaded by running an additional dependency detection from your Multiverse tests: require 'newrelic/your-project' DependencyDetection.detect! class YourProjectTest > Minitest::Test end Copy To run your Multiverse tests against the gem dependencies in your Envfile: After setting up Multiverse for your gem, run rake test:multiverse to execute the tests in your directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.43867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NewRelic::<em>Agent</em>::Datastores.trace",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "This document details how to instrument third-party gems with the <em>Ruby</em> <em>agent</em>, as well as some best practices for interacting with the <em>agent</em>. This is useful if you are using a gem that the <em>Ruby</em> <em>agent</em> does not instrument by default, or if you are a gem author who wants to add instrumentation for your"
      },
      "id": "604403e0e7b9d23d64579a05"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/ruby-custom-instrumentation": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.230644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-09-02T06:08:35Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.07653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-09-02T06:09:40Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.46581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/ruby-custom-metrics": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.230644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-09-02T06:08:35Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.07653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-09-02T06:09:40Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.46581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.230644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-09-02T06:08:35Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.07653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Third party instrumentation",
        "Contents",
        "Finding third-party extensions",
        "Extensions as gems",
        "Starting transactions",
        "add_transaction_tracer",
        "perform_action_with_newrelic_trace",
        "Nodes in transaction traces",
        "add_method_tracer",
        "Custom Datastores",
        "NewRelic::Agent::Datastores.trace",
        "NewRelic::Agent::Datastores.wrap",
        "NewRelic::Agent::Datastores.notice_sql",
        "Caution",
        "NewRelic::Agent::Datastores.notice_statement",
        "Testing your extension",
        "NewRelic::Agent.require_test_helper",
        "assert_metrics_recorded",
        "in_web_transaction/in_background_transaction",
        "with_config",
        "Tip",
        "Multiverse: Test against multiple gem versions"
      ],
      "title": "Third party instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "57bcc0d905afa6233b74207ec38808fdf5cc97ef",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/third-party-instrumentation/",
      "published_at": "2021-09-02T02:57:44Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document details how to instrument third-party gems with the Ruby agent, as well as some best practices for interacting with the agent. This is useful if you are using a gem that the Ruby agent does not instrument by default, or if you are a gem author who wants to add instrumentation for your library. Contents Finding third-party extensions Anyone can write a gem that builds on top of the Ruby agent. New Relic maintains a repository called extends_newrelic_rpm to track these extensions and to provide links to other gems that build the Ruby agent. These extensions are not supported by New Relic. New Relic gathers these links as a service to our customers. Issues with those gems should be reported to the respective projects on GitHub. Extensions as gems New Relic encourages third-party extensions to be maintained as gems, with one gem per instrumented library. For example, newrelic-redis provides instrumentation for the redis gem. Starting transactions If your library provides code which should be represented as a full transaction in New Relic (for example: a web request or background job that isn't instrumented by the Ruby agent), then use one of these mechanisms for starting a transaction. add_transaction_tracer The simplest way to get a transaction started is to call add_transaction_tracer on the method. This assumes that NewRelic::Agent::Instrumentation::ControllerInstrumentation is included in your class. class CustomBackgroundJob include NewRelic::Agent::Instrumentation::ControllerInstrumentation def transaction # execute a transaction end add_transaction_tracer :transaction end Copy perform_action_with_newrelic_trace Sometimes you need slightly more control over the transaction that New Relic generates. When that happens, you can use perform_action_with_newrelic_trace. Some of the parameters you can override include the transaction name and category (whether it's a web transaction or a background transaction). class CustomBackgroundJob include NewRelic::Agent::Instrumentation::ControllerInstrumentation def transaction perform_action_with_newrelic_trace(:name => \"custom_name\", :category => :task) do # your work here... end end end Copy See the full documentation of perform_action_with_newrelic_trace for further information on parameters and usage. Nodes in transaction traces You may want to add timing information to New Relic about calls to a method, but it does not represent a full transaction. New Relic recommends adding a method tracer to accomplish this. add_method_tracer require 'new_relic/agent/method_tracer' class Foo include ::NewRelic::Agent::MethodTracer def generate_image # ... end add_method_tracer :generate_image, 'Custom/generate_image' end Copy The above example results in metrics being recorded for the name 'Custom/generate_image', as well as an entry in transaction traces that includes the method call. Custom Datastores The Ruby agent provides special functionality for recording calls to Datastores. These are intended to support both SQL and NoSQL databases, and provide a consistent interface for use by third-party gems. Metrics recorded via the NewRelic::Agent::Datastores module functions will show up in the Databases UI in New Relic. NewRelic::Agent::Datastores.trace trace is the simplest way to record Datastore for a method. class FauxDB def find # FauxDB lookup end NewRelic::Agent::Datastores.trace self, :find, \"FauxDB\" end Copy The first parameter is the class to instrument, the second the method to find, the third the datastore product name. An optional operation name can be included as the final parameter, otherwise the method name is used to represent the operation in metrics. Note that Datastore metrics recorded with this interface do not allow for adding a collection/table name. For that, see the wrap method below. NewRelic::Agent::Datastores.wrap wrap allows for recording Datastore metrics with additional collection/table information in the metric names. It also provides a callback for operations such as noticing slow statements. class FauxDB def find(table) NewRelic::Agent::Datastores.wrap(\"FauxDB\", \"find\", table) do # FauxDB lookup end end end Copy If you want to record additional information about your datastore call, you can use the optional callback parameter on wrap: class FauxDB def find(query) callback = Proc.new do |result, scoped_metric, elapsed| NewRelic::Agent::Datastores.notice_sql(query, scoped_metric, elapsed) end NewRelic::Agent::Datastores.wrap(\"FauxDB\", \"find\", \"items\", callback) do # execute query end end end Copy NewRelic::Agent::Datastores.notice_sql This helper method records slow SQL queries for presentation in transaction traces and slow SQL pages. SQL is filtered and obfuscated based on the user's settings. NewRelic::Agent::Datastores.notice_sql(query, scoped_metric, elapsed) Copy Non-SQL queries should never be sent through notice_sql.Use notice_statement instead. Caution New Relic's Transaction Tracing and Slow SQL features will attempt to apply obfuscation to the passed queries, but it is possible for a query format to be unsupported and result in exposing user information embedded within captured queries. NewRelic::Agent::Datastores.notice_statement This helper method records statements for slow datastore calls to transaction traces. These are not obfuscated. NewRelic::Agent::Datastores.notice_statement(statement, elapsed) Copy SQL queries should never be sent through notice_statement. Use notice_sql instead. Caution This method will properly ignore statements when the user has turned off capturing queries, but it is not able to obfuscate arbitrary data! Ensure all data passed to this method is safe to transmit to New Relic in order to prevent exposing user information embedded in captured queries. Testing your extension You can write automated tests when you author a gem that extends New Relic. The test helpers used by the agent itself are available to simplify some common testing tasks. NewRelic::Agent.require_test_helper The test methods documented in this section can be accessed by calling this from your test code (most commonly a test_helper.rb file) NewRelic::Agent.require_test_helper Copy assert_metrics_recorded This method is the primary way to ensure your expected metrics are recorded by the Ruby agent. refute_metrics_recorded is also available. In the simplest form, assert_metrics_recorded can be called like this: assert_metrics_recorded([\"MetricA\", \"MetricB\"]) Copy Metrics with specific values can be asserted via this syntax: assert_metrics_recorded('MetricA' => { :call_count => 1, :total_call_time => 1.0 }) Copy in_web_transaction/in_background_transaction These methods simulate running in web or background transaction. in_web_transaction do # Perform work to test behavior in transaction end Copy with_config Configuration of the agent can be changed for testing via with_config. It takes a hash which is applied to the other configuration values in agent. with_config(:enabled => false) do # Check what happens when agent's disabled end Copy Tip This method doesn't help for testing installation of instrumentation, as those config values are typically checked when instrumentation happens on require, and isn't influenced by the setting change in a test. Multiverse: Test against multiple gem versions If you need to test your extension against multiple gem versions, you can use Multiverse, a part of the Ruby agent's own testing code. For examples of Multiverse testing, see the suites directory in the agent files. To configure Multiverse for your own gem: Require tasks/multiverse in Rakefile. To enable the rake test:multiverse command, add the following to your Rakefile: require \"tasks/multiverse\" Copy Create the Multiverse test directory. Multiverse tests require a specific file layout. Create a directory named test/multiverse/YOUR_PROJECT with the following file locations: test/multiverse/YOUR_PROJECT test/multiverse/YOUR_PROJECT/Envfile test/multiverse/YOUR_PROJECT/config/newrelic.yml test/multiverse/YOUR_PROJECT/FILE_WITH_A_TEST.rb Copy Configure your Envfile. Use the Envfile to declare sets of gem dependencies for your Multiverse tests. For example, your Envfile might look like this: gemfile <-RB gem 'your-project', '~> 1.0.0' gem 'rack' gem 'newrelic_rpm' gem 'newrelic_your-project', path: '../../..' RB gemfile <-RB gem 'your-project', '~> 2.1.0' gem 'rack' gem 'newrelic_rpm' gem 'newrelic_your-project', path: '../../..' RB Copy Tip Include the gem lines for newrelic_rpm and rack to ensure your Multiverse tests work. Detect dependencies. If necessary, ensure your extension's instrumentation is loaded by running an additional dependency detection from your Multiverse tests: require 'newrelic/your-project' DependencyDetection.detect! class YourProjectTest > Minitest::Test end Copy To run your Multiverse tests against the gem dependencies in your Envfile: After setting up Multiverse for your gem, run rake test:multiverse to execute the tests in your directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.43867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NewRelic::<em>Agent</em>::Datastores.trace",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "This document details how to instrument third-party gems with the <em>Ruby</em> <em>agent</em>, as well as some best practices for interacting with the <em>agent</em>. This is useful if you are using a gem that the <em>Ruby</em> <em>agent</em> does not instrument by default, or if you are a gem author who wants to add instrumentation for your"
      },
      "id": "604403e0e7b9d23d64579a05"
    }
  ],
  "/docs/agents/ruby-agent/api-guides/third-party-instrumentation": [
    {
      "sections": [
        "Guide to using the Ruby agent API",
        "Important",
        "Instrument missing sections of your code with transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Collect or ignore errors",
        "Send custom event and metric data from your app",
        "Control the browser agent",
        "Instrument calls to datastores",
        "Instrument calls to externals",
        "Instrument calls for distributed tracing"
      ],
      "title": "Guide to using the Ruby agent API",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "b8a0743300bf602822bfdcf6c4760c64a4bebc0e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/guide-using-ruby-agent-api/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T14:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent provides a public API with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your Ruby app and collect more in-depth data: Overview Public API methods The following sections explain common goals, solutions, and links to relevant parts of the documentation. Important When using the Ruby agent API, ensure that you have the latest Ruby agent release. Several APIs used in the following examples require Ruby agent version 4.6.0 or higher. Instrument missing sections of your code with transactions To instrument your app, New Relic separates each path through your code into its own transaction. New Relic times (or \"instruments\") the parent method in these transactions to measure your app's overall performance, and collects transaction traces from long-running transactions for additional detail. Use these methods when New Relic is not instrumenting a particular part of your code at all: If you want to... Do this... Time a method New Relic is not instrumenting automatically Create a new transaction. See Tracing transaction entry points. Time something other than a single method call Use the Tracer API. Prevent a transaction from reporting to New Relic Ignore the transaction. Time specific methods using segments If a transaction is already visible in the New Relic UI, but you don't have enough data about a particular method that was called during that transaction, you can create segments to time those individual methods in greater detail. For example, you might want to time a particularly critical method with complex logic. Use these methods when you want to instrument a method within an existing transaction: If you want to... Do this... Time a particular method See Method tracers. Time something other than a single method call Use the Tracer API. Enhance the metadata of a transaction Sometimes the code you are targeting is visible in the New Relic UI, but some details of the method are not useful. For example: The default name is causing a metric grouping issue. You want to add custom attributes to your transactions so you can filter them in the query builder. Use these methods when you want to change how New Relic instruments a transaction that is already visible in the New Relic UI: If you want to... Do this... Change the name of a transaction See Naming transactions. Add metadata (such as your customer's account name or subscription level) to your transactions Use custom attributes. See Adding custom attributes. Mark a transaction as a background job See Monitor custom background jobs. Mark a transaction as a web transaction Pass a :category => :controller option to set_transaction_name(). For more information, see Naming transactions. Prevent a transaction from affecting your Apdex score See Ignoring Apdex contributions. Collect or ignore errors Usually the agent detects errors automatically. However, you can manually mark an error with the agent. You can also mark errors as ignored or expected. If you want to... Do this... Report an error the agent does not report automatically See Sending New Relic handled errors. Prevent the agent from reporting an error at all Mark the error as ignored. See Error Collector to use the error_collector.ignore_errors config option. Prevent an error from affecting your Apdex or error rate, but still report it to New Relic Mark the error as expected. See Sending New Relic handled errors, and set :expected to true. Send custom event and metric data from your app APM includes a number of ways to record arbitrary custom data. For an explanation of New Relic data types, see Data collection. If you want to... Do this... Send data about an event so you can analyze it in dashboards Create a custom event. See record_custom_event(). Tag your events with metadata to filter and facet them in dashboards or error analytics Add custom attributes. Pass a hash of attributes to record_custom_event(). Report custom performance data Create a custom metric. See record_metric(). Control the browser agent Usually the browser agent is added automatically to your pages or deployed by copy/pasting the JavaScript snippet. For more information about these recommended methods, see Add apps to browser monitoring. However, you can also retrieve the browser agent via APM agent API calls. For more information, see browser_timing_header(). Instrument calls to datastores Use these methods to collect data about your app's connections to other datastores: If you want to... Do this... Time a call to a datastore not instrumented automatically by New Relic See wrap(). Time a datastore call that can't cleanly be wrapped in a Ruby block See Tracer.start_datastore_segment(). You must call finish on the object returned by this method. Capture SQL queries along with timing See notice_sql(). Capture non-SQL queries along with timing See notice_statement(). Instrument calls to externals Use these methods to collect data for external requests: If you want to... Do this... Time a call to an external request not instrumented automatically by New Relic Use Tracer.start_external_segment(). You must call finish on the object returned by this method. Add cross-application tracing (CAT) headers to an outbound HTTP request Use add_request_headers(). Read CAT headers from an inbound HTTP request Use read_response_headers(). Generate an obfuscated string to transport CAT information in an outbound request Use get_request_metadata(). Process an obfuscated string containing CAT information received from an inbound request Use process_response_metadata(). Instrument calls for distributed tracing Important The following API examples require Ruby agent version 6.9.0 or higher. These APIs require distributed tracing to be enabled. Distributed tracing lets you see the paths requests take as they travel through a distributed system. For general instructions on how to use the calls below to implement distributed tracing, see Use distributed tracing APIs. If you want to... Do this... Send a payload/header to the called service. See insert_distributed_trace_headers(). Accept a payload/header received from the first service, which will link these services together in a trace See accept_distributed_trace_headers().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.230644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "sections": "<em>Guide</em> to using the <em>Ruby</em> <em>agent</em> <em>API</em>",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> provides a public <em>API</em> with documentation available on GitHub. The GitHub documentation tells you how to set up custom instrumentation of your <em>Ruby</em> app and collect more in-depth data: Overview Public <em>API</em> methods The following sections explain common goals, solutions"
      },
      "id": "604403a5196a67e712960f33"
    },
    {
      "sections": [
        "Ignoring specific transactions",
        "Blocking all instrumentation",
        "Ignoring specific actions with Rails",
        "Ignoring specific routes with Sinatra",
        "Ignoring Apdex contributions",
        "Blocking browser instrumentation",
        "Ignoring transactions dynamically",
        "Ignoring transactions by URL with configuration",
        "Troubleshooting",
        "For more help"
      ],
      "title": "Ignoring specific transactions",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "711df6a6f072c451ca8a55a9316d8c13c083ada2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/",
      "published_at": "2021-09-02T06:08:35Z",
      "updated_at": "2021-07-21T19:10:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic for Ruby allows you to selectively disable instrumentation for particular requests within your Rails or Sinatra application. Blocking all instrumentation Call newrelic_ignore with no arguments from within a Rails controller or Sinatra application to prevent instrumentation of all requests serviced by that controller or application: newrelic_ignore Copy Using newrelic_ignore prevents the agent from recording any performance data (metrics, transaction traces, events, traced errors, and so on) for the targeted transactions, and will also prevent the transactions from contributing to your overall Apdex score. Ignoring specific actions with Rails If you want to ignore only specific actions with a Rails controller, you can use the :only or :except options with newrelic_ignore. For example, to ignore only the index and show actions on the controller, use: newrelic_ignore :only => [:index, :show] Copy To ignore all actions on the controller except index: newrelic_ignore :except => [:index] Copy Ignoring specific routes with Sinatra If you want to ignore only specific routes within your Sinatra application, you can pass a Sinatra-style route definition to newrelic_ignore from within your Sinatra application. For more information, see Sinatra: Ignoring routes. Ignoring Apdex contributions If you want to prevent all actions in a controller from contributing to your Apdex score, but still want other performance data, use newrelic_ignore_apdex: newrelic_ignore_apdex Copy In a Rails application, newrelic_ignore_apdex supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Blocking browser instrumentation Using newrelic_ignore_enduser prevents the agent from automatically inserting the JavaScript used to capture browser monitoring data. Server-side instrumentation will be unaffected. To prevent browser agent injection for all actions in a controller, add a call like this to the controller class: newrelic_ignore_enduser Copy In a Rails application, newrelic_ignore_enduser supports the same :only and :except options as newrelic_ignore. In a Sinatra application, it will accept the same Sinatra-style route for targeting specific transactions. Ignoring transactions dynamically In some cases, you may want to base the decision to ignore a specific transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren't a good fit. Starting in Ruby agent version 3.9.2, you can instead use the following family of API calls from any point within your transaction: NewRelic::Agent.ignore_transaction NewRelic::Agent.ignore_apdex NewRelic::Agent.ignore_enduser Copy These methods will have a similar results to the newrelic_ignore, newrelic_ignore_apdex, and newrelic_ignore_enduser calls, but can be called during a request instead of during the class definition. Ignoring transactions by URL with configuration You can ignore transactions by URL using the rules.ignore_url_regexes configuration setting: rules: ignore_url_regexes: [\"secret\", \"^/admin\"] Copy This configuration will only prevent Transaction events that match the set pattern from reporting. Use any of the newrelic_ignore* family of methods if you would like to prevent all data, such as trace data, from reporting from a transaction. Note that regexes do not include any type of anchoring by default. The /secret/ regex will match 'newrelic.com/secret/login' and it will also match 'newrelic.com/users/secretpanda'. The anchored admin regex will match 'newrelic.com/admin/praetorians' but it will not match 'newrelic.com/users/totally-real-admin'. If necessary you may also provide a list of regexes in a comma-separated string, allowing you to set ignore regexes with an environment variable: NEW_RELIC_RULES_IGNORE_URL_REGEXES=\"secret,^/admin\" Copy As always configuration from environment variables will override configuration in newrelic.yml. Troubleshooting The newrelic_ignore* family of methods will only work from within Rails controller classes, or Sinatra applications (subclasses of Sinatra::Base). Other applications should use the NewRelic::Agent.ignore_* family of calls from within each request that you would like to ignore, which will work in any context. If you get a NoMethodError when trying to use newrelic_ignore from within a Rails controller or Sinatra application, make sure that newrelic_rpm has been required before you try to call newrelic_ignore inside of your class definition. For more help Additional documentation resources include Apdex: Measuring user satisfaction (how Apdex is calculated).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.07653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>API</em> <em>guides</em>",
        "body": " transaction on criteria only known at runtime, during the request. For scenarios like this, the declarative mechanisms explained above aren&#x27;t a good fit. Starting in <em>Ruby</em> <em>agent</em> version 3.9.2, you can instead use the following family of <em>API</em> calls from any point within your transaction: NewRelic"
      },
      "id": "603eb738196a67db90a83dbd"
    },
    {
      "sections": [
        "Sending handled errors to New Relic",
        "Notify the New Relic Ruby agent of an error"
      ],
      "title": "Sending handled errors to New Relic",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "API guides"
      ],
      "external_id": "349823d25fe83093a39bb114453b471888aacfb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/sending-handled-errors-new-relic/",
      "published_at": "2021-09-02T06:09:40Z",
      "updated_at": "2021-03-11T08:12:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To send error data that you are handling in your own code to New Relic, use the Ruby agent API NewRelic::Agent.notice_error call within your error handler. Notify the New Relic Ruby agent of an error This API call takes the exception and an optional options hash. Use this format: notice_error(exception, options = { }) ⇒ Object Copy This function records the given error and passes it through the normal error filtering process, including configuration-based ignoring of errors and the global #ignore_error_filter method if defined. The exception is the exception to be recorded, or an error message. If needed, you can also include options = { }. The following parameters will receive special treatment, and any other parameters you supply will be treated as custom parameters. options = { } Comments :expected Only records the error trace. This does not affect the error rate or Apdex status. For information on expected errors in the UI, see View expected errors. Replaces the :trace_only option, which was deprecated in version 4.3.x of the Ruby agent. :custom_params Custom parameters. :uri The request path, minus any request parameters or query string. Usually not needed. Include this only if you are calling notice_error outside a transaction. :metric The metric name associated with the transaction. Usually not needed. Include this only if you are calling notice_error outside a transaction. :request_params (deprecated) Older Ruby agent versions allowed passing a :request_params option, but those are now ignored. If you need to record the request parameters, call this method inside a transaction, or pass the information in :custom_params.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.46581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Notify the New Relic <em>Ruby</em> <em>agent</em> of an error",
        "tags": "<em>API</em> <em>guides</em>",
        "body": "To send error data that you are handling in your own code to New Relic, use the <em>Ruby</em> <em>agent</em> <em>API</em> NewRelic::<em>Agent</em>.notice_error call within your error handler. Notify the New Relic <em>Ruby</em> <em>agent</em> of an error This <em>API</em> call takes the exception and an optional options hash. Use this format: notice_error"
      },
      "id": "604403e0e7b9d295a15799ec"
    }
  ],
  "/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.93094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-09-02T06:10:23Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.74166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.30403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-agent-attributes": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.93091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.30402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Enable and disable attributes (Ruby)",
        "Properties",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Attribute rules",
        "Root level takes precedence for enabled.",
        "Destination enabled takes precedence over include and exclude.",
        "Attribute is included if the destination is enabled.",
        "Exclude always supersedes include.",
        "Keys are case sensitive.",
        "Use \\* for wildcards.",
        "Most specific setting for a key takes priority.",
        "Include or exclude affects the specific destination.",
        "URI-related properties",
        "Deprecated properties"
      ],
      "title": "Enable and disable attributes (Ruby)",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "af78e50fc7741c48a005c8fe81225b84f06e6c3c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/enable-disable-attributes-ruby/",
      "published_at": "2021-09-02T02:57:45Z",
      "updated_at": "2021-03-11T10:09:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This describes the properties to enable or disable attributes, and the rules that New Relic uses when determining which attributes to include or exclude for a destination. This also includes a summary of the Ruby agent properties that have been deprecated with the release of New Relic agent attributes. Properties Use the following properties to enable or disable attributes: attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. To prevent error.message collection, instead use the strip_exception_messages configuration. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction segments. Allows * as wildcard at end. Attribute rules New Relic follows these rules when determining which attributes to include or exclude for a destination. Root level takes precedence for enabled. The attributes.enabled field trumps all other settings. When false, no attributes will be reported to New Relic. Example configuration: attributes.enabled: false attributes.include: foo, bar transaction_tracer.attributes.enabled: true Copy Example output: Keys passed in: foo, bar, baz Keys included for all destinations: Keys excluded for all destinations: foo, bar, baz Copy Destination enabled takes precedence over include and exclude. The YOUR_DESTINATION.attributes.enabled flags take precedence over include and exclude keys. Example configuration: transaction_tracer.attributes.enabled: false attributes.include: one, two transaction_tracer.attributes.include: three, four Copy Example output: Keys passed in: one, two, three, four Keys included for transaction traces: Keys excluded for transaction traces: one, two, three, four Copy Attribute is included if the destination is enabled. If a destination is enabled, all user attributes are sent to that destination by default. Note: All user attributes default to true. However, by default, request parameters are disabled for all destinations. Example configuration: attributes.enabled: true attributes.exclude: baz Copy Example output: Keys passed in: foo, bar, baz Keys included: foo, bar Keys excluded: baz Copy Exclude always supersedes include. If the same key is listed in the include and exclude lists, then attributes with the specified key will be excluded. Example configuration: attributes.enabled: true attributes.include: foo, bar attributes.exclude: nerd, bar Copy Example output: Keys passed in: foo, bar, nerd Keys included: foo Keys excluded: nerd, bar Copy Keys are case sensitive. Keys are case-sensitive. Example configuration: attributes.enabled: true attributes.exclude: username, UsErNaMe Copy Example output: Keys passed in: username, Username, USERNAME, UsErNaMe, userNAME Keys included: Username, USERNAME, userNAME Keys excluded: username, UsErNaMe Copy Use \\* for wildcards. You can use an asterisk * at the end of a key as a wildcard. This will match a set of attributes with the same prefix. Example configuration: attributes.enabled: true attributes.include: custom* attributes.exclude: request.parameters.* Copy Example output: Keys passed in: custom, custom.key1, custom.key2, request.parameters., request.parameters.foo, request.parameters.bar Keys included: custom, custom.key1, custom.key2 Keys excluded: request.parameters., request.parameters.foo, request.parameters.bar Copy Most specific setting for a key takes priority. If multiple include or exclude attributes affect the same key, the most specific setting will have priority. Example configuration: attributes.enabled: true attributes.include: request.parameters.foo attributes.exclude: request.parameters.* Copy Example output: Keys passed in: request.parameters., request.parameters.foo, request.parameters.bar Keys included: request.parameters.foo Keys excluded: request.parameters., request.parameters.bar Copy Include or exclude affects the specific destination. If the attribute include or exclude is specified on a destination, then it only impacts that destination. Example configuration: attributes.include: foo transaction_events.attributes.exclude: foo Copy Example output: Keys passed in: foo Keys included for transaction events: Keys included for other destinations: foo Keys excluded for transaction events: foo Copy URI-related properties By default, the Ruby Agent reports Uniform Resource Identifiers (URIs) to New Relic in several different places, including the following destinations: The request.uri attribute of error events The http.url attribute of span events The url attribute of slow SQL traces The uri attribute of external request segments New Relic recommends having these URIs reported, as they can contain useful debugging information. If your URIs contain sensitive data that you don't want reported, URI reporting can be disabled. For example, sensitive data could include email addresses or account IDs. To disable URI reporting, add any of the above attribute names to the attributes.exclude list. For example, if you adding the following key to your configuration file will stop the agent from reporting any of the URI-related properties: attributes.exclude: uri Copy Deprecated properties The following properties have been deprecated. Switch to the new attributes configuration for these properties when upgrading your Ruby agent. Deprecated property New property capture_params attributes.include: request.parameters.* resque.capture_params attributes.include: job.resque.args.* sidekiq.capture_params attributes.include: job.sidekiq.args.* transaction_tracer.capture_attributes transaction_tracer.attributes.enabled error_collector.capture_attributes error_collector.attributes.enabled browser_monitoring.capture_attributes browser_monitoring.attributes.enabled analytics_events.capture_attributes transaction_events.attributes.enabled",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.76096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable and disable <em>attributes</em> (<em>Ruby</em>)",
        "sections": "Enable and disable <em>attributes</em> (<em>Ruby</em>)",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "This describes the properties to enable or disable <em>attributes</em>, and the rules that New Relic uses when determining which <em>attributes</em> to include or exclude for a destination. This also includes a summary of the <em>Ruby</em> <em>agent</em> properties that have been deprecated with the release of New Relic <em>agent</em>"
      },
      "id": "604403e0196a67cab0960f3a"
    }
  ],
  "/docs/agents/ruby-agent/attributes/ruby-attribute-examples": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.93091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent attributes",
        "httpResponseCode",
        "request.headers.referer",
        "request.parameters.*",
        "job.resque.args.*",
        "job.sidekiq.args.*",
        "Adding custom attributes",
        "Caution",
        "Upgrading the Ruby agent",
        "For more help"
      ],
      "title": "Ruby agent attributes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Attributes"
      ],
      "external_id": "76453699d829800b2dc9757c66c6f25f6c37f86a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/attributes/ruby-agent-attributes/",
      "published_at": "2021-09-02T06:10:23Z",
      "updated_at": "2021-06-02T22:15:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations. These attribute settings apply to version 3.12.0 or higher of the Ruby agent. Ruby agent attributes The following table lists the attributes that can be automatically captured by the Ruby agent: httpResponseCode The response status code for a web request. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Unavailable Note: The httpResponseCode attribute (string value) is deprecated as of agent version 6.12.0. http.statusCode (integer value) should be used instead. request.headers.referer The HTTP referrer header if present (minus the query string). Defaults: Transaction traces: Disabled Error collector (traced errors): Enabled Transaction events: Disabled Page views (browser monitoring): Unavailable request.parameters.* The HTTP request parameters, associated with the transaction. Available for Rails, Sinatra, and Grape applications only. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Disabled Note: The capture_params property is deprecated. However, if set to true, it will enable request parameters for transaction traces and traced errors. job.resque.args.* Job arguments passed to the Resque worker. Arguments passed to Resque workers are positional. These arguments are stored as keys of the form job.resque.args.<position> where position is the index of the argument to the perform method. For example, a Resque job that takes two arguments will have keys job.resque.args.0 and job.resque.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The resque.capture_params property is deprecated. However, if set to true, it will enable capture of Resque arguments for transaction traces, traced errors. job.sidekiq.args.* Job arguments passed to the Sidekiq worker. Arguments passed to Sidekiq workers are positional. These arguments are stored as keys of the form job.sidekiq.args.<position> where position is the index of the argument to the perform method. For example, a Sidekiq job that takes two arguments will have keys job.sidekiq.args.0 and job.sidekiq.args.1. Defaults: Transaction traces: Disabled Error collector (traced errors): Disabled Transaction events: Disabled Page views (browser monitoring): Unavailable Note: The sidekiq.capture_params property is deprecated. However, if set to true, it will enable capture of Sidekiq arguments for transaction traces and traced errors. Adding custom attributes To capture additional custom attributes from your application, use NewRelic::Agent.add_custom_attributes. For full reference see Collecting custom attributes. Defaults: Transaction traces: Enabled Error collector (traced errors): Enabled Transaction events: Enabled Page views (browser monitoring): Disabled Caution If you want to query your custom parameters or attributes, avoid using any of the reserved terms for naming them. Upgrading the Ruby agent When upgrading to Ruby agent 3.12.0 or higher, upgrade your newrelic.yml configuration. For more help Additional documentation resources include: Agent attributes (types, destinations, and limits for attributes used by New Relic agents) Enabling and disabling attributes (properties, rules, and backwards compatibility information for Ruby agent attributes) Attribute examples (scenarios and results of enabling and disabling different Ruby agent attributes)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.74165,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "sections": "<em>Ruby</em> <em>agent</em> <em>attributes</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " <em>attributes</em> (types, destinations, and limits for <em>attributes</em> used by New Relic <em>agents</em>) Enabling and disabling <em>attributes</em> (properties, rules, and backwards compatibility information for <em>Ruby</em> <em>agent</em> <em>attributes</em>) Attribute examples (scenarios and results of enabling and disabling different <em>Ruby</em> <em>agent</em> <em>attributes</em>)"
      },
      "id": "6044042028ccbc7da82c6083"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.30402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> monitors your applications to help you identify and solve performance issues. You can also extend the <em>agent</em>&#x27;s performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/delayedjob-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-09-02T06:31:36Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.09497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-09-02T03:31:18Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.10678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.18,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes": [
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-09-02T03:31:18Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.10678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.18,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.78471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/rake-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-09-02T06:31:36Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.09497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-09-02T03:31:18Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.10678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.18,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/resque-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-09-02T06:31:36Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.09497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Sidekiq instrumentation",
        "Capture job arguments",
        "Tip",
        "Troubleshoot Sidekiq jobs"
      ],
      "title": "Sidekiq instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "731a708841b1a18ecb19a0e60bf39d16cc8824c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation/",
      "published_at": "2021-09-02T03:31:18Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent (version 3.6.0 or higher) can automatically instrument your Sidekiq jobs. You do not need to include an instrumentation library in your worker. The Ruby agent will instrument the perform method on all Sidekiq workers. Data for background jobs appears in APM's Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Sidekiq job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: newrelic_rpm 3.12.0 or higher: attributes.include: job.sidekiq.args.* newrelic_rpm 3.6.9 to 3.11.x: sidekiq.capture_params: true Tip This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Troubleshoot Sidekiq jobs If it appears that jobs are not being monitored, review your newrelic_agent.log file generated when the worker starts. It should indicate whether the agent detects Sidekiq and communicates with the server. If you need support, note the exact command line that you used to start Sidekiq.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.10678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Troubleshoot Sidekiq <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": " for <em>background</em> <em>jobs</em> appears in APM&#x27;s Transactions page, complete with transaction traces and errors, by selecting Non-web transactions as the transaction type. Capture <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Sidekiq <em>job</em> arguments"
      },
      "id": "603ebccf64441f81034e8852"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.78471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/background-jobs/sidekiq-instrumentation": [
    {
      "sections": [
        "Monitor Ruby background processes",
        "Supported frameworks",
        "Important",
        "Monitor custom background jobs",
        "Monitor custom background methods",
        "Monitor short-lived processes",
        "Configure newrelic.yml for background processes",
        "Non-Rails background application",
        "Background job environment monitored by New Relic",
        "Report to an alternate application name",
        "Ensure the agent starts",
        "Non-Rails standalone script",
        "Background tasks with daemons gem",
        "Monitor scripts",
        "For more help"
      ],
      "title": "Monitor Ruby background processes",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "72fb23aadf860f8618b7d775a5cb74e798d2fdcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/monitor-ruby-background-processes/",
      "published_at": "2021-09-02T06:31:36Z",
      "updated_at": "2021-03-16T07:56:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent automatically instruments several common background job frameworks. You can also customize it to trace any background tasks. Data from background jobs appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following background job frameworks are supported by default in recent versions of the Ruby agent: Resque instrumentation (Ruby agent 3.4.0) Sidekiq instrumentation (Ruby agent 3.6.0) Delayed::Job instrumentation (Ruby agent 2.10) Important JRuby users may see issues with CPU metrics. If you are using these frameworks, monitoring background jobs typically doesn't require additional configuration. Monitor custom background jobs You can instrument custom background jobs to appear in the APM Transactions page as Non-web transactions. To monitor Non-web transactions while using an unsupported framework, you must add custom instrumentation. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module. Use the add_transaction_tracer directive below the method definition Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end Copy You can pass a string to the :category, but values will only appear on the APM Transactions page if the string begins with OtherTransaction/. Monitor custom background methods Using the Ruby agent API, you can designate specific methods to trace the Non-web transactions. This gathers traces for slow running jobs and associates captured errors to transactions. To instrument a class method, use the class singleton. As an example, a background job periodically runs a task called SalesOrganization#find_new_leads. Add the ControllerInstrumentation module below the method definition. Use the add_transaction_tracer directive Add :category => :task to tell the agent this trace is a Non-web transaction. require 'newrelic_rpm' class SalesOrganization def self.find_new_leads ... end class << self include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation add_transaction_tracer :find_new_leads, :category => :task end end Copy For more information, see Ruby custom metrics. Monitor short-lived processes Make sure the process isn't running before the agent connects to the back-end servers. To do so, make the Ruby agent synchronously connect to New Relic, rather than the default asynchronous behavior. Use manual_start and pass in the :sync_startup => true option: require 'new_relic/agent' NewRelic::Agent.manual_start(:sync_startup => true) Copy Using require 'new_relic/agent' will require the agent's code, and it will make sure the agent doesn't run until you manually start it. If the process is shorter than the agent harvest cycle, you need to manually shut down the agent with ::NewRelic::Agents.shutdown to ensure all queued data is sent. Configure newrelic.yml for background processes Configuring your newrelic.yml depends on the context of the background application. Non-Rails background application If your background app is non-Rails application already running the Ruby agent, copy your newrelic.yml file to the directory where you launch the background job or in the config subdirectory. Make sure it includes your license key. Background jobs that do not run in a Rails context will examine the NEW_RELIC_ENV environment variable to determine which section of the configuration file to read, falling back to the RUBY_ENV, RAILS_ENV, and RACK_ENV environment variables in sequence, and finally defaulting to development if none of these environment variables are set. Background job environment monitored by New Relic If your background job runs in the context of an existing web application that is already monitored with New Relic, the Ruby agent will automatically pick up your existing newrelic.yml file. Background jobs that boot your application's Rails environment will use the RAILS_ENV environment variable in order to determine which section of the newrelic.yml file to read. Report to an alternate application name You can make jobs that run in the context of an existing New Relic web application appear under a different application name in the APM UI. Begin before newrelic_rpm gets required by your worker code. Set the NEW_RELIC_APP_NAME environment variable to the application name to use for your background jobs when starting your background worker processes. This will override the app_name setting in your newrelic.yml. $ NEW_RELIC_APP_NAME=\"My Background Jobs\" ./bin/my_background_worker.rb Copy Ensure the agent starts The Ruby agent will automatically start in most cases as soon as you require 'newrelic_rpm', unless the agent detects a blacklisted executable name, rake task name, or constant. This prevents it from starting during common rake tasks and interactive console sessions. Non-Rails standalone script Standalone scripts running without Rails generally will start the agent as soon as they require 'newrelic_rpm'. If you have a script that forks or daemonizes before it begins its main work, you may want to defer this require call until after the initial setup finishes. Background tasks with daemons gem If you use the daemons gem to start background tasks, the Ruby agent may fail to start and also not emit any logging. This happens because the daemons gem changes the working directory to / before executing your background code. The agent then attempts to resolve the paths to its configuration file and log file relative to the current working directory of the host process. To allow the agent to start in this situation, set environment variables with the locations of the agent configuration file and log file; for example: ENV['NRCONFIG'] ||= File.dirname(__FILE__) + '/../../config/newrelic.yml' ENV['NEW_RELIC_LOG'] ||= File.dirname(__FILE__) + '/../../log/newrelic_agent.log' Copy For more information, see the documentation about controlling agent startup Monitor scripts The agent startup instructions apply when running background jobs in a daemon. If a script executes a single background task and exits, manually shut down the agent with ::NewRelic::Agents.shutdown when the script finishes. This ensures the New Relic collector receives the data. For example: require 'newrelic_rpm' class SalesOrganization include ::NewRelic::Agent::Instrumentation::ControllerInstrumentation def find_new_leads ... end add_transaction_tracer :find_new_leads, :category => :task end SalesOrganization.new.find_new_leads ::NewRelic::Agent.shutdown Copy For more help Additional documentation resources include: Ruby custom metrics (method tracers, metric names, stats, examples Ruby agent API (public API methods for the New Relic Ruby agent)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.09497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Monitor <em>Ruby</em> <em>background</em> processes",
        "sections": "Monitor custom <em>background</em> <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> automatically instruments several common <em>background</em> <em>job</em> frameworks. You can also customize it to trace any <em>background</em> tasks. Data from <em>background</em> <em>jobs</em> appears in the Transactions page in APM as Non-web transactions. Supported frameworks The following <em>background</em> <em>job</em> frameworks"
      },
      "id": "603ebccf28ccbca804eba7b4"
    },
    {
      "sections": [
        "Resque instrumentation",
        "Capturing job arguments",
        "Resque versions 1.23.1 or higher",
        "Alternate forking modes",
        "Old Resque versions (< 1.23.1)",
        "Deadlocking jobs"
      ],
      "title": "Resque instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "c9fc14a5f737d8d9b07d1beae24aa8fd8d030268",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/resque-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T06:55:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In addition to your web application itself, the New Relic Ruby agent can also instrument your Resque jobs. Capturing job arguments Starting with Ruby agent version 3.6.9, you can optionally configure the Ruby agent to capture Resque job arguments in transaction traces and traced errors. This can be especially useful in attempting to reproduce failed jobs. By default this feature is off in case your job arguments contain sensitive information. To enable this feature, edit your newrelic.yml as appropriate for your agent version: For newrelic_rpm 3.12.0 or higher: attributes.include: job.resque.args.* For newrelic_rpm 3.6.9 to 3.11.X: resque.capture_params: true This feature is distinct from the generic capture_params top-level setting, which controls whether HTTP request parameters are captured on transaction traces and traced errors for web requests. You can configure these two settings independently. Resque versions 1.23.1 or higher If you are running Resque 1.23.1 or higher, you should not need to make any code changes outside of the normal agent installation procedures in order for New Relic's Resque instrumentation to work. Exception: If you have leftover calls to NewRelic::Agent methods from your Resque before_first_fork, before_fork, or after_fork hooks from when you were running an older version of Resque, be sure to remove those calls after upgrading to Resque 1.23.1 or higher. Alternate forking modes The resque-multi-job-forks or resque-jobs-per-fork gems change the forking behavior of Resque so that it will not fork for each individual job, but instead fork once per batch of jobs. Similarly, you can set the FORK_PER_JOB environment variable to false in order to completely disable forking in Resque. If you use any of these alternate forking modes in your application, make sure you are running Ruby agent version 3.9.7 or higher. Earlier versions of the Ruby agent do not work correctly with these alternate forking modes. If you are upgrading to 3.9.7 or higher, make sure to remove any direct calls to NewRelic::Agent methods such as manual_start or after_fork that you may have previously been using in order to get the agent to work in these environments. Old Resque versions ( < 1.23.1) It is possible to use New Relic's Ruby agent with Resque versions older than 1.23.1. However, New Relic recommends that you upgrade to Resque 1.23.1 or higher for best results. Many applications use the hooks exposed by Resque (before_fork, after_fork, etc.) in order to inject custom code at critical points during the lifetime of Resque jobs. The New Relic Ruby agent also must use these hooks in order to be able to place its instrumentation. Resque versions before 1.23.1 do not allow hooks to be defined multiple times; the last definition will take precedence. If you cannot upgrade to a Resque version >= 1.23.1 (which allows hooks to be defined multiple times without overwriting each other), you can modify your custom Resque hooks by adding the necessary New Relic code. Here is an example. Example: Modifying custom Resque hooks You may omit definitions for any hooks that you have no custom code for. They will be automatically installed by the agent in this case. Resque.before_first_fork do # ... your custom hook code ... NewRelic::Agent.manual_start(:dispatcher => :resque, :sync_startup => true, :start_channel_listener => true) end Resque.before_fork do |job| # ... your custom hook code ... NewRelic::Agent.register_report_channel(job.object_id) end Resque.after_fork do |job| # ... your custom hook code ... NewRelic::Agent.after_fork(:report_to_channel => job.object_id, :report_instance_busy => false) end Copy Deadlocking jobs Some customers (particularly those with very high job throughput) have reported intermittent deadlocks in their Resque worker processes with the Ruby agent enabled. These deadlocks are due to a bad interaction between the background thread that the Ruby agent uses to send data to New Relic servers and Resque's forking behavior. Use either of these options to resolve these issues: Disable Resque's forking behavior by setting the FORK_PER_JOB environment variable to false when spawning Resque processes. Use the resolv-replace library from Ruby's standard library to replace Ruby's native DNS resolution code with a pure Ruby version. The Ruby agent uses a background thread in the Resque master process to send data to the New Relic collector. In some environments, this thread will acquire a native lock during DNS resolution (when resolving the hostnames of New Relic collectors). If this native lock is held by the background thread while the main Resque master process's main thread calls fork to create a child process, it will still be marked as held in the forked child process. However, since fork only copies the calling thread, the background thread that was holding the native lock will not exist in the child process, and thus the native lock will never be released. If the child process attempts to do any DNS resolution, it will attempt to acquire the same native lock and deadlock. To avoid this Github issue, use resolv-replace instead of Ruby's default DNS resolution path.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.18,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deadlocking <em>jobs</em>",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "In addition to your web application itself, the New Relic <em>Ruby</em> <em>agent</em> can also instrument your Resque <em>jobs</em>. Capturing <em>job</em> arguments Starting with <em>Ruby</em> <em>agent</em> version 3.6.9, you can optionally configure the <em>Ruby</em> <em>agent</em> to capture Resque <em>job</em> arguments in transaction traces and traced errors. This can"
      },
      "id": "603ebccf64441f10384e88b2"
    },
    {
      "sections": [
        "Rake instrumentation",
        "Enable Rake support",
        "Remove newrelic-rake when appropriate",
        "Caution",
        "Capture Rake job arguments"
      ],
      "title": "Rake instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Background jobs"
      ],
      "external_id": "d9f92b20388116f3ad38161c58ea8238e6243c71",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/background-jobs/rake-instrumentation/",
      "published_at": "2021-09-02T03:30:17Z",
      "updated_at": "2021-03-16T07:58:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher Ruby agent version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app's Rake tasks, add the names of the target tasks to the rake.tasks element in your newrelic.yml file. The Ruby agent matches these names against your active tasks using string regex. Example: Instrumenting two Rake tasks For example, to instrument the Rake tasks deploy and deploy:all, add the following to your newrelic.yml file: rake: tasks: [\"deploy\", \"deploy:all\"] Copy Since task name matching is with regex, you can instrument all of your app's Rake tasks by using a wildcard regex like [\".+\"]. However, this will not include Rake tasks that are in your deny list by default from the autostart.blacklisted_rake_tasks configuration setting, such as db:migrate. To include any Rake tasks that are in your deny list by default, include them in your customized deny list. To ensure the tasks are instrumented before they run if you are using Rails but your Rake task does not require the Rails environment, add require 'tasks/newrelic' to the top of the Rake tasks. Remove newrelic-rake when appropriate The newrelic-rake third-party gem provides Rake instrumentation support as an add-on to the Ruby agent. If the agent detects newrelic-rake, it will not install the built-in Rake instrumentation, but it will record a log message like this at startup: INFO : Not installing New Relic supported Rake instrumentation because the third party newrelic-rake gem is present Copy Caution Removing the newrelic-rake gem in favor of the built-in instrumentation will change your transaction names. To preserve your existing transaction names, ignore the log message and do not uninstall the gem. To switch to New Relic's built-in Rake instrumentation and change your transaction names: Remove the newrelic-rake gem. Specify the tasks you want to instrument in your config file. Capture Rake job arguments By default Rake job arguments are not captured. To capture Rake job arguments, use: attributes.include: job.rake.* Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.78471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Capture Rake <em>job</em> arguments",
        "tags": "<em>Background</em> <em>jobs</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> has opt-in support for instrumenting Rake tasks. This requires: Rake version 10.0.0 or higher <em>Ruby</em> <em>agent</em> version 3.13.0 or higher To instrument Rake tasks, specify the tasks by name in your newrelic.yml file. Enable Rake support To instrument your app&#x27;s Rake tasks, add"
      },
      "id": "603e9fea64441f1e104e8841"
    }
  ],
  "/docs/agents/ruby-agent/configuration/connect-hosts-your-account": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.560036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "<em>Configure</em> standard distributed tracing for your older <em>agents</em>",
        "tags": "Enable and <em>configure</em>",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through <em>configuration</em> settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side <em>configuration</em>"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.94278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation <em>configuration</em> Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and start"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.61218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    }
  ],
  "/docs/agents/ruby-agent/configuration/custom-ssl-certificates-ruby": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.560036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "<em>Configure</em> standard distributed tracing for your older <em>agents</em>",
        "tags": "Enable and <em>configure</em>",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through <em>configuration</em> settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side <em>configuration</em>"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.94278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation <em>configuration</em> Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and start"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.61218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    }
  ],
  "/docs/agents/ruby-agent/configuration/ruby-agent-configuration": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.560036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "<em>Configure</em> standard distributed tracing for your older <em>agents</em>",
        "tags": "Enable and <em>configure</em>",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through <em>configuration</em> settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side <em>configuration</em>"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.94278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation <em>configuration</em> Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and start"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.61218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    }
  ],
  "/docs/agents/ruby-agent/features/cross-application-tracing-ruby": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.28443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.2767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/developer-mode": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.28443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.2767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/garbage-collection": [
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.2767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-09-02T03:05:33Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.15247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/http-client-tracing-ruby": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.284424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.2767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-09-02T03:05:33Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.15247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/message-queues": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.284424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.2767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.28442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    },
    {
      "sections": [
        "Message queues",
        "Requirements",
        "Performance improvements with background tasks",
        "Queue operations",
        "View in New Relic UI",
        "Transactions page",
        "Tip",
        "Transaction trace summary page",
        "Transaction trace details tab"
      ],
      "title": "Message queues",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "1c074612f5486198c2639542507e2008abb20187",
      "image": "https://docs.newrelic.com/static/1789ce28689c4575593e79b8305171fd/c1b63/transactions_page.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/message-queues/",
      "published_at": "2021-09-02T03:05:33Z",
      "updated_at": "2021-05-05T01:16:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe/consume messages) as Message background tasks. Message creation via RabbitMQ also appears in transaction traces. Requirements Requires New Relic Ruby agent version 4.3.0 or higher. Instrumentation is automatic for supported versions of Bunny AMQP, and requires no additional configuration. Performance improvements with background tasks One way to increase responsiveness of web applications is to delegate work to background processes. Message queues are commonly used for this inter-process communication. In the context of message queuing systems, applications typically interact with message brokers to send and receive messages. The RabbitMQ Bunny client library allows Ruby applications to interface with message brokers that implement the Advanced Message Queuing Protocol (AMQP). New Relic's Ruby agent shows messages sent and received using the RabbitMQ client library. With this visibility, you can see details including: Number of messages produced by your app Time your app spends publishing messages Time your app spends processing \"consumed\" messages APM conveniently groups and reports operations that interact with queues. By analyzing this information, you can more easily identify bottlenecks and areas for performance improvement in your message passing architecture. Queue operations Supported entry points for queue operations appear as Put (publish a message) or Take (receive a message) in APM's user interface. Queue operations Publish a message (Put in UI) Receive a message (Take in UI) RabbitMQ publish pop subscribe (with block) View in New Relic UI Message queue operations are visible in several places in the APM UI: Transactions page Queue operations appear on APM's Transactions page for the selected app. The Put and Take metrics appear in the Breakdown table and are categorized as MessageBroker metrics. Here is an example: Transaction traces also provide additional details for messages. Tip You can select transaction traces from the app's Summary or Transactions pages in APM. Transaction trace summary page The Transaction trace summary page may show Put and Take operations in the Slowest components section. For example: Transaction trace details tab The Transaction trace page includes a dedicated Details tab that shows more detailed information about the transaction. Here is an example:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.15247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The New Relic <em>Ruby</em> <em>agent</em> supports the Bunny RabbitMQ client library, giving you insight into the performance of your message processing, for both incoming and outgoing messages. The APM UI shows transactions initiated via RabbitMQ message receipt (subscribe&#x2F;consume messages) as Message background"
      },
      "id": "604427cb28ccbcc86f2c606a"
    }
  ],
  "/docs/agents/ruby-agent/features/record-deployments-ruby-agent": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.28442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.276695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/features/ruby-vm-measurements": [
    {
      "sections": [
        "Garbage collection",
        "Important",
        "Enable garbage collection instrumentation",
        "View app-wide GC statistics",
        "View detailed GC metrics",
        "For more help"
      ],
      "title": "Garbage collection",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "9981cf22973c76aec7d8d0ac31c2793e04a42e48",
      "image": "https://docs.newrelic.com/static/e2fdc5c35adef00b9a2646a1ec6589c9/c1b63/garbage_collection_overview.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/garbage-collection/",
      "published_at": "2021-09-02T05:18:45Z",
      "updated_at": "2021-08-02T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Garbage collection (GC) finds unused data objects and reclaims that memory space for use by another process. The New Relic Ruby agent can collect information about how much time is spent in garbage collection for applications running on MRI 1.9.2 or higher or Ruby Enterprise Edition, but you must explicitly enable this feature in your application. Important Avoid using garbage collection in production for long periods of time, as it increases overhead. Enable garbage collection instrumentation To activate the feature, add the appropriate call in your application initialization. MRI 1.9.2 or higher: GC::Profiler.enable Ruby Enterprise Edition: GC.enable_stats For Rails applications, you can either add this call to an initializer in config/initializers, or add it directly to your config/application.rb file. View app-wide GC statistics To view overall garbage collection statistics: Log into New Relic, select a Ruby app, and go to Summary. From the APM Summary page, look for GC Execution statistics on the Web transactions time chart. one.newrelic.com > APM > (select a Ruby app) > Summary: On the Web transactions time chart, garbage collection statistics are labeled GC Execution. View detailed GC metrics To view garbage collection metrics on a per-transaction basis, go to one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction). You can then view the amount of time spent in GC, and the average number of times GC is called for each transaction. Hide other labels for a detailed view of garbage collection. one.newrelic.com > APM > (select a Ruby app) > Transactions > (select a transaction): Select an individual transaction to view detailed GC metrics, including average time and average number of calls. Detailed information includes: Garbage collection details Comments Trend of garbage collection time Garbage collection usually takes a small amount of time, and therefore the trend line may not be visible in your charts. To view the trend in garbage collection time, navigate to the overview chart or to detailed transaction metrics. Then, hide every chart label except GC Execution by selecting each label. Average number of calls To view the average number of garbage collection calls for each controller action: From your APM Summary page, select Transaction. Then select a controller action and view the App Server Breakdown. For more help Additional documentation resources include: APM Summary page (features and drill-down details when using the APM Summary page) Transactions page (features and drill-down details for transactions) Ruby agent configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.28441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " Additional documentation resources include: APM Summary page (<em>features</em> and drill-down details when using the APM Summary page) Transactions page (<em>features</em> and drill-down details for transactions) <em>Ruby</em> <em>agent</em> configuration (update procedures and configuration file values, including general, proxy, transaction traces, and error collector)"
      },
      "id": "603eba3a28ccbcb144eba7aa"
    },
    {
      "sections": [
        "Browser monitoring and the Ruby agent",
        "Requirements",
        "Use auto-instrumentation",
        "Manually instrument via agent API",
        "CSP Nonce support",
        "Troubleshooting",
        "Disable auto-instrumentation"
      ],
      "title": "Browser monitoring and the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "c7381e06d48fe877cdbcc935d51c88dd858d3673",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/new-relic-browser-ruby-agent/",
      "published_at": "2021-09-02T05:17:52Z",
      "updated_at": "2021-07-09T22:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Ruby agent, you can add browser monitoring agent instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser agent. Then follow the procedures in this section to set up the Ruby agent. Requirements Automatic browser instrumentation is supported for most recent versions of Rails: New Relic Ruby agent (version 3.0.1 or higher) For automatic instrumentation: Rails 2.3 or higher For manual instrumentation: Rails 2.0 to 2.2 Use auto-instrumentation Automatic instrumentation works with Rack, and requires Rails 2.3 or higher. Configure the agent to automatically instrument pages with end user monitoring scripts, by adding or editing the following flag in newrelic.yml. browser_monitoring: auto_instrument: true Copy This is the simplest way to monitor end users. The Ruby agent examines each page from your application and automatically injects the browser JavaScript in the header. Auto-instrumentation works for environments that support Rack. For performance reasons the agent scans only the first 50k of your application's response for the header instrumentation point. In cases where a X-UA-Compatible meta tag is present and the <head> tag is longer than 50k, auto-instrumentation will fail gracefully. Auto-instrumentation will look for an X-UA-Compatible meta tag and insert the JavaScript directly after it. If the auto-instrumentation cannot find an X-UA-Compatible meta tag, it will insert after the opening head tag, and failing that it will insert after the opening body tag. If any of these tags are wrapped in conditionals or comments, the automatic instrumentation will likely fail. If auto-instrumentation fails to correctly instrument your application’s pages, then you must manually instrument via agent API. Manually instrument via agent API If you are using Rails 2.1 to 2.2 or cannot use auto-instrumentation, you can still set up end user monitoring manually by including appropriate scripts in your pages. Use the New Relic Ruby agent's API to generate the script to be inserted into your pages. For example, to modify your application's template to call the agent, use: <head> <%= ::NewRelic::Agent.browser_timing_header rescue \"\" %> ... existing template code ... </head> Copy CSP Nonce support CSP Nonce usage in our browser instrumentation is supported in version 7.1.0+ of the Ruby agent. To use a nonce with the browser instrumentation, you must disable browser monitoring auto instrumentation and use the manual instrumentation via the agent API. You may now pass a nonce as an argument into the API method to allow the agent to insert the nonce into the browser instrumentation. For example, NewRelic::Agent.browser_timing_header(nonce). Troubleshooting If you do not see any browser data being reported, view the HTML source and confirm two blocks of script similar to this in your HTML head: <script type=\"text/javascript\">window.NREUM||(NREUM={});...</script> Copy If these are not present, check the auto-instrumentation settings or the placement of manual instrumentation in your template files. In versions of the Ruby agent prior to 3.7.0, <%=::NewRelic::Agent.browser_timing_footer rescue \"\" %> also needed to be called as close to the bottom of the document as possible. With 3.7.0, all the required script is included by browser_timing_header. browser_timing_footer returns an empty string for compatibility. Disable auto-instrumentation The default value of auto-instrument is true (even when unspecified). To disable auto-instrumentation, set this flag to false. To disable auto-instrumentation only for certain controllers or controller actions, use newrelic_ignore_enduser. Server-side instrumentation will be unaffected by this call.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.276695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "sections": "Browser monitoring and the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "With the <em>Ruby</em> <em>agent</em>, you can add browser monitoring <em>agent</em> instrumentation to your webpages either automatically or manually. To enable browser monitoring in the UI, follow the procedures to install the browser <em>agent</em>. Then follow the procedures in this section to set up the <em>Ruby</em> <em>agent</em>. Requirements"
      },
      "id": "603eb812e7b9d247a82a07dc"
    },
    {
      "sections": [
        "HTTP client tracing in Ruby",
        "Supported HTTP client libraries",
        "Excon notes",
        "Typhoeus notes",
        "Curb notes"
      ],
      "title": "HTTP client tracing in Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Features"
      ],
      "external_id": "49066996b3f5e2ec1ac4b0fdee102ee922879a90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/features/http-client-tracing-ruby/",
      "published_at": "2021-09-02T05:18:44Z",
      "updated_at": "2021-03-16T07:58:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they're hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests between applications instrumented with New Relic. Supported HTTP client libraries The following HTTP client libraries are currently supported by the Ruby agent: Name Minimum supported version Notes Net::HTTP N/A (part of the Ruby standard library) Also includes libraries built upon Net::HTTP, such as httparty. Excon 0.10.1 See Excon notes. Typhoeus 0.5.3 Hydra requests get partial instrumentation, 1.8.7 stability. See Typhoeus notes. HTTPClient 2.2.0 Instrumentation of asynchronous requests is not supported. Curb 0.8.1 Curl::Multi requests get partial instrumentation. See Curb notes. http.rb 0.9.9 Excon notes The Ruby agent supports Excon version 0.10.1 or higher. Excon instrumentation for Excon versions 0.19.0 and up relies on the ability to add an Excon middleware to the :middlewares key of Excon.defaults, so if your application modifies Excon.defaults you should ensure that you preserve the value of the :middlewares key. Typhoeus notes The Ruby agent supports Typhoeus version 0.5.3 or higher. Parallel requests made via the Hydra mechanism in Typhoeus currently only have partial tracing support. For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Hydra mechanism will also not get cross application tracing support. Testing has shown significant issues with segfaults when running Typhoeus on MRI 1.8.7. Recommendation: Use Ruby Enterprise Edition or MRI 1.9.3 or higher to avoid these problems. Curb notes The Ruby agent supports Curb version 0.8.1 or higher. Curb instrumentation on JRuby is not supported. Requests made via the Curl::Multi API currently only have partial tracing support (equivalent to what is offered for requests made via the Typhoeus Hydra API). For such requests, the Ruby agent will record a single transaction trace node representing the entire batch, but you will not be able to see the details about each individual request in the batch. Requests made via the Curl::Multi mechanism will also not get cross application tracing support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.534744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP client tracing in <em>Ruby</em>",
        "sections": "HTTP client tracing in <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "The <em>Ruby</em> <em>agent</em> can trace outgoing HTTP requests made by your application or script in order to: Record metrics about how long your HTTP requests are taking and which hosts they&#x27;re hitting. Annotate transaction traces with nodes for each HTTP request. Provide cross application tracing for requests"
      },
      "id": "603eb84a196a6755a9a83de9"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/metal-controller-instrumentation": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.25212,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/mongo-instrumentation": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.25212,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/rack-metal-support": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.2521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/frameworks/sequel-instrumentation": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.2521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/apm-agent-security-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.31693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.31104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-09-02T04:23:26Z",
      "updated_at": "2021-08-02T11:08:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.77638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.31693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.31104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-09-02T04:23:26Z",
      "updated_at": "2021-08-02T11:08:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.77638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-7x-guide": [
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-09-02T04:23:26Z",
      "updated_at": "2021-08-02T11:08:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.776375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.58861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " (recommended) Install docs for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/migration-8x-guide": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.31688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-09-02T04:23:26Z",
      "updated_at": "2021-08-02T11:08:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.776375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.58861,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " (recommended) Install docs for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/new-relics-github-repository": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.31688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Ruby agent requirements and supported frameworks",
        "Operating systems",
        "Security requirements",
        "Ruby versions",
        "Web servers",
        "Web frameworks",
        "Databases",
        "Other APM software",
        "Instance details",
        "Background jobs",
        "HTTP clients",
        "Message queuing",
        "Other",
        "Connect the agent to other parts of New Relic"
      ],
      "title": "Ruby agent requirements and supported frameworks",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "fcbaf26ace3ac2dba3d30693820665ad5ae23b36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks/",
      "published_at": "2021-09-02T04:23:26Z",
      "updated_at": "2021-08-02T11:08:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Ruby agent, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don't have one already, start by creating a New Relic account. It's free, forever. Operating systems The Ruby agent supports UNIX-like operating systems such as Linux, Solaris, FreeBSD, and macOS. Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Ruby versions The New Relic Ruby agent does not support experimental versions. Ruby versions supported by the Ruby agent include: Ruby versions Supported Deprecated JRuby 9.0.x 9.1.x 9.2.x 1.7.x or earlier: Last supported agent was 3.18.1.330. MRI 1.8.7 1.9.x 2.0.x 2.1.x 2.2.x 2.3.x 2.4.x 2.5.x 2.6.x 2.7.x 2.0.x, 2.1.x Last supported agent: 6.15.0. 1.8.7, 1.9.2, 1.9.3: Last supported agent was 3.18.1.330. 1.8.6: Last supported agent was 3.6.8.168. Web servers Web servers supported by the Ruby agent include: Web servers Supported Deprecated Experimental Passenger 2.2.x 3.0.x 4.0.x 5.x.x 6.0.x Puma 2.0.x 3.x.x 1.0.x Rainbows! 4.5.0 Thin 1.x.x Unicorn 4.x.x 5.x.x 6.0.x 1.0.x 2.0.x 3.0.x Webrick Supported for all agent-supported versions of Ruby Web frameworks The Ruby agent does not support experimental versions. Web frameworks supported by the Ruby agent include: Web frameworks Supported Deprecated Grape 0.2.0 1.2.x 1.3.x 1.4.x Padrino 0.14.x 0.15.x Rack 1.1.0 or higher 2.0.3 or higher 1.0.x Rails 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x: Last supported agent was 3.6.8.168. 3.0.x, 3.1.x: Last supported agent was 6.15.0. Sinatra 1.4.x 1.5.x 2.0.x 2.1.x 1.2.x, 1.3.x: Last supported in agent version 6.15.0 Databases The Ruby agent does not support experimental versions. Databases supported by the Ruby agent include: Databases Supported Deprecated ActiveRecord 3.2.x 4.0.x 4.1.x 4.2.x 5.0.x 5.1.x 5.2.x 6.0.x 6.1.x 3.0.x, 3.1.x: Last supported in agent version 6.15.0. 2.1.x, 2.2.x, 2.3.x: Last supported agent was 3.18.1.330. 2.0.x Last supported agent was 3.6.8.168. DataMapper 1.0 Mongo 1.8.x or higher 1.9.x 2.0.x or higher Redis 3.x 4.0.x 4.1.x 4.2.x Sequel 3.37.x 4.0.x 5.5.x or higher Other APM software If your application uses other application performance monitoring (APM) software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors when using other monitoring software. Instance details New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Ruby agent version 3.17.0 or higher supports the following ORM databases: ORM Database Adapter name Minimum agent version ActiveRecord 5 or higher PostgreSQL pg 3.17.0 MySQL mysql2 3.17.0 ActiveRecord 2.1 to 4 PostgreSQL pg 3.17.0 MySQL mysql 3.17.0 MySQL mysql2 3.17.0 The Ruby agent also supports these gem databases: Gem database Gem name Minimum gem version Minimum agent version Memcached Dalli memcached memcache-client 2.7.6 1.8.0 1.5.0 3.17.0 Mongo DB mongo 1.8.6 3.17.0 Redis redis-rb 3.0.7 3.17.0 To request instance-level information from datastores currently not listed for your New Relic agent, get support at support.newrelic.com. Background jobs Background jobs supported by the New Relic Ruby agent include: Background jobs Supported Deprecated Delayed_Job 2.0.x 3.0.x 4.0.x 4.1.x Rake 12.3.3 or higher 13.x 10.x 11.x 12.3.2 or earlier. NOTE: Only 12.3.3 or higher tested due to exploit potential in earlier versions. Resque 1.23.x 1.27.x 2.0.0 or higher 1.22.x and earlier Sidekiq 4.2.x 5.0.x 6.0.x 6.1.x 2.8.x, 3.4.x, 4.0.x, and 4.1.x: Last supported in agent version 6.15.0 HTTP clients HTTP clients supported by the Ruby agent include: Net::HTTP : Supported for all agent-supported versions of Ruby. Curb: 0.8.1 or higher Excon: 0.10.1 or higher HttpClient: 2.2.0 or higher HttpRb: 0.9.9 or higher Typhoeus: 0.5.3 or higher Message queuing Message queue instrumentation is only available with the Ruby agent version 4.3.0 or higher. Currently supported message brokers: RabbitMQ Other APM's Ruby agent also supports: ActiveMerchant:1.25.0 or higher Acts_as_Solr authlogic Bunny: 2.0 or higher Dalli Memcache-Client Sunspot Connect the agent to other parts of New Relic The Ruby agent integrates with other New Relic capabilities to give you end-to-end visibility. Capability Integration Browser monitoring The Ruby agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see the browser and Ruby agent documentation. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in infrastructure monitoring. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.776375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "sections": "<em>Ruby</em> <em>agent</em> requirements and supported frameworks",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Before you install New Relic&#x27;s <em>Ruby</em> <em>agent</em>, make sure you meet these requirements for compatible operating systems, security requirements, and supported frameworks. If you don&#x27;t have one already, <em>start</em> by creating a New Relic account. It&#x27;s free, forever. Operating systems The <em>Ruby</em> <em>agent</em> supports"
      },
      "id": "603ebad028ccbc6835eba79d"
    }
  ],
  "/docs/agents/ruby-agent/getting-started/ruby-agent-requirements-supported-frameworks": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.31685,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " without issues going forward. If you need <em>Ruby</em> 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these <em>Ruby</em> versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The <em>agent</em> fails to initialize and <em>start</em>"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.31097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.5886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Getting</em> <em>started</em>",
        "body": " (recommended) Install docs for rails plugin Add <em>Ruby</em> data Extend <em>agent</em> instrumentation After installing the <em>agent</em>, go further and extend the <em>agent</em>&#x27;s instrumentation: Page load timing: Automatically inject the browser monitoring <em>agent</em> to <em>get</em> visibility into end-user activity. Custom instrumentation"
      },
      "id": "603eb68428ccbcae31eba779"
    }
  ],
  "/docs/agents/ruby-agent/index": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.03649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Ruby agent 7.x to 8.x migration guide",
        "Summary",
        "Changes to the add_method_tracer API method",
        "Metric name parameter accepts Procs; strings no longer interpolated",
        ":code_header and :code_footer parameters accept only Procs",
        "Call add_method_tracer once per method",
        "Distributed Tracing is enabled by default",
        "Cross Application Tracing is deprecated",
        "Tip",
        "Removed deprecated API methods and legacy instrumentation"
      ],
      "title": "Ruby agent 7.x to 8.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "34bc6e2440f16d254dd0bd39a99d99e7028ef541",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-8x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-26T04:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the Ruby agent, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled by default Cross Application Tracing is deprecated Removed deprecated API methods and legacy instrumentation See the milestone for 8.0 for more information. Changes to the add_method_tracer API method Metric name parameter accepts Procs; strings no longer interpolated The second argument to add_method_tracer is the name of the metric used to record calls to the traced method. Previously, this string could include Ruby-style interpolation to allow for the metric name to include variables from the method receiver. For example: # old (<= 7.2) add_method_tracer :foo, ‘metric_#{args[0]}’ Copy As of 8.0, this string will no longer be interpolated. To preserve the behavior described above, pass a Proc instead: # new (8.0+) add_method_tracer :foo, -> (*args) { “metric_#{args[0]}” } # note the double-quotes Copy Note that the arity of the Proc passed to add_method_tracer should match the arity of the original traced method (or use a compatible splat). :code_header and :code_footer parameters accept only Procs Similar to metric names, the :code_header and :code_footer options to add_method_tracer were previously given as strings that would be interpolated in the context of the method receiver. In Ruby Agent 8.0, :code_header and :code_footer will only be invoked if given as Procs, as in the example above. Call add_method_tracer once per method Calling add_method_tracer multiple times on the same method will overwrite any previously defined method tracers for that method. There should be only one add_method_tracer line for each traced method. Previously, the agent allowed adding multiple metrics to the same method by invoking add_method_tracer once for each such metric. This can still be done, but the metric names need to be passed as the second argument of add_method_tracer as an array of strings or procs. # old add_method_tracer :foo, ‘metric1’ add_method_tracer :foo, ‘metric2’, push_scope: false add_method_tracer :foo, ‘metric3’, push_scope: false Copy # new add_method_tracer :foo, [‘metric1’, ‘metric2’, ‘metric3’] Copy Note that the first metric name will be created as a scoped metric unless push_scope: false is specified. The following named metrics will be unscoped. Each traced method may only have one scoped metric. Distributed Tracing is enabled by default The default configuration option for distributed_tracing.enabled is set to true for versions 8.0 or higher. To disable distributed tracing, set this configuration option to false in your newrelic.yml. distributed_tracing: enabled: false Copy Cross Application Tracing is deprecated Cross Application Tracing is deprecated in 8.0 and will be removed in a future release. Tip Distributed tracing and cross application tracing cannot be used simultaneously. If both configuration options are enabled, then only distributed tracing is used. To continue using cross application tracing, settings for both distributed tracing and cross application tracing need to be updated in your newrelic.yml. cross_application_tracing: enabled: true distributed_tracing: enabled: false Copy Removed deprecated API methods and legacy instrumentation The following methods had been previously deprecated and are now removed. Removed Replacement disable_transaction_tracing API method disable_all_tracing or ignore_transaction API methods External.start_segment API method Tracer#start_external_request_segment API method Transaction.wrap API method Tracer#in_transaction API method Mongo < 2.1 instrumentation Upgrade to Mongo 2.1 or higher Excon < 0.19.0 instrumentation Upgrade to Excon 0.19.0 or higher",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.210236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 7.x to 8.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 7.x and 8.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to successfully migrate to version 8.x. The main changes include: Changes to the add_method_tracer API method Distributed Tracing is enabled"
      },
      "id": "61271c8428ccbc2c96f2615c"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 77.19121,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent-gae-flexible-environment": [
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-09-02T03:11:55Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.42981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85263,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent and Heroku",
        "Install the New Relic agent add-on",
        "Via the Heroku website",
        "Via Heroku toolbelt",
        "Non-Rails applications",
        "Troubleshooting your installation",
        "Upgrade from an existing New Relic installation",
        "Configure the Ruby agent on Heroku",
        "Hostnames on Heroku",
        "Dyno hostname aggregation",
        "Logging for Heroku",
        "For more help"
      ],
      "title": "Ruby agent and Heroku",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bdb3ce6ecf86503dc3e3cba3afef294e6851878a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-heroku/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-07-09T12:46:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages, including Ruby. With New Relic, you can extend Heroku using APM and browser monitoring metrics. This page describes special considerations for using Heroku as a hosting service with New Relic's Ruby agent. Install the New Relic agent add-on After deploying your Ruby app on Heroku, install the New Relic agent: Via the Heroku website To install the New Relic add-on through the Heroku website, you must be logged in to Heroku: From Heroku's Add-on page for New Relic, select a subscription plan. From Select an app, select your New Relic app. Give your application a descriptive name with this Heroku toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Via Heroku toolbelt To install the New Relic add-on with the Heroku toolbelt: Run the following toolbelt command, where $planlevel is the appropriate subscription plan: heroku addons:create newrelic:$planlevel Copy Give your application a descriptive name with this toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Non-Rails applications If you are using New Relic's Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic_rpm gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Installing the add-on automatically creates a private New Relic account and configures access for Heroku servers. New Relic will begin monitoring application performance, end user experience, and app server performance collected after the add-on is installed. Within a few minutes, data should start appearing in your APM summary page. Troubleshooting your installation Within a few minutes of installing and configuring New Relic, data should start appearing in your app's APM summary page. If no data appears, follow the Ruby agent troubleshooting procedures. Upgrade from an existing New Relic installation If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Configure the Ruby agent on Heroku You can configure New Relic in your newrelic.yml file, or you can use environment variables to take precedence over the values in your config file. Use heroku config:set to modify the agent's settings for your Heroku appication. For example, to set the analytics_events.max_samples_stored setting to 500: heroku config:set NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED=500 Copy Hostnames on Heroku Knowing which data came from which host allows you to filter the metrics displayed in the UI to a specific host. On Heroku, hostnames within dynos are dynamically generated and not generally meaningful to you as an application developer. Starting in version 3.9.5, the Ruby agent reports the Heroku dyno name as the hostname (for example, web.1). This allows you to view your data scoped to a particular dyno name. You can disable this behavior by setting the heroku.use_dyno_names setting to false. The agent will then use a single aggregated placeholder name called Dynamic Hostname. Dyno hostname aggregation Some dynos have names that are dynamically generated, and these may take on many unique values over time. Examples include scheduler dynos created by the Scheduler add-on, and run dynos created by invoking heroku run on the command line. In order to keep the number of unique hostnames reasonable, the Ruby agent will automatically aggregate data from scheduler and run dynos into hostnames called scheduler.* and run.*. If you have other dyno types that are dynamically created, use the heroku.dyno_name_prefixes_to_shorten configuration setting to apply the same aggregation to these other dyno types. Logging for Heroku On Heroku, the Ruby agent logs to standard output, mixing agent logs with your normal application logs. Log entries generated by the Ruby agent include a [NewRelic] tag as a prefix. To retrieve logs on Heroku: Verify that your NEW_RELIC_LOG environment variable is set to stdout with this Heroku toolbelt command: heroku config Copy To reset the environment variable if necessary, run: heroku config:set NEW_RELIC_LOG=\"stdout\" Copy Open your newrelic.yml file in an editor. Change the log_level to debug and save the file. Be sure you do not modify the indentation. Restart your web app. Generate some traffic to your app and run it for about five minutes. Run the following Heroku toolbelt command to view logs only from the New Relic agent: heroku logs -n 1500 | grep -i relic Copy If sending your log file to New Relic Support, attach the log file to your support ticket, along with newrelic.yml, your Gemfile, and Gemfile.lock. Edit newrelic.yml again, and change the log_level to the previous setting. Save the file. For more help Additional documentation resources include: Heroku and New Relic (additional topics for Heroku users) Heroku Dev Center (information on the Heroku site on installing New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.690414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> and Heroku",
        "sections": "<em>Ruby</em> <em>agent</em> and Heroku",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " and configuring New Relic, data should start appearing in your app&#x27;s APM summary page. If no data appears, follow the <em>Ruby</em> <em>agent</em> troubleshooting procedures. Upgrade from an existing New Relic <em>installation</em> If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set"
      },
      "id": "604404ea28ccbc0dee2c60cf"
    }
  ],
  "/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85263,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent and Heroku",
        "Install the New Relic agent add-on",
        "Via the Heroku website",
        "Via Heroku toolbelt",
        "Non-Rails applications",
        "Troubleshooting your installation",
        "Upgrade from an existing New Relic installation",
        "Configure the Ruby agent on Heroku",
        "Hostnames on Heroku",
        "Dyno hostname aggregation",
        "Logging for Heroku",
        "For more help"
      ],
      "title": "Ruby agent and Heroku",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bdb3ce6ecf86503dc3e3cba3afef294e6851878a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-heroku/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-07-09T12:46:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages, including Ruby. With New Relic, you can extend Heroku using APM and browser monitoring metrics. This page describes special considerations for using Heroku as a hosting service with New Relic's Ruby agent. Install the New Relic agent add-on After deploying your Ruby app on Heroku, install the New Relic agent: Via the Heroku website To install the New Relic add-on through the Heroku website, you must be logged in to Heroku: From Heroku's Add-on page for New Relic, select a subscription plan. From Select an app, select your New Relic app. Give your application a descriptive name with this Heroku toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Via Heroku toolbelt To install the New Relic add-on with the Heroku toolbelt: Run the following toolbelt command, where $planlevel is the appropriate subscription plan: heroku addons:create newrelic:$planlevel Copy Give your application a descriptive name with this toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Non-Rails applications If you are using New Relic's Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic_rpm gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Installing the add-on automatically creates a private New Relic account and configures access for Heroku servers. New Relic will begin monitoring application performance, end user experience, and app server performance collected after the add-on is installed. Within a few minutes, data should start appearing in your APM summary page. Troubleshooting your installation Within a few minutes of installing and configuring New Relic, data should start appearing in your app's APM summary page. If no data appears, follow the Ruby agent troubleshooting procedures. Upgrade from an existing New Relic installation If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Configure the Ruby agent on Heroku You can configure New Relic in your newrelic.yml file, or you can use environment variables to take precedence over the values in your config file. Use heroku config:set to modify the agent's settings for your Heroku appication. For example, to set the analytics_events.max_samples_stored setting to 500: heroku config:set NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED=500 Copy Hostnames on Heroku Knowing which data came from which host allows you to filter the metrics displayed in the UI to a specific host. On Heroku, hostnames within dynos are dynamically generated and not generally meaningful to you as an application developer. Starting in version 3.9.5, the Ruby agent reports the Heroku dyno name as the hostname (for example, web.1). This allows you to view your data scoped to a particular dyno name. You can disable this behavior by setting the heroku.use_dyno_names setting to false. The agent will then use a single aggregated placeholder name called Dynamic Hostname. Dyno hostname aggregation Some dynos have names that are dynamically generated, and these may take on many unique values over time. Examples include scheduler dynos created by the Scheduler add-on, and run dynos created by invoking heroku run on the command line. In order to keep the number of unique hostnames reasonable, the Ruby agent will automatically aggregate data from scheduler and run dynos into hostnames called scheduler.* and run.*. If you have other dyno types that are dynamically created, use the heroku.dyno_name_prefixes_to_shorten configuration setting to apply the same aggregation to these other dyno types. Logging for Heroku On Heroku, the Ruby agent logs to standard output, mixing agent logs with your normal application logs. Log entries generated by the Ruby agent include a [NewRelic] tag as a prefix. To retrieve logs on Heroku: Verify that your NEW_RELIC_LOG environment variable is set to stdout with this Heroku toolbelt command: heroku config Copy To reset the environment variable if necessary, run: heroku config:set NEW_RELIC_LOG=\"stdout\" Copy Open your newrelic.yml file in an editor. Change the log_level to debug and save the file. Be sure you do not modify the indentation. Restart your web app. Generate some traffic to your app and run it for about five minutes. Run the following Heroku toolbelt command to view logs only from the New Relic agent: heroku logs -n 1500 | grep -i relic Copy If sending your log file to New Relic Support, attach the log file to your support ticket, along with newrelic.yml, your Gemfile, and Gemfile.lock. Edit newrelic.yml again, and change the log_level to the previous setting. Save the file. For more help Additional documentation resources include: Heroku and New Relic (additional topics for Heroku users) Heroku Dev Center (information on the Heroku site on installing New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.690414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> and Heroku",
        "sections": "<em>Ruby</em> <em>agent</em> and Heroku",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " and configuring New Relic, data should start appearing in your app&#x27;s APM summary page. If no data appears, follow the <em>Ruby</em> <em>agent</em> troubleshooting procedures. Upgrade from an existing New Relic <em>installation</em> If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set"
      },
      "id": "604404ea28ccbc0dee2c60cf"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-09-02T05:52:35Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.63939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-heroku": [
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-09-02T03:11:55Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.42981,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85263,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Update the Ruby agent",
        "Verify your Ruby agent versions",
        "Update the agent",
        "Instrument JRuby",
        "Ruby agent versions not supported",
        "Update unsupported agent versions",
        "Important"
      ],
      "title": "Update the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "3248580dc4c2039ed569a158783912ea23ef1fc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/update-ruby-agent/",
      "published_at": "2021-09-02T05:52:35Z",
      "updated_at": "2021-04-28T05:21:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To take full advantage of New Relic's latest features, enhancements, and important security patches, we recommend you update your Ruby agent to the latest version. For additional information about specific agent updates, refer to the Ruby agent release notes. Verify your Ruby agent versions To determine which Ruby agent versions your apps currently use: In New Relic, from the account dropdown, select Account settings > Connected agents. Optional: Sort by Oldest agent version. Update the agent To update the Ruby agent: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using Bundler: Run this command: gem update newrelic_rpm Copy Instrument JRuby For correct instrumentation: With JRuby versions 1.7 or higher, use New Relic Ruby agent version 3.6.8.164 to 3.18.1. With JRuby versions 9 or higher, use New Relic Ruby agent version 3.6.8.164 or higher. Otherwise, if your application has no transactions and you are using JRuby, you will not be able to see your CPU metrics. This was due to a bug in JRuby, where Process.times returned wall-clock time instead of elapsed CPU time. That bug was fixed as of New Relic’s Ruby agent 3.6.8.164 and JRuby 1.7.0. Ruby agent versions not supported End of life notification: As of January 26, 2015, New Relic will no longer accept data from Ruby agent versions earlier than 3.9.6. These agent versions use an out-of-date protocol when communicating with New Relic's data collection services. In addition, many of these versions contain a potential security issue where they may incorrectly send sensitive data to the New Relic collector. Update unsupported agent versions Important If you are updating from an older agent version, including major version jumps, review the following list for changes in functionality. Migration Comments From version 6 to 7 Release notes: Ruby agent 7.0.0 Please see our Ruby Agent 6.x to 7.x migration guide for helpful strategies and tips for migrating from earlier versions of the Ruby agent to 7.0.0. We cover new configuration settings, diagnosiing and installing SSL CA certificates and deprecated items and their replacements in this guide. Ruby 2.0 and 2.1 dropped Implemented prepend auto-instrumentation strategies for most Ruby gems/libraries Removed SSL cert bundle Removed various deprecated config options From version 5 to 6 Release notes: Ruby agent 6.0.0.351 With the addition of the Tracer API for flexible custom instrumentation, several APIs were deprecated. If used, they need to be updated. For more information, see Ruby custom instrumentation. From version 4 to 5 Release notes: Ruby agent 5.0.0.342 SSL connections to New Relic are now mandatory. From version 3 to 4 Release notes: Ruby agent 4.0.0.332 The agent no longer supports Ruby versions prior to 2.0, JRuby 1.7 and earlier, and all versions of Rubinius. Deprecated API calls For a list of deprecated API calls and their replacements, see Update deprecated API calls.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.63939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Update the <em>Ruby</em> <em>agent</em>",
        "sections": "Update the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " To determine which <em>Ruby</em> <em>agent</em> versions your apps currently use: In New Relic, from the account dropdown, select Account settings &gt; Connected <em>agents</em>. Optional: Sort by Oldest <em>agent</em> version. Update the <em>agent</em> To update the <em>Ruby</em> <em>agent</em>: Using Bundler: Run this command: bundle update newrelic_rpm Copy Not using"
      },
      "id": "603eb7db64441f83f84e88b1"
    }
  ],
  "/docs/agents/ruby-agent/installation/ruby-agent-installation-rails-plugin": [
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-09-02T03:11:55Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.4298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent and Heroku",
        "Install the New Relic agent add-on",
        "Via the Heroku website",
        "Via Heroku toolbelt",
        "Non-Rails applications",
        "Troubleshooting your installation",
        "Upgrade from an existing New Relic installation",
        "Configure the Ruby agent on Heroku",
        "Hostnames on Heroku",
        "Dyno hostname aggregation",
        "Logging for Heroku",
        "For more help"
      ],
      "title": "Ruby agent and Heroku",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bdb3ce6ecf86503dc3e3cba3afef294e6851878a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-heroku/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-07-09T12:46:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages, including Ruby. With New Relic, you can extend Heroku using APM and browser monitoring metrics. This page describes special considerations for using Heroku as a hosting service with New Relic's Ruby agent. Install the New Relic agent add-on After deploying your Ruby app on Heroku, install the New Relic agent: Via the Heroku website To install the New Relic add-on through the Heroku website, you must be logged in to Heroku: From Heroku's Add-on page for New Relic, select a subscription plan. From Select an app, select your New Relic app. Give your application a descriptive name with this Heroku toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Via Heroku toolbelt To install the New Relic add-on with the Heroku toolbelt: Run the following toolbelt command, where $planlevel is the appropriate subscription plan: heroku addons:create newrelic:$planlevel Copy Give your application a descriptive name with this toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Non-Rails applications If you are using New Relic's Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic_rpm gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Installing the add-on automatically creates a private New Relic account and configures access for Heroku servers. New Relic will begin monitoring application performance, end user experience, and app server performance collected after the add-on is installed. Within a few minutes, data should start appearing in your APM summary page. Troubleshooting your installation Within a few minutes of installing and configuring New Relic, data should start appearing in your app's APM summary page. If no data appears, follow the Ruby agent troubleshooting procedures. Upgrade from an existing New Relic installation If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Configure the Ruby agent on Heroku You can configure New Relic in your newrelic.yml file, or you can use environment variables to take precedence over the values in your config file. Use heroku config:set to modify the agent's settings for your Heroku appication. For example, to set the analytics_events.max_samples_stored setting to 500: heroku config:set NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED=500 Copy Hostnames on Heroku Knowing which data came from which host allows you to filter the metrics displayed in the UI to a specific host. On Heroku, hostnames within dynos are dynamically generated and not generally meaningful to you as an application developer. Starting in version 3.9.5, the Ruby agent reports the Heroku dyno name as the hostname (for example, web.1). This allows you to view your data scoped to a particular dyno name. You can disable this behavior by setting the heroku.use_dyno_names setting to false. The agent will then use a single aggregated placeholder name called Dynamic Hostname. Dyno hostname aggregation Some dynos have names that are dynamically generated, and these may take on many unique values over time. Examples include scheduler dynos created by the Scheduler add-on, and run dynos created by invoking heroku run on the command line. In order to keep the number of unique hostnames reasonable, the Ruby agent will automatically aggregate data from scheduler and run dynos into hostnames called scheduler.* and run.*. If you have other dyno types that are dynamically created, use the heroku.dyno_name_prefixes_to_shorten configuration setting to apply the same aggregation to these other dyno types. Logging for Heroku On Heroku, the Ruby agent logs to standard output, mixing agent logs with your normal application logs. Log entries generated by the Ruby agent include a [NewRelic] tag as a prefix. To retrieve logs on Heroku: Verify that your NEW_RELIC_LOG environment variable is set to stdout with this Heroku toolbelt command: heroku config Copy To reset the environment variable if necessary, run: heroku config:set NEW_RELIC_LOG=\"stdout\" Copy Open your newrelic.yml file in an editor. Change the log_level to debug and save the file. Be sure you do not modify the indentation. Restart your web app. Generate some traffic to your app and run it for about five minutes. Run the following Heroku toolbelt command to view logs only from the New Relic agent: heroku logs -n 1500 | grep -i relic Copy If sending your log file to New Relic Support, attach the log file to your support ticket, along with newrelic.yml, your Gemfile, and Gemfile.lock. Edit newrelic.yml again, and change the log_level to the previous setting. Save the file. For more help Additional documentation resources include: Heroku and New Relic (additional topics for Heroku users) Heroku Dev Center (information on the Heroku site on installing New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.69041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> and Heroku",
        "sections": "<em>Ruby</em> <em>agent</em> and Heroku",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " and configuring New Relic, data should start appearing in your app&#x27;s APM summary page. If no data appears, follow the <em>Ruby</em> <em>agent</em> troubleshooting procedures. Upgrade from an existing New Relic <em>installation</em> If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set"
      },
      "id": "604404ea28ccbc0dee2c60cf"
    }
  ],
  "/docs/agents/ruby-agent/installation/uninstall-ruby-agent": [
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-09-02T03:11:55Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.4298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent and Heroku",
        "Install the New Relic agent add-on",
        "Via the Heroku website",
        "Via Heroku toolbelt",
        "Non-Rails applications",
        "Troubleshooting your installation",
        "Upgrade from an existing New Relic installation",
        "Configure the Ruby agent on Heroku",
        "Hostnames on Heroku",
        "Dyno hostname aggregation",
        "Logging for Heroku",
        "For more help"
      ],
      "title": "Ruby agent and Heroku",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bdb3ce6ecf86503dc3e3cba3afef294e6851878a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-heroku/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-07-09T12:46:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages, including Ruby. With New Relic, you can extend Heroku using APM and browser monitoring metrics. This page describes special considerations for using Heroku as a hosting service with New Relic's Ruby agent. Install the New Relic agent add-on After deploying your Ruby app on Heroku, install the New Relic agent: Via the Heroku website To install the New Relic add-on through the Heroku website, you must be logged in to Heroku: From Heroku's Add-on page for New Relic, select a subscription plan. From Select an app, select your New Relic app. Give your application a descriptive name with this Heroku toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Via Heroku toolbelt To install the New Relic add-on with the Heroku toolbelt: Run the following toolbelt command, where $planlevel is the appropriate subscription plan: heroku addons:create newrelic:$planlevel Copy Give your application a descriptive name with this toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Non-Rails applications If you are using New Relic's Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic_rpm gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Installing the add-on automatically creates a private New Relic account and configures access for Heroku servers. New Relic will begin monitoring application performance, end user experience, and app server performance collected after the add-on is installed. Within a few minutes, data should start appearing in your APM summary page. Troubleshooting your installation Within a few minutes of installing and configuring New Relic, data should start appearing in your app's APM summary page. If no data appears, follow the Ruby agent troubleshooting procedures. Upgrade from an existing New Relic installation If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Configure the Ruby agent on Heroku You can configure New Relic in your newrelic.yml file, or you can use environment variables to take precedence over the values in your config file. Use heroku config:set to modify the agent's settings for your Heroku appication. For example, to set the analytics_events.max_samples_stored setting to 500: heroku config:set NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED=500 Copy Hostnames on Heroku Knowing which data came from which host allows you to filter the metrics displayed in the UI to a specific host. On Heroku, hostnames within dynos are dynamically generated and not generally meaningful to you as an application developer. Starting in version 3.9.5, the Ruby agent reports the Heroku dyno name as the hostname (for example, web.1). This allows you to view your data scoped to a particular dyno name. You can disable this behavior by setting the heroku.use_dyno_names setting to false. The agent will then use a single aggregated placeholder name called Dynamic Hostname. Dyno hostname aggregation Some dynos have names that are dynamically generated, and these may take on many unique values over time. Examples include scheduler dynos created by the Scheduler add-on, and run dynos created by invoking heroku run on the command line. In order to keep the number of unique hostnames reasonable, the Ruby agent will automatically aggregate data from scheduler and run dynos into hostnames called scheduler.* and run.*. If you have other dyno types that are dynamically created, use the heroku.dyno_name_prefixes_to_shorten configuration setting to apply the same aggregation to these other dyno types. Logging for Heroku On Heroku, the Ruby agent logs to standard output, mixing agent logs with your normal application logs. Log entries generated by the Ruby agent include a [NewRelic] tag as a prefix. To retrieve logs on Heroku: Verify that your NEW_RELIC_LOG environment variable is set to stdout with this Heroku toolbelt command: heroku config Copy To reset the environment variable if necessary, run: heroku config:set NEW_RELIC_LOG=\"stdout\" Copy Open your newrelic.yml file in an editor. Change the log_level to debug and save the file. Be sure you do not modify the indentation. Restart your web app. Generate some traffic to your app and run it for about five minutes. Run the following Heroku toolbelt command to view logs only from the New Relic agent: heroku logs -n 1500 | grep -i relic Copy If sending your log file to New Relic Support, attach the log file to your support ticket, along with newrelic.yml, your Gemfile, and Gemfile.lock. Edit newrelic.yml again, and change the log_level to the previous setting. Save the file. For more help Additional documentation resources include: Heroku and New Relic (additional topics for Heroku users) Heroku Dev Center (information on the Heroku site on installing New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.69041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> and Heroku",
        "sections": "<em>Ruby</em> <em>agent</em> and Heroku",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " and configuring New Relic, data should start appearing in your app&#x27;s APM summary page. If no data appears, follow the <em>Ruby</em> <em>agent</em> troubleshooting procedures. Upgrade from an existing New Relic <em>installation</em> If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set"
      },
      "id": "604404ea28ccbc0dee2c60cf"
    }
  ],
  "/docs/agents/ruby-agent/installation/update-ruby-agent": [
    {
      "sections": [
        "Install the New Relic Ruby agent",
        "Install the gem",
        "Important",
        "Install the configuration file",
        "Update the agent",
        "Install agent outside production environments",
        "Uninstall the Ruby agent gem",
        "Install on older versions of Rails"
      ],
      "title": "Install the New Relic Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "5550d694861d682735dc54a8582d2df311b05fc8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/install-new-relic-ruby-agent/",
      "published_at": "2021-09-02T03:11:55Z",
      "updated_at": "2021-08-08T04:45:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Ruby agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic Ruby agent installation. Add Ruby data Install the gem Important If you are using the agent in a Docker container, install the agent within each container. The Ruby agent's gem is available from rubygems.org as newrelic_rpm. For applications using Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy To use Infinite Tracing, the Infinite Tracing gem is also available from rubygems.org as newrelic-infinite_tracing. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy The next step varies depending on if you are using Rails or Sinatra: Ruby installation Comments If using Rails or Sinatra Rails: If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic_rpm to be required during startup of your application. Sinatra: If you're using Sinatra or another framework, you must manually call require 'newrelic_rpm'. Additionally, if you're using Infinite Tracing, manually call require 'newrelic/infinite_tracing'. Alternately, manually call Bundler.require, which also enables Infinite Tracing. If not using Rails or Sinatra In order to use automatic browser application monitoring and Cross application tracing in a Rack application that does not use Sinatra or Rails, you must manually include additional Rack middlewares provided by the agent. Place the New Relic gem as low in the list as possible, allowing the frameworks above it to be instrumented when the gem initializes. Install the configuration file After installing the agent, you will need to install the newrelic.yml configuration file, and name your app: If you haven't already, create a New Relic account. It's free, forever. Or, sign in. From the account dropdown, select Account settings. On the Account settings page, look for the Download a clean configuration file section and click the newrelic.yml file. Copy the newrelic.yml file into the config sub-directory of your application. Change the default application name to a meaningful name. Alternatively, you can generate a newrelic.yml file manually with the following command: newrelic install --license_key=\"YOUR_KEY\" \"My application\" Copy You may also use the --force option with this command if you need to overwrite an existing newrelic.yml. Update the agent See Upgrade Ruby agent versions. Install agent outside production environments Typically you will install the Ruby agent in your production environment. If you want to try out the Ruby agent in a development or localhost environment, verify in the relevant environment: block of the newrelic.yml file that the monitor_mode config value has been set to true. For example, to deploy New Relic in your development environment and still be able to view your app's performance metrics: In the development: block, set the monitor_mode config value to true. Uninstall the Ruby agent gem To uninstall the Ruby agent using Bundler, remove gem 'newrelic_rpm' from your Gemfile. If you are not using Bundler, remove all references to newrelic_rpm from your environment.rb file. Install on older versions of Rails If you're installing the Ruby agent on Rails 2.x, and aren't using Bundler, follow these procedures. Ruby installation Comments Rails 2.1 - 2.3 without Bundler Install the gem using gem install newrelic_rpm. Edit environment.rb, and add to the initializer block: config.gem \"newrelic_rpm\" Copy If enabling Infinite Tracing, add the following to the next line in the environment.rb file: config.gem \"newrelic-infinite_tracing\" Copy Rails earlier than 2.1 New Relic does not officially support Rails versions prior to 2.1. However, if you want to use New Relic for Rails versions 2.0. * , edit environment.rb and add this statement after the initializer: block: require \"newrelic_rpm\" Copy Infinite Tracing If enabling Infinite Tracing, add the following to the next line in the environment.rb file: require \"newrelic/infinite_tracing\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.429794,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "sections": "<em>Install</em> the New Relic <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Our <em>Ruby</em> <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic <em>Ruby</em> <em>agent</em> <em>installation</em>. Add <em>Ruby</em> data Install the gem Important If you are using the <em>agent</em> in a Docker container, install"
      },
      "id": "603eb684e7b9d2d6fb2a07d3"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-09-01T21:29:27Z",
      "updated_at": "2021-09-01T21:29:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.85252,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language <em>agents</em> and distributed tracing",
        "sections": "Language <em>agents</em> and distributed tracing",
        "body": ": <em>Ruby</em> 2.5 or higher Configure standard distributed tracing for your older <em>agents</em> Distributed tracing is enabled through configuration settings. Review the following <em>agent</em>-specific sections. For general help with <em>agent</em> configurations, see Configure the <em>agent</em>. Important Server-side configuration"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Ruby agent and Heroku",
        "Install the New Relic agent add-on",
        "Via the Heroku website",
        "Via Heroku toolbelt",
        "Non-Rails applications",
        "Troubleshooting your installation",
        "Upgrade from an existing New Relic installation",
        "Configure the Ruby agent on Heroku",
        "Hostnames on Heroku",
        "Dyno hostname aggregation",
        "Logging for Heroku",
        "For more help"
      ],
      "title": "Ruby agent and Heroku",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "bdb3ce6ecf86503dc3e3cba3afef294e6851878a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/ruby-agent-heroku/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-07-09T12:46:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Heroku is a Platform as a Service (PaaS) solution for hosting web applications in various agent languages, including Ruby. With New Relic, you can extend Heroku using APM and browser monitoring metrics. This page describes special considerations for using Heroku as a hosting service with New Relic's Ruby agent. Install the New Relic agent add-on After deploying your Ruby app on Heroku, install the New Relic agent: Via the Heroku website To install the New Relic add-on through the Heroku website, you must be logged in to Heroku: From Heroku's Add-on page for New Relic, select a subscription plan. From Select an app, select your New Relic app. Give your application a descriptive name with this Heroku toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Via Heroku toolbelt To install the New Relic add-on with the Heroku toolbelt: Run the following toolbelt command, where $planlevel is the appropriate subscription plan: heroku addons:create newrelic:$planlevel Copy Give your application a descriptive name with this toolbelt command: heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Add the New Relic gem to your Gemfile. The New Relic Ruby agent's gem is available from rubygems.org as newrelic_rpm. If your app uses Bundler, add this gem to the Gemfile: gem 'newrelic_rpm' Copy Restart your dyno. Generate some traffic to your app. Non-Rails applications If you are using New Relic's Ruby agent with a non-Rails application, Heroku users need to install the plugin in your repository manually. For example, in a Sinatra app, add the newrelic_rpm gem to your Gemfile, and then add the following code to your app: configure :production do require 'newrelic_rpm' end Copy Installing the add-on automatically creates a private New Relic account and configures access for Heroku servers. New Relic will begin monitoring application performance, end user experience, and app server performance collected after the add-on is installed. Within a few minutes, data should start appearing in your APM summary page. Troubleshooting your installation Within a few minutes of installing and configuring New Relic, data should start appearing in your app's APM summary page. If no data appears, follow the Ruby agent troubleshooting procedures. Upgrade from an existing New Relic installation If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set NEW_RELIC_APP_NAME='Your Application Name' Copy Configure the Ruby agent on Heroku You can configure New Relic in your newrelic.yml file, or you can use environment variables to take precedence over the values in your config file. Use heroku config:set to modify the agent's settings for your Heroku appication. For example, to set the analytics_events.max_samples_stored setting to 500: heroku config:set NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED=500 Copy Hostnames on Heroku Knowing which data came from which host allows you to filter the metrics displayed in the UI to a specific host. On Heroku, hostnames within dynos are dynamically generated and not generally meaningful to you as an application developer. Starting in version 3.9.5, the Ruby agent reports the Heroku dyno name as the hostname (for example, web.1). This allows you to view your data scoped to a particular dyno name. You can disable this behavior by setting the heroku.use_dyno_names setting to false. The agent will then use a single aggregated placeholder name called Dynamic Hostname. Dyno hostname aggregation Some dynos have names that are dynamically generated, and these may take on many unique values over time. Examples include scheduler dynos created by the Scheduler add-on, and run dynos created by invoking heroku run on the command line. In order to keep the number of unique hostnames reasonable, the Ruby agent will automatically aggregate data from scheduler and run dynos into hostnames called scheduler.* and run.*. If you have other dyno types that are dynamically created, use the heroku.dyno_name_prefixes_to_shorten configuration setting to apply the same aggregation to these other dyno types. Logging for Heroku On Heroku, the Ruby agent logs to standard output, mixing agent logs with your normal application logs. Log entries generated by the Ruby agent include a [NewRelic] tag as a prefix. To retrieve logs on Heroku: Verify that your NEW_RELIC_LOG environment variable is set to stdout with this Heroku toolbelt command: heroku config Copy To reset the environment variable if necessary, run: heroku config:set NEW_RELIC_LOG=\"stdout\" Copy Open your newrelic.yml file in an editor. Change the log_level to debug and save the file. Be sure you do not modify the indentation. Restart your web app. Generate some traffic to your app and run it for about five minutes. Run the following Heroku toolbelt command to view logs only from the New Relic agent: heroku logs -n 1500 | grep -i relic Copy If sending your log file to New Relic Support, attach the log file to your support ticket, along with newrelic.yml, your Gemfile, and Gemfile.lock. Edit newrelic.yml again, and change the log_level to the previous setting. Save the file. For more help Additional documentation resources include: Heroku and New Relic (additional topics for Heroku users) Heroku Dev Center (information on the Heroku site on installing New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.69041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> and Heroku",
        "sections": "<em>Ruby</em> <em>agent</em> and Heroku",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " and configuring New Relic, data should start appearing in your app&#x27;s APM summary page. If no data appears, follow the <em>Ruby</em> <em>agent</em> troubleshooting procedures. Upgrade from an existing New Relic <em>installation</em> If New Relic is already installed, reinstall the add-on using the Heroku toolbelt command. heroku config:set"
      },
      "id": "604404ea28ccbc0dee2c60cf"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/rack-middlewares": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72269,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-09-02T05:50:21Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/redis-instrumentation": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.25209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Sinatra instrumentation",
        "Contents",
        "Getting started",
        "Middleware installation",
        "Ignoring routes",
        "Padrino",
        "Shotgun (not supported)"
      ],
      "title": "Sinatra instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "97ce5f5307e5c41049d2daf7c08d9eb741f27f47",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T07:57:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Ruby agent works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked as separate actions. Contents Getting started To set up Sinatra: Install the latest newrelic_rpm gem. In your Sinatra app, immediately below the Sinatra require directive, add: require 'newrelic_rpm' Copy Set RACK_ENV to the environment corresponding to the configuration definitions in your newrelic.yml file; for example, development, staging, production, etc. Note: Developer mode only works with Rails. Middleware installation Ruby agent versions prior to 3.6.3 required manual addition of New Relic middlewares to enable certain features, such as cross application tracing and browser monitoring. For more information about required middlewares, see Rack middlewares, or upgrade to the most recent Ruby agent. Ignoring routes Ruby agent versions 3.6.3 or higher support ignoring certain routes, similar to what was previously available in Rails controller instrumentation. To specify these values, use the same style of routes that you use to define your Sinatra application. For example, to ignore a ping route in a Sinatra app, include the following code in the app: newrelic_ignore '/ping' get '/ping' do # ... end Copy If you want an entire application to be ignored (for example, in a mounted application), call newrelic_ignore without parameters: newrelic_ignore Copy Additionally, newrelic_ignore_apdex and newrelic_ignore_enduser are supported. The newrelic_ignore_apdex call will exclude a given route from consideration in overall Apdex calculations. The newrelic_ignore_enduser call will prevent automatic injection of the page load timing JavaScript when a route is rendered. Padrino Padrino is a framework built on top of Sinatra. Starting with Ruby agent version 3.6.3, New Relic's Sinatra instrumentation works with Padrino versions 0.10.x or higher. Shotgun (not supported) The New Relic Ruby agent will not work with shotgun. It cannot make a connection before the dispatcher process exits. Neither Developer mode nor Monitor mode will work.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.68298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Sinatra <em>instrumentation</em>",
        "sections": "Sinatra <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "New Relic&#x27;s <em>Ruby</em> <em>agent</em> works with Sinatra 1.2.x or higher. In the New Relic UI, the Sinatra actions appear similar to controller actions. The actions in the UI correspond to the pattern expression used to match them. HTTP operations are not distinguished. Multiple matches are all tracked"
      },
      "id": "603ebc9928ccbc1046eba786"
    }
  ],
  "/docs/agents/ruby-agent/instrumented-gems/sinatra-instrumentation": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.72266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " detection mechanism to identify conflicting external <em>gems</em> and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other <em>gems</em> to make changes to their <em>gem</em> libraries in order to facilitate using the <em>Ruby</em> <em>agent</em> in conjunction"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Rack middlewares",
        "Rack instrumentation",
        "Rack::Builder",
        "Rails middlewares",
        "Viewing middleware data",
        "In the APM Summary page",
        "In the APM Transactions page",
        "In APM transaction trace summary",
        "Disabling Rack instrumentation",
        "Installing Ruby agent middlewares manually",
        "Manual Rack instrumentation"
      ],
      "title": "Rack middlewares",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "fa34ef9ebcf8904e3601568b15d53bfe825424f4",
      "image": "https://docs.newrelic.com/static/6a0f3d54778590afddb09dde98b4773e/c1b63/web_transactions.png",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/instrumented-gems/rack-middlewares/",
      "published_at": "2021-09-02T04:35:52Z",
      "updated_at": "2021-07-09T15:20:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent automatically instruments Rack middlewares. If you are unfamiliar with the basics of Rack middlewares, review the resources linked by the Rails on Rack guide. Additionally, the Ruby agent provides some features via Rack middlewares: Cross application traces Auto-instrumentation for browser monitoring New Relic automatically installs these middlewares for Rails and Sinatra. Rack instrumentation The two most common ways to configure Rack middlewares are the Rack::Builder API (most often from config.ru) and Rails' middleware stack configuration: Rack::Builder Middlewares in your config.ru file are configured using Rack::Builder. For the Ruby agent to instrument middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack gem. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class (ActionDispatch::MiddlewareStack) instead of Rack::Builder to configure middlewares. Even if you haven't explicitly added middlewares to your Rails application, many components of Rails itself are implemented as middleware, so middleware data will appear by default. The Ruby agent automatically instruments middlewares added via ActionDispatch::MiddlewareStack on Rails 3.0 or higher. For more information about configuring middlewares with Rails, see the Ruby on Rails guide. Viewing middleware data You can view middleware data in APM. In the APM Summary page The main chart on your app's APM Summary page includes a purple bar that shows average time per request spent in all Rack middlewares for your application. APM > (selected application) > Summary: Middleware time appears in purple on your app's main Overview chart. In the APM Transactions page You can also see time for individual middlewares for a specific transaction name from your app's APM Transactions page. APM > (selected application) > Monitor > Transactions > (selected transaction) > Trace details: Here is an example of middleware time for a selected transaction for your app. In APM transaction trace summary Transaction traces also capture detailed middleware call information. APM > (selected application) > Monitor > Transactions > (selected transaction trace): Here is an example of middleware details in a transaction trace. Disabling Rack instrumentation If you do not want to instrument Rack middlewares, you may disable Rack middleware instrumentation with the disable_middleware_instrumentation setting. You can also ignore specific transactions. Installing Ruby agent middlewares manually The Ruby agent's implementation of New Relic's Cross Application Tracing feature uses Rack middleware instrumentation to read and write HTTP headers that are necessary to pass information between monitored applications. If you have disabled middleware instrumentation as described above and want to use cross application tracing, you must manually add the NewRelic::Rack::AgentHooks middleware to your middleware stack. For more information, see Cross application tracing in Ruby. Manual Rack instrumentation Earlier versions of the Ruby agent supported manually instrumenting Rack middlewares via the NewRelic::Agent::Instrumentation::Rack module. This instrumentation is deprecated in Ruby agent versions 3.9.0 or higher, because it is unnecessary with automatic middleware instrumentation. New Relic recommends that you remove references to this module from your code after upgrading to 3.9.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.25209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installing <em>Ruby</em> <em>agent</em> middlewares manually",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": " config.ru file are configured using Rack::Builder. For the <em>Ruby</em> <em>agent</em> to <em>instrument</em> middlewares from Rack::Builder, your app must run version 1.1.0 or higher of the rack <em>gem</em>. This is the most common use of middlewares with Sinatra or pure-rack applications. Rails middlewares Rails uses its own class"
      },
      "id": "603ebc9ae7b9d2754a2a0810"
    },
    {
      "sections": [
        "Mongo instrumentation",
        "Contents",
        "Supported gems",
        "Third-party and rpm_contrib instrumentation",
        "Disabling instrumentation",
        "For more help"
      ],
      "title": "Mongo instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Instrumented gems"
      ],
      "external_id": "140273418eb46eab0e42622805c8585f81db9cd4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/frameworks/mongo-instrumentation/",
      "published_at": "2021-09-02T05:50:21Z",
      "updated_at": "2021-03-16T06:42:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Ruby agent has built-in instrumentation for MongoDB queries made via the mongo gem. Contents Supported gems This summarizes the Ruby agent's support for gems by version. Gem version Comments mongo 1.8 and 1.9 Supported by New Relic's Ruby agent 3.7.1 or higher mongo 2.0 Not supported mongo 2.1 or higher Requires New Relic's Ruby agent 3.13.1 or higher Other gems Support for Mongoid 2/3/4 and Moped currently is available only via third-party gems. For links to the relevant projects, see the plugin list on rpm_contrib. Third-party and rpm_contrib instrumentation The rpm_contrib and newrelic_mongo gems both provided basic instrumentation for mongo. New Relic does not recommend running Mongo instrumentation via these gems alongside the Ruby agent's built-in Mongo support. This might double-count metrics such as overall database time. Also, the rpm_contrib and newrelic_mongo gems both use a distinct setting that can be used to disable them if removing those gems entirely isn't possible in your environment. For those third party gems, set disable_mongodb: false in your newrelic.yml. Disabling instrumentation To disable Mongo instrumentation in the agent, add the following to your newrelic.yml: disable_mongo: true Copy For more help Additional documentation resources include: New Relic for Ruby (compatibility and requirements, general information about installation, configuration, troubleshooting, and known issues) Ruby agent installation (using the New Relic Ruby gem and configuration file)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.26926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Mongo <em>instrumentation</em>",
        "sections": "Mongo <em>instrumentation</em>",
        "tags": "<em>Instrumented</em> <em>gems</em>",
        "body": "The <em>Ruby</em> <em>agent</em> has built-in instrumentation for MongoDB queries made via the mongo <em>gem</em>. Contents Supported <em>gems</em> This summarizes the <em>Ruby</em> <em>agent</em>&#x27;s support for <em>gems</em> by version. <em>Gem</em> version Comments mongo 1.8 and 1.9 Supported by New Relic&#x27;s <em>Ruby</em> <em>agent</em> 3.7.1 or higher mongo 2.0 Not supported mongo 2.1"
      },
      "id": "603ebcd0e7b9d2b7862a07e6"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/control-when-ruby-agent-starts": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.930756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.216324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/generating-logs-troubleshooting-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.930756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/incompatible-gems": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.930756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Uninstall the Ruby agent",
        "For more help"
      ],
      "title": "Uninstall the Ruby agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Installation"
      ],
      "external_id": "b92596a58ce64fd42a0349b0a3e0e07483122cb6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/installation/uninstall-ruby-agent/",
      "published_at": "2021-09-02T05:51:26Z",
      "updated_at": "2021-03-13T02:18:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how to uninstall the New Relic Ruby agent. For instructions on how to temporarily disable the agent, see Disable the agent. To uninstall the Ruby agent: Delete the line gem 'newrelic_rpm' from your Gemfile. Remove the newrelic.yml file from your RAILS_ROOT/config/ folder. Run bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for Ruby. For more help Additional documentation resources include: Troubleshooting the Ruby agent (a library of troubleshooting solutions for your Ruby application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.14956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "sections": "Uninstall the <em>Ruby</em> <em>agent</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " bundle install. When the uninstall process finishes, restart your app. For more information about installation, see New Relic for <em>Ruby</em>. For more help Additional documentation resources include: <em>Troubleshooting</em> the <em>Ruby</em> <em>agent</em> (a library of <em>troubleshooting</em> solutions for your <em>Ruby</em> application)"
      },
      "id": "604404ec64441f7a8b378f3c"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-appears-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14639,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-data-unicorn": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14639,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/no-log-file-ruby": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.2163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/not-installing-new-relic-supported-grape": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.2163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/passenger-troubleshooting": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.2163,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/ruby-agent-audit-log": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/systemstackerror-stack-level-too-deep": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.14633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-deprecated-api-calls": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.1463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/agents/ruby-agent/troubleshooting/update-private-api-calls-public-tracer-api": [
    {
      "sections": [
        "Ruby agent 6.x to 7.x migration guide",
        "Summary",
        "Support for Ruby 2.0 and 2.1 is dropped",
        "Prepend instrumentation configuration",
        "Tip",
        "Modernized auto-instrumentation strategy",
        "The SSL Certificate bundle is removed",
        "Deprecated API's and configuration attributes",
        "Denied and allowed lists enabled",
        "Active Record",
        "httpResponseCode",
        "Notice Error (trace_only)",
        "Distributed Tracing APIs"
      ],
      "title": "Ruby agent 6.x to 7.x migration guide",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "ff363737ba54f9b1c6e2a7ea3a897d8af909fe08",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/migration-7x-guide/",
      "published_at": "2021-09-02T04:20:43Z",
      "updated_at": "2021-08-27T04:57:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the Ruby agent, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for Ruby 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs that were deprecated in various 6.x releases are now removed Auto-instrumentation defaults to prepend over method chaining Auto-instrumentation gets consistent configuration attributes See the milestone for 7.0 target release for more information. Support for Ruby 2.0 and 2.1 is dropped Ruby 2.0 and 2.1 reached EOL in February 2016, and New Relic is following suit with dropping support for these versions in the 7.0 release. There are no known changes that would inherently prevent these versions from continuing to work, but we are no longer guaranteeing the Ruby agent continues to function without issues going forward. If you need Ruby 2.0 or 2.1, then continue to use 6.15.0, which is the last release published to support these Ruby versions. Prepend instrumentation configuration Relevant pull request: Prepend instrumentation #565. Potential issue: The agent fails to initialize and start reporting data. A stack level too deep error message is reported in the logs. Solution: Our configuration and dependency detection mechanism can now be controlled through configuration. By default all auto-instrumented gems/libraries are activated with the prepend strategy. The default configuration setting for these libraries in the absence of any settings appearing in the configuration file is auto, which will pick the best strategy. In the case of a known conflict with prepend strategies, auto instructs the agent to fall back to method-chaining when such conflicts are detected. Below is a complete explanation of our changes to the configuration section for auto-instrumentation using sidekiq as an example. instrumentation: sidekiq: chain Copy Tip The use case for this is when an unknown gem is found to be conflicting. The user is able to revert to method-chaining to deal with the conflict until the agent can be updated to auto-detect and handle the conflict. To disable instrumentation altogether: instrumentation: sidekiq: disable Copy In some cases, we may know specific gems conflict with prepend. To facilitate, we offer by default an auto config option, which automatically degrades to chain in such cases. The default setting in most cases is thus: instrumentation: sidekiq: auto Copy It's possible to force using prepend strategy by specifying it in the config file: instrumentation: sidekiq: prepend Copy Tip The use case for this is when a newer version of the conflicting gem is released and it's known to no longer conflict with prepend strategy. If you encounter stack level too deep errors, see our troubleshooting guide on how to resolve these issues. After working through this troubleshooting guide, you can let us know about the prepend conflict you find by commenting on this GitHub issue. We appreciate your feedback so we may detect and automatically fall back to method-chaining in such scenarios. Modernized auto-instrumentation strategy Ruby introduced prepend as a way to insert method definitions earlier into the method resolution stack in Ruby 2.0 (released in 2013) with the intent that prepend eliminates the need to do method-chaining as a means of patching original gem libraries' implementations with trace/observability logic. Mixing prepend with method-chaining (a.k.a. method _ alias monkey patching) can lead to a known stack level too deep scenario as described in our blog post on the topic. New Relic has previously updated many auto-instrumented libraries over the years to use prepend strategy. The 7.0 release makes prepend the default strategy of choice to auto-instrument over method-chaining, except when known scenarios exist that would lead to triggering stack level too deep errors. A best effort to identify conflicting external gems that would lead to this scenario was made, but there are bound to be others out in the wild that we have not identified. In the past, we had only one way to auto-instrument for most gems and that was method-chaining. With 7.0 release, we can instrument most gems using either method-chaining or prepend and our configuration of all auto-instrumented gems has been updated to reflect this. With the modernization of our auto-instrumentation, we have also introduced new functionality in our dependency detection mechanism to identify conflicting external gems and automatically switch from prepend strategy to method-chaining. This means you no longer have to depend on the maintainers of other gems to make changes to their gem libraries in order to facilitate using the Ruby agent in conjunction with those gems. However, we are not aware of such conflicts until our users report them to us, so only a few of our auto-instrumented libraries can auto-detect these conflicts and auto-switch to method-chaining strategies. We need your help to hear about these scenarios and to add auto-detection to future Ruby agent releases. The SSL Certificate bundle is removed In the early days of Ruby (1.8, 1.9, etc.), integration with OpenSSL and making HTTPS connections was not well-handled. To ensure customers would be able to consistently make HTTPS connections to New Relic's Collector servers, a selection of SSL CA Certificates were bundled and distributed with the Ruby Agent. Over time, the Ruby ecosystem has stabilized and now supports system installed CA Certificates in a standard manner that largely obsoletes the need to bundle and distribute the certificate bundle. The vast majority of certificates bundled have expired or are nearing expiration, so we have decided to remove this dependency from the agent. If you're deploying a Ruby application and agent to a container or server that does not have CA certificates installed, you will need to ensure they're now installed for 7.0+ releases of the agent to make successful HTTPS connections to New Relic servers. For more information, see Remove cert bundle #478. Potential issue: If you're deploying to a host that does not have OpenSSL and system CA certificates installed, you may experience issues connecting to New Relic servers and experience loss of APM data. Solution: New Relic servers require HTTPS, which uses CA certificates to initiate successful connections. These may be installed, and depending on your host, in various ways. The following are helpful links for testing the readiness of your host and installing CA certificates: Troubleshooting SSL Certificate Errors Automated SSL Check Installing CA Certificates How to handle Certificates in Docker If needed, the agent can be configured to use any CA bundle by giving the path to the CA bundle file via configuration: :ca\\_bundle\\_path. Please see Custom SSL certificate for Ruby for more info. Deprecated API's and configuration attributes All deprecated API's have replacement API's that either expand scope and/or improve robustness of the deprecated API. Relevant pull requests are: Remove references to whitelist and blacklist in codebase #479 Remove deprecated ActiveRecord config options #480 Remove httpResponseCode attribute #481 Remove deprecated option from notice _ error API #597 Remove deprecated distributed trace API methods #598 Denied and allowed lists enabled Potential issue: Black/White listed attributes no longer work. Solution : Change black to denied and white to allowed in your configuration or environment variable settings. :autostart.blacklisted _ constants => :autostart.denylisted _ constants :autostart.blacklisted _ executables => :autostart.denylisted _ executables :autostart.blacklisted _ rake _ tasks => :autostart.denylisted _ rake _ tasks :strip _ exception _ messages.whitelist => :strip _ exception _ messages.allowed _ classes Active Record Potential issue: Disabling older Active Record versions no longer works. Solution: Change the following configuration settings: :disable _ active _ record _ 4 => :disable _ active _ record _ notifications :disable _ active _ record _ 5 => :disable _ active _ record _ notifications httpResponseCode Potential issue: The attribute httpResponseCode no longer appears in UI in the traces reported. Solution: httpResponseCode was replaced with http.statusCode. Notice Error (trace _ only) Potential issue: Passing the :trace\\_only option to NewRelic::Agent.notice\\_error no longer works. Solution: Replace :trace\\_only with the :expected attribute. Distributed Tracing APIs Potential issue: Errors are raised in application code while calling the api methods create_distributed_trace_payload and accept_distributed_trace_payload. Solution: Instead, please see insert _ distributed _ trace _ headers and accept _ distributed _ trace _ headers, respectively.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.1463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "sections": "<em>Ruby</em> <em>agent</em> 6.x to 7.x migration guide",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Summary This guide covers the major changes between the 6.x and 7.x series of the <em>Ruby</em> <em>agent</em>, issues that may be encountered while upgrading, and how to migrate successfully to version 7.x. Main changes include: Support for <em>Ruby</em> 2.0 and 2.1 is dropped SSL Certificate Bundle is removed Several APIs"
      },
      "id": "605adf9b64441f9fed868b80"
    },
    {
      "sections": [
        "Introduction to New Relic for Ruby",
        "Compatibility and requirements",
        "Monitor app performance",
        "Install the agent",
        "Extend agent instrumentation",
        "Troubleshooting",
        "Check the source code"
      ],
      "title": "Introduction to New Relic for Ruby",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Getting started"
      ],
      "external_id": "2051cf404d245d992e5bf734ec28bdef44c04bc9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/getting-started/introduction-new-relic-ruby/",
      "published_at": "2021-09-02T03:10:51Z",
      "updated_at": "2021-07-27T09:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Ruby agent monitors your applications to help you identify and solve performance issues. You can also extend the agent's performance monitoring to collect and analyze business data to help you improve the customer experience and make data-driven business decisions. Compatibility and requirements The Ruby agent supports many of the most common Ruby frameworks and platforms. You can also use the Ruby agent in a Google App Engine (GAE) flexible environment. Before you install the Ruby agent, ensure your system meets the system requirements. Monitor app performance View the big picture of your app Monitor your app's Apdex (user satisfaction). Get a high-level summary of your app. Create architectural maps of your app. Enable distributed tracing to understand activity in an environment that relies on many services. Install New Relic Infrastructure and view detailed host data for your app. Find errors and problems quickly Track key transactions. Create customized dashboards for important metrics. Alert your team when errors or problems occur before they affect your users. Track performance after a deployment. Drill down into performance details Examine code-level transaction traces and cross application traces. Examine database query traces. Examine error traces. Monitor Ruby background processes and daemons. Analyze business data Use the Ruby agent to organize, query, and visualize your data to answer key questions about application performance and customer experience. Use default transaction attributes or add your own. Query your data using NRQL. Send your own event data. Create and share customizable, interactive dashboards. Install the agent After creating a New Relic account, use our launcher or see the installation instructions. Install docs for gem (recommended) Install docs for rails plugin Add Ruby data Extend agent instrumentation After installing the agent, go further and extend the agent's instrumentation: Page load timing: Automatically inject the browser monitoring agent to get visibility into end-user activity. Custom instrumentation: Instrument transactions not captured as part of our framework instrumentation. Agent API: Use the agent API to fully customize the agent's behavior. For example, you can collect custom metrics, flag an error, or ignore a particular transaction entirely. Custom metrics: Record additional metrics as part of a transaction to gain more insights into your app's performance and business data. Agent attributes: Customize the attributes attached to transactions. Customizing attributes allows you to avoid sending sensitive attributes, or to collect additional attributes for deeper visibility into your transactions. Troubleshooting If you encounter issues with the Ruby agent, see our full list of troubleshooting documentation. Common issues include: No data appears (Ruby) Gems incompatible with the Ruby agent Sending handled errors to New Relic Controlling when the Ruby agent starts Check the source code The Ruby agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.93073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic for <em>Ruby</em>",
        "sections": "Introduction to New Relic for <em>Ruby</em>",
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": " transactions. <em>Troubleshooting</em> If you encounter issues with the <em>Ruby</em> <em>agent</em>, see our full list of <em>troubleshooting</em> documentation. Common issues include: No data appears (<em>Ruby</em>) Gems incompatible with the <em>Ruby</em> <em>agent</em> Sending handled errors to New Relic Controlling when the <em>Ruby</em> <em>agent</em> starts Check the source"
      },
      "id": "603eb68428ccbcae31eba779"
    },
    {
      "sections": [
        "Incompatible gems",
        "Problem",
        "Solution",
        "db-charmer",
        "escape_utils",
        "right_http_connection",
        "ar-octopus",
        "makara"
      ],
      "title": "Incompatible gems",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Troubleshooting"
      ],
      "external_id": "ba9768e299d7e3a9183aeec7b1973d29a4795dc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/troubleshooting/incompatible-gems/",
      "published_at": "2021-09-02T04:38:24Z",
      "updated_at": "2021-08-03T00:05:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using a Ruby gem that is incompatible with the New Relic Ruby agent. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the Ruby agent. This details incompatible gems and known workarounds. db-charmer Problem: The db-charmer gem has incompatibilities of how it patches Rails controllers. Solution: Force New Relic to load and start before DbCharmer.enable_controller_magic! is called. For example, add the following to your config/application.rb: require 'newrelic_rpm' NewRelic::Agent.manual_start DbCharmer.enable_controller_magic! Copy escape_utils Problem: The escape_utils gem is incompatible with automatic instrumentation for New Relic's page load timing feature (sometimes referred to as real user monitoring or RUM). Due to the way escape_utils monkey-patches Rack, your whole HTML response may be escaped. Solution: If you see HTML source instead of the rendered page, use either of these options: Remove the escape_utils gem. Use manual instrumentation for page load timing. right_http_connection Problem: If the right_http_connection gem is loaded after newrelic_rpm, it patches the Net::HTTP class in a way that causes New Relic's Externals instrumentation to be missed. Solution: Ensure that right_http_connection is required before newrelic_rpm. ar-octopus Problem: The ar-octopus gem changes the way ActiveRecord's connection management works, breaking the Ruby agent's ability to gather instance information, apply vendor-specific obfuscation to queries, and capture explain plans for long-running database queries. Solution: No known workaround. Either remove the ar-octopus gem, or continue to use it, in which case no explain plans will be captured. makara Problem: The makara gem masks the Ruby agent's ability to detect the database adapter underlying ActiveRecord by modifying the name of the underlying connection. The original adapter name is needed to properly obfuscate queries. Some transaction traces display ActiveRecord content instead of MySQL content. Solution: No known workaround. Either remove the makara gem, or continue to use it. Over-obfuscation will be the expected behavior.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.21629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Ruby</em> <em>agent</em>",
        "body": "Problem You are using a <em>Ruby</em> gem that is incompatible with the New Relic <em>Ruby</em> <em>agent</em>. Solution While New Relic strives to be compatible with all gems, there are some that will not work properly with the <em>Ruby</em> <em>agent</em>. This details incompatible gems and known workarounds. db-charmer Problem: The db"
      },
      "id": "603e7eb528ccbc1e42eba77e"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions": [
    {
      "image": "https://docs.newrelic.com/static/82d53ad1a17b876fc5a92f51e5c01a54/ae694/whats_up_accelerated_decisions.png",
      "url": "https://docs.newrelic.com/whats-new/2020/10/applied-intelligence-now-features-accelerated-suggested-decisions/",
      "sections": [
        "Applied Intelligence now features accelerated suggested decisions"
      ],
      "published_at": "2021-09-02T12:27:16Z",
      "title": "Applied Intelligence now features accelerated suggested decisions",
      "updated_at": "2021-03-11T00:20:00Z",
      "type": "docs",
      "external_id": "3366f3f7d7258c27c856967f1a8d2a90c00f2342",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Incident Intelligence continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested correlation decisions that merge incidents to reduce alert noise further. Suggested decisions use machine learning to tailor correlations based on your data. Usually, we can create suggestions after a few weeks of use and data ingestion. However, if you’re an existing New Relic user, we can now leverage your historical New Relic Alerts data to bring you tailored suggested decision logic in a matter of days. You won’t need to perform any additional configuration—choose the alert policies you want to feed in for correlation as usual, and we’ll take care of the rest. The more policies you add, and the more data we have access to, the better suggestions you’ll receive. Be sure to set up your New Relic alerts source to take advantage of this new capability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.71626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "sections": "<em>Applied</em> <em>Intelligence</em> now features accelerated suggested <em>decisions</em>",
        "body": "Incident <em>Intelligence</em> continuously analyzes alerts and incident data to find patterns in event sequences and offers suggested <em>correlation</em> <em>decisions</em> that merge incidents to reduce alert noise further. Suggested <em>decisions</em> use machine learning to tailor correlations based on your data. Usually, we can"
      },
      "id": "60446abe196a672c4c960f90"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.39289,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "sections": "Get started <em>with</em> Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": "As part of <em>Applied</em> <em>Intelligence</em>, Incident <em>Intelligence</em> helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident <em>Intelligence</em> Before setting up Incident <em>Intelligence</em>, note"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-09-02T03:32:17Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.89611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use Incident <em>Intelligence</em>",
        "sections": "Use Incident <em>Intelligence</em>",
        "tags": "Alerts and <em>Applied</em> <em>Intelligence</em>",
        "body": " for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use <em>decisions</em> To further reduce noise or get improved incident <em>correlation</em>, you can <em>change</em> or customize your <em>decisions</em>. <em>Decisions</em> determine how Incident <em>Intelligence</em> groups incidents together. To get started, see <em>Decisions</em>."
      },
      "id": "6080293564441fd0669d8580"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.0479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-09-02T03:32:17Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.56882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-09-02T04:44:36Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence": [
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-09-02T03:32:17Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.56882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-09-02T04:44:36Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-09-02T04:43:13Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.87076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.0479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-09-02T03:32:17Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.56882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-09-02T04:43:13Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.87076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/rest-api-applied-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.0479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Use Incident Intelligence",
        "Issue summary",
        "Impacted entities issue map",
        "Use suggested responders",
        "Important",
        "Tip",
        "Root cause analysis",
        "Issue timeline",
        "Related activity",
        "Use decisions"
      ],
      "title": "Use Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "f7b852fa406a6e9ff88b791e4cbccc2bd20a5962",
      "image": "https://docs.newrelic.com/static/6e37cc77304398121e1a0080a57e47bb/8c557/screenshot_incident_intelligence_timeline_event_detail.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence/",
      "published_at": "2021-09-02T03:32:17Z",
      "updated_at": "2021-07-02T09:43:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you set up Incident Intelligence, our system will begin finding issues from your data sources. In the issue feed, you can find an overview of all your issues, along with helpful information about them. You can also click any individual issue for more detail, including its analysis summary, event log, and details about correlated issues. This screenshot shows an example issue feed, which describes your issues' statuses, correlations, and more. What's the difference between an issue, incident, and event? In short, these terms are like building blocks. Events are raw data from your sources. Incidents are made up of one or more events. Issues are composed of one or more incidents. In more detail: Events indicate a state change or trigger defined by your monitoring systems. An event contains information about the affected entity, and they are almost always triggered automatically by the system. Incidents are groups of events that describe the \"symptoms\" of your system over time. These symptoms are detected by your monitoring tools, which evaluate your data streams and events. Issues are groups of incidents that describe the underlying problem of your symptoms. When a new incident is created, Incident Intelligence opens an issue and evaluates other open issues for correlations. Issue summary The Issue page is built to provide you with bottom line insights first to understand the problem, and then to minimize the time you need to resolve it. The Issue page includes the following sections: Issue summary: This section has two machine learning modules, the golden signals and the related components. Suggested responders: This section will tell you who to potentially reach out to on your team to solve a specific problem. Label sets: Label sets are focused on incidents that come from 3rd party sources, such as PagerDuty, AWS Cloudwatch, REST APIs, etc., as well as for NRQL queries. They come in the form of key:value pairs. Impacted entities: An entity is anything that has data you can monitor. Specifically, these are focused on incidents from New Relic sources, extracting the entities and providing a summary. Each entity is unique. You can see your entities in a list or on a map. Depending on the data in an issue, all four of these sections can show up together for each issue or separately. If you hover over an impacted entity application, you’ll notice a few calls to action: relevant dashboards, anomaly overview, deployment events, and entity overview. Relevant dashboards helps users in your account look at and interact with dashboards you've created that are related to an entity. The queries you've run to power the various widgets are automatically mapped to entities whenever possible and are presented back to you here for quick access and discovery. Anomaly overview will open the application's anomalies page. This is only available for applications that are set up for Proactive Detection. There are two types of deployment events: deployments and related deployments. Click Show all deployments to see all your deployment events when they arrive, or click a specific deployment to see its APM deployments page. The APM deployment page lists recent deployments and their impact on your end user and app server's Apdex scores, response times, throughput, and errors. This section will only show up if New Relic has identified applications under the impacted entities that have deployments. Impacted entities issue map Hover over an entity to see more information about it. In the Impacted entities section, an issue map is available for any issue involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic alerts violations as your incident notification tools, Incident Intelligence suggests relevant team members that can help resolve your issues. Incident Intelligence learns from your PagerDuty and alerts violations data to provide suggestions for each new incident. Once you receive a suggestion, you can contact the responder or search for relevant documentation that person may have written. To get started, enable PagerDuty or alerts violations as a source for Incident Intelligence. Afterwards, you can view the suggestions in two places: The issue feed, where you can also provide feedback on the suggestions. Directly within PagerDuty (both UI and API.) If you’re also using PagerDuty as a destination, the suggestions will appear in your issue notifications payload. Important This feature doesn't account for on-call availability at the time of incident. Tip In order to train the model, we use the information PagerDuty provides about individuals. We ingest incident information only, not users’ contact details. Root cause analysis Root cause analysis automatically finds potential causes for an issue and its impacted entities. It shows you why open issues occurred, which deployments contributed, and relevant error logs and attributes. With this, you can investigate the problem and reduce your mean time to resolution (MTTR). Tip Note that root cause analysis is dependent on other New Relic data sources and features. This is why root cause analysis information may not always be present for every issue. When you select an issue, you may see Root cause analysis information. Root cause analysis includes three main UI sections: Deployment events: When you set up deployments, we provide the deployment nearest to the issue creation. Changes, such as deployments, account for a high percentage of the root causes of incidents and having that information at hand can help diagnose and resolve issues. Error logs: You can explore millions of log messages with a single click and use manual querying to help you find anomalous patterns and hard-to-find problems. Attributes to investigate: We scan the distribution of attributes and surface possible causes by finding significant changes in the distribution. This section also shows changes in database and external metrics. You can also query interesting attributes. Issue timeline The issue timeline, as presented below, shows you a breakdown of: Incidents The trends taking place What incidents are active What incidents are resolved What is correlated to each other Various milestones at different issue levels In addition, you’ll see a grey line at the top of the timeline. In comparison to the visual timeline that shows the changes to each incident, the grey line represents changes to the issue. Mouse over the grey line to see details of the event. Finally, mouse over the incident to see information on the location, timing, and level of importance of a specific incident. This figure shows a particular incident populated on January 11th with a level of Critical. To view the issues in a text format, in the right hand corner, click Switch to issue log view. Related activity The issue page includes a Related activity section, which is a table displaying activity related to the incident or anomally you are are trying to analyze. You can click each line item in the table to view a unique dashboard that displays data for the entity the incident or anomally came from. The related activity section aggregates a set of incidents into a single issue, according to a rule-based system. Use decisions To further reduce noise or get improved incident correlation, you can change or customize your decisions. Decisions determine how Incident Intelligence groups incidents together. To get started, see Decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.56882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Incident</em> <em>Intelligence</em>",
        "sections": "Use <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " involving two or more entities. The map shows not only the affected entities, but also the services and resources directly related to those entities. Use suggested responders If you’re using PagerDuty or New Relic <em>alerts</em> violations as your <em>incident</em> notification tools, <em>Incident</em> <em>Intelligence</em> suggests"
      },
      "id": "6080293564441fd0669d8580"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-09-02T04:44:36Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/use-incident-intelligence": [
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.0479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "sections": "Get started with <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under <em>Incident</em> <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-09-02T04:44:36Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "sections": "<em>Incident</em> <em>Intelligence</em> destination examples",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Destinations are the data outputs to <em>Applied</em> <em>Intelligence</em>, where you can view your automatically correlated incidents. You can configure <em>Incident</em> <em>Intelligence</em> destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats"
      },
      "id": "6044280d64441f4af5378ed3"
    },
    {
      "sections": [
        "EU/US datacenters and Incident Intelligence"
      ],
      "title": "EU/US datacenters and Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "7ff5005d6728922c357974438d731b8432cd3ffb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/eu-us-datacenters-incident-intelligence/",
      "published_at": "2021-09-02T04:43:13Z",
      "updated_at": "2021-04-21T13:32:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Incident Intelligence service is performed solely in the United States. By using New Relic Incident Intelligence, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic's US region data center or in our EU region data center. If you elect to use the Suggested Responder feature and manage EU-based individuals, you may need to confirm that an appropriate data processing agreement is in place.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.87076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "sections": "EU&#x2F;US datacenters <em>and</em> <em>Incident</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "New Relic&#x27;s <em>Incident</em> <em>Intelligence</em> service is performed solely in the United States. By using New Relic <em>Incident</em> <em>Intelligence</em>, you agree that New Relic may move your data to, and process your data in, the US region. This applies whether you store your data in New Relic&#x27;s US region data center"
      },
      "id": "60802950196a67858464a7cb"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows": [
    {
      "sections": [
        "Incident workflows",
        "Add a Workflow",
        "Tip",
        "Enrichments",
        "Important",
        "Notifier",
        "Variables",
        "Destinations",
        "Add a Destination",
        "Webhook destination",
        "ServiceNow incidents destination",
        "Jira destination"
      ],
      "title": "Incident workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "0993c323f76467d22136cac6982ccd48e859f722",
      "image": "https://docs.newrelic.com/static/0b3369e3d41604e37c47250fa1037c52/c1b63/variables.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/",
      "published_at": "2021-09-02T04:54:17Z",
      "updated_at": "2021-07-27T20:31:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With incident workflow control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue's notifications with additional New Relic data. Add a Workflow The Workflows feature is located under the Alerts & AI menu. Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond click Workflow, then click Add a workflow. Tip The maximum workflows you can add per environment is 1000 Name your workflow. This field is mandatory and needs to be unique Workflows filters the issues you want to send to the relevant destination. You can send all issues by selecting Send all issues or you can build a query to filter the right issues. Build a query by selecting an attribute, operator and value/s to narrow down the right issues you want to be passed on. Optional: Enrichments Enrichments can give additional context on alert notifications by adding NRQL query results to them The workflows enrich tool is similar to the query builder. The NRQL query's results are included in the notification message. If you create queries for your workflows, they run in real time and the query results are the value of the enricher. You can save any valid query into your workflow, even if they return an empty result, but you must run the query before saving the enrichment. You can also query with issue-specific variables; for example {{entities.ids}} Note: the query name needs to be unique because you will use the name to decide how to include the result in the payload of the notification that will be sent by the workflow. Important The maximum number of enrichments per workflow is 10. The maximum number of variables an enrichment can contain is 1. Notifier In order to save and activate a Workflow you need to include a notifier. Setting up a notifier requires having a notification destination configured. You can either set it up through the Destination menu item, or through the Create new destination item in the destination selection drop down in each destination channel screen. A notification destination includes the credentials required to send a notification to a third party platform and an option to customize the message sent by mapping fields from our issues to fields in the destination platform. Note: each notifier allows for extensive customization tailored to your needs. Examples can be found below Click “update message” once completing the notifier requirements, then complete the workflow by clicking activate. Tip In any destination channel, start typing and a variable menu will open up. You will see the names of the variables, that at runtime will be replaced with the variable’s value/s. In order to use the enrichers’ results use their name. Variables To get information about the entity that violated a condition, you can use variables as part of the where statement of the query. For example, to get a list of error logs for a specific issue use: FROM log SELECT * where service.name = {{ entities.names }} AND level = ‘error’ LIMIT 10 Copy This query returns the last 10 error logs for each notification sent for the entities that are associated with the issue. This would give you additional context as to what may have gone wrong and likely help you solve the issue faster. You can use any other entity properties in the same way. An example of how to populate the field Important Note: In order to attain the value in the JSON format, you must specify the word JSON. Otherwise, you will get a comma delimited list (e.g. {{ json entities.Ids}} ). For more variable options to find additional context, a comprehensive list of variables can be found here: Key Display Name (First word will be used for grouping) accumulations.origin Issue Origin accumulations.source Issue Source activatedAt Issue Activated At dataMLModules.components Machine Learning Components dataMLModules.suggestedResponders Machine Learning Suggested Responder dataMLModules.goldenSignals Machine Learning Golden Signals annotations.description Issue Description annotations.title Issue Title closedAt Issue ClosedAt createdAt Issue CreatedAt entities.ids Impacted Entities IDs entities.types Impacted Entities Types entities.names Impacted Entities Names entities.kinds Impacted Entities Kinds incidentIds Incident IDs isCorrelated Issue Is Correlated issueId Issue ID labels.accountIds Issue Environment Associated Account ID labels.aggregationKeys Labels Alerts Aggregation Key labels.conditionNames Labels Alert Condition Names labels.originalAccountIds Labels Account IDs labels.policyIds Labels Alert Policy IDs labels.policyNames Labels Alert Policy Names priority Issue Priority state Issue State status Issue Status totalIncidents Incident Count triggerEvent Issue Notification Trigger Event triggeredAt Issue Triggered At updatedAt Issue Updated At workflowName Workflow Name Destinations Destinations are unique identifiers and credentials for third-party systems. The destination you choose is the location where we send notifications. Destinations are located under the Alerts and AI menu. Add a Destination Go to one.newrelic.com, click Alerts & AI, in the left navigation under Enrich and Respond , then click Destinations. Select one of the destination types at the top of the destinations management screen. Webhook destination Use the webhook notifier to send notification messages to any endpoint. The webhook configuration requires: A unique destination name The endpoint url of the target application Authorization which can be ‘basic authentication or a ‘bearer token’ Basic authentication allows users to provide the username and password associated with your HTTP endpoint, which will populate in the header. Bearer token involves security tokens, where the token is a cryptic string. The user must send this token in the authorization header when requesting protected resources To test your webhook, click ‘test connection’ on the bottom right. There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. ServiceNow incidents destination Using ServiceNow as a notifier enables you to push valuable issues into new ServiceNow incidents. With two-way integrations, you can also make sure that status updates of ServiceNow incidents are mirrored back to New Relic. The ServiceNow notifier requires: Unique notifier name ServiceNow domain endpoint A username and password Optional: enable two-way integration Important The Servicenow user details should have read permissions for the tables: sys_dictionary, sys_choice, sys_user, change_request Optional: enable two-way integration You can configure a two-way integration with ServiceNow incidents so that when state updates for the incident (resolved or closed), it triggers an update in the corresponding New Relic Issue state. Here are some important things to remember when configuring the two-way integration: The following steps are required to enable two-way integration: Check Allow two-way integration when you create the Notifier. Open and download this XML file(which includes the business rule for Incident Workflows). In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. We create a New Relic API-key in the SNOW ‘api_key_credentials’ table. If you want two-way integration, the user used for setting the destination also needs write permissions to the table: api_key_credentials After you enable two-way integration, an incident state in ServiceNow changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. Jira destination Using Jira as a notifier enables you to push valuable issues into a new Jira Cloud ticket. With two-way integration you can also make sure that state-updates are mirrored back to New Relic. Atlassian Jira notifiers need: Notifier name Jira url endpoint A username Jira API key After you enable two-way integration, an incident on Jira changes to Resolved or Closed, and the corresponding workflow incident changes to Closed. Finally, test your notifier to make sure everything is running smoothly and you are receiving your Alerts and Issues. If everything is connecting correctly, you will receive a ‘connection successful’ message.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 284.61426,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Incident</em> <em>workflows</em>",
        "sections": "<em>Incident</em> <em>workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>incident</em> <em>workflow</em> control when and where you want to receive notifications about issues, tunnel the right information to the relevant person or team, and enrich your issue&#x27;s notifications with additional New Relic data. Add a <em>Workflow</em> The <em>Workflows</em> feature is located under the <em>Alerts</em> &amp; AI menu"
      },
      "id": "603e967664441f7e6f4e889b"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.6148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " about. The threshold determines when you’ll be notified. Follow these steps to write your first <em>alerts</em> condition using a NRQL query and a threshold. Once you&#x27;re done, you&#x27;ll have a working <em>alert</em> condition. Step 1: Write your query You can use a NRQL query to return data about how your environment"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.58728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition violations are closed",
        "sections": "How <em>alert</em> condition violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows": [
    {
      "sections": [
        "Custom variables for Incident Workflows",
        "Use custom variables in a filter statement",
        "Workflow data enrichment examples",
        "Query for when application traffic drops",
        "Query for transaction failures",
        "Query for Kubernetes consumption overview",
        "Full variables list by category"
      ],
      "title": "Custom variables for Incident Workflows",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident workflows"
      ],
      "external_id": "48f9db1f21750574985a1563c6b2dad8f4dcb2ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/custom-variables-incident-workflows/",
      "published_at": "2021-09-02T08:52:48Z",
      "updated_at": "2021-03-16T08:06:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Incident Workflows, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the workflow, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part of the configuration of a workflow action. You can retrieve Information about the alert, condition, violation, and entity by using double curly brackets:: {{variable_name}}. Use custom variables in a filter statement To get information about the entity that violated a condition, you can use custom variables as part of the where statement of the query. For example, to get the state of the EC2 instance use: SELECT latest(ec2State) FROM ComputeSample where provider = 'Ec2Instance' where entityName = `{{entity.name}}' Copy This query returns a single value (for example, stopped), as the query only uses a single field. The variable entity.name is the identifier of the entity. You can use any other entity properties in the same way. Workflow data enrichment examples You can use custom variables to enrich your workflow data queries in different ways: Query for when application traffic drops There are times when you want to know when traffic to your application drops. You can use the { { entity.name}} variable in place of your application's name. SELECT count(*) FROM Transaction WHERE appName = '{{entity.name}}' since 10 minutes ago Copy Query for transaction failures There are times when you want to know when your application transactions have failed. This query shows the latest HTTP status code responses filtered by the { { entity.name}} variable that violated your alert policy threshold. From Transaction select latest(httpResponseCode), average(duration) where appName = '{{entity.name}}' Copy Query for Kubernetes consumption overview Use a query like this to get the number of entities and their ingest times within a Kubernetes pod. By identifying what entities have large ingest times, you can begin to address that issue and find a potential remedy. SELECT uniqueCount(displayName), sum(nr.ingestTimeMs) from K8sServiceSample where entityName = '{{entity.name}}' since 1 hour ago. Copy Full variables list by category We'll be updating this table frequently as we make updates to Applied Intelligence. Key Name Display Name alert/account_id alert.account_id Alert Account ID internal alert. * ALL alert/description alert.description Alert Description alert/label_names alert.labels Alert Labels alert/deep_link alert.link Alert Link alert/message alert.message Alert Message alert/policy_name alert.name Alert Name alert/policy_id alert.id Alert Policy ID alert/priority alert.priority Alert Priority alert/state alert.state Alert State internal * ALL internal aws. * ALL internal condition. * ALL newrelic/violation/condition_name condition.name Condition Name newrelic/product condition.product Condition Product newrelic/evaluation/threshold condition.threshold Condition Threshold newrelic/evaluation/threshold_duration_seconds condition.threshold_duration Condition Threshold Duration newrelic/evaluation/threshold_occurrences condition.threshold_occurrences Condition Threshold Occurrences internal entity. * (queries both entity.name and entity.type) ALL newrelic/entity/name entity.name Entity Name newrelic/entity/type entity.type Entity Type newrelic/violation/close_time violation.close_time Violation Close Time internal violation. * ALL newrelic/signal/nrql/query condition.nrql.query Signal NRQL Query newrelic/violation/deep_link_url violation.deep_link_url Violation Deep Link URL newrelic/violation/degradation_time violation.degradation_time Violation Degradation Time newrelic/violation/event violation.event Violation Event Status host/id violation.host.id Violation Host ID host/name violation.host.name Violation Host Name newrelic/violation/id violation.id Violation ID newrelic/violation/muted violation.muted Violation Muted newrelic/violation/open_time violation.open_time Violation Open Time newrelic/violation/priority violation.priority Violation Priority newrelic/violation/recovery_time violation.recovery_time Violation Recovery Time newrelic/violation/runbook_url violation.runbook_url Violation Runbook URL newrelic/violation/time_limit violation.time_limit Violation Time Limit newrelic/violation/title violation.title Violation Title internal workflow.id Workflow Id internal workflow.name Workflow Name",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 245.15204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "sections": "Custom variables for <em>Incident</em> <em>Workflows</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>Incident</em> <em>Workflows</em>, you identify the Policy you want to be alerted on. When the policy gets violated, the violation triggers the <em>workflow</em>, and violation attributes are transferred into the notification creation. Custom variables are violation-related properties you can use as part"
      },
      "id": "603e7a6528ccbcad47eba77f"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.61469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " about. The threshold determines when you’ll be notified. Follow these steps to write your first <em>alerts</em> condition using a NRQL query and a threshold. Once you&#x27;re done, you&#x27;ll have a working <em>alert</em> condition. Step 1: Write your query You can use a NRQL query to return data about how your environment"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.58716,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition violations are closed",
        "sections": "How <em>alert</em> condition violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection": [
    {
      "sections": [
        "Proactive Detection with Applied Intelligence",
        "Requirements",
        "Why it matters",
        "How it works",
        "Set up notifications for Proactive Detection",
        "Set up for Slack",
        "Tip",
        "Set up for webhooks",
        "Set up without notifications",
        "Mute notifications (Slack only)",
        "Use Proactive Detection Slack messages",
        "View overview of anomalies",
        "Anomaly visibility settings",
        "Query anomaly data",
        "Important",
        "Add anomalies as source in Incident Intelligence",
        "Webhook payload and examples",
        "JSON schema example",
        "Data limits"
      ],
      "title": "Proactive Detection with Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "53e01b53fc341ef1e89b96e7927b16de03e72358",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence/",
      "published_at": "2021-09-02T04:55:31Z",
      "updated_at": "2021-07-27T20:32:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With Applied Intelligence's Proactive Detection, anomalies from your New Relic APM-monitored applications are automatically surfaced in our activity streams and anomalies feed. Each anomaly can be clicked on to bring up an automatic analysis. You can have notifications for anomalies delivered in Slack, or you can set up a webhook to deliver messages when you need them. These events are available for querying, creating custom dashboards, and alerting. By creating a Proactive Detection configuration (a group of apps you’re interested in), you can then add this configuration as a source, and have anomalies automatically correlated with other data sources via Incident Intelligence. Requirements To use Proactive Detection, ensure you have: An APM agent installed for at least one applications. To receive notifications in Slack, you'll need to ask your IT administrator to install the Applied Intelligence application in your Slack workspace. For more on data limits, see Data limits. Why it matters With Proactive Detection, Applied Intelligence delivers insights about anomalies in your production system, along with an automatic analysis of the anomaly. It’s enabled automatically, at no additional cost. When an anomaly is detected, you can view it in the Applied Intelligence anomalies feed, or we'll send notifications directly to your Slack channel or a webhook. How it works Proactive Detection uses the following methods to detect anomalies in your app data: Proactive Detection monitors metric data reported by an APM agent, building a model of your typical application dynamics, and focuses on key golden signals: throughput, response time, and errors. If one of these golden signals shows anomalous behavior, the system flags it and tracks recovery to normal behavior. The system adapts to changes in your data, and continuously updates models based on new data. Automatically on: By default, Proactive Detection monitors all your APM applications, with no action required by you. When an anomaly is detected, it's automatically surfaced in various activity streams, the Applied Intelligence anomalies feed and is available for querying via NRQL. Receiving notifications: We send notifications when we detect anomalous changes in throughput, error rate, or response time. The notifications are sent to selected Slack channels, or sent via webhook. When the anomaly goes back to normal, a recovery message is sent. If you don't want to receive notifications, you still have access to the data via NRQL query. Anomaly analysis: For each anomaly, we provide a link in Slack to an analyze anomaly page. This page generates automatic insights into the anomaly. The page is also available from the anomalies tab, which lists recent anomalies. This page uses your existing APM and Proactive Detection data to provide explanations as to the cause of the anomaly. Activity stream: Inside various activity streams such as the New Relic One homepage, APM Summary page, Lookout and Explorer, you'll see relevant anomalies from your APM-monitored applications. Clicking on any of the anomaly events in the activity stream brings up the analysis page for that anomaly. Applications will not always generate anomalies, so it can be normal to not receive any detections. Set up notifications for Proactive Detection Proactive Detection is enabled automatically, at no additional cost. To receive notifications or to have a configuration (group of apps) that you can add as a source for Incident Intelligence, you will need to create a Proactive Detection configuration. You can create a configuration in the Proactive Detection UI: From one.newrelic.com, click Alerts & AI. Under Proactive Detection, click Settings. Click Add a configuration. Input the following information into the form: Choose a name for your configuration that helps you easily identify it from others in your account. Select an account. Select up to 1,000 applications. Note that certain applications with low throughput might not be good candidates for Proactive Detection, as they can be more sensitive to smaller amounts of data fluctuation. Optional: select the golden signals you'd like to monitor for anomalies. Optional: connect to Incident Intelligence. Set up for Slack To use Proactive Detection with Slack: Select Slack. Choose which Slack channel receives notifications. You can select any existing public or private channel. This prompts the workflow to add the Applied Intelligence Slack application to your selected channel. To create a new channel, do that directly in Slack first. Tip If you experience an error when assigning Slack channels, make sure that the New Relic AI Slack application has been added to your Slack workspace. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up for webhooks To use Proactive Detection with webhooks: Select Webhook. Input the following information into the form: Provide the webhook URL. Provide optional custom headers. Choose to edit the custom payload, or enable using the default payload. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Set up without notifications To use Proactive Detection when you don't need to receive notifications: Select No notifications. Save the configuration. You can modify the applications for each configuration at any time by selecting the configuration in the configuration table. Mute notifications (Slack only) In Slack, detections coming from specific applications can be muted temporarily or permanently. The entire channel can also be muted temporarily. This is useful in the case of an incident or when the channel should otherwise not be interrupted. To mute in Slack, select Mute this app’s warnings or Mute all warnings, then select the duration. We will resume sending notifications for any detections once the muting duration has completed. Muting an application permanently removes it from the configuration. To add it back in, go to one.newrelic.com, in the top nav click Alerts & AI, then click Proactive Detection, and select the configuration to edit. Muting Proactive Detection notifications does not affect alerts. Use Proactive Detection Slack messages Each anomaly message has several key pieces of information you can use to learn more about and start troubleshooting the potential issue: The application name and a link to more information about it in New Relic One. The metric experiencing an anomaly and a link to its details in New Relic One. A graph of the metric over time to provide a visual understanding of the anomaly’s behavior and degree. An Analyze button that navigates to an analysis page in Applied Intelligence that identifies key attributes that are unique to the anomaly, anomalies found upstream or downstream, and any other relevant signals. Once an anomaly has returned to normal, we send a recovery notification with the option to provide feedback. Your feedback provides our development team with input to help us improve detection quality. In the case of feedback provided on throughput anomalies, an evaluation is run each hour based on feedback to fit a more suitable model. If we helped you, you can select Yes or No. View overview of anomalies In addition to notifications for anomalies that give you information via Slack or webhook, you can view more information about the anomalies in your environment via the Anomalies tab on the Alerts & AI Overview page. That tab provides a list of all the recent anomalies from every configuration in the selected account, and you can select an anomaly for a detailed analysis. Anomaly visibility settings Anomalies are displayed in various New Relic activity streams and in the Applied Intelligence anomalies feed. You can customize what is displayed using the anomaly visibility settings (for example, hiding throughput anomalies on an activity stream but keeping them in the anomalies feed). To find these settings: from Alerts & AI, under Proactive Detection, click Settings. Notes on using these settings: These settings are applied at the user level. Changes you make won’t affect others users in your organization. Regardless of these settings, the anomalies are still reported and available for NRQL querying. Details on these UI sections: AI overview and anomalies tab: Use the AI overview and anomalies tab setting to hide anomalies from the AI overview and anomalies tab setting. Please note you also can use filters specific to these views as well. Global activity stream: Use the global activity stream section to customize what anomalies are shown in the various New Relic activity streams, including the New Relic One homepage, APM Summary, and Lookout. Anomaly types: Use the check boxes here to hide specific types of anomalies. For example uncheck Web throughput and Non-web throughput anomalies to hide these types of anomalies from both the activity streams and the AI overview and anomalies tab. (Note they are still reported and available for querying.) Query anomaly data You can use NRQL to query and chart your Proactive Detection data using the NrAiAnomaly event. For example: FROM NrAiAnomaly SELECT * Important This data has previously been attached to the ProactiveDetection event. That event will be deprecated on April 7, 2021. If you use ProactiveDetection in your custom charts, you should convert those queries to using NrAiAnomaly. Here are important attributes attached to this event: Attribute Description closeTime timestamp The time when the anomaly ended. Example: 1615304100000. configurationType string The type of configuration monitoring the event. If at least one configuration is monitoring the entity, this is set to configuration. Otherwise, it's set to automatic. entity.accountId number The New Relic account ID to which the entity belongs. entity.domain number The domain of the entity (currently only APM but will change with future functionality). entity.guid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entityGuid. entityGuid string The GUID of the entity. This is used to identify and retrieve data about the entity via NerdGraph. Identical to entity.guid. entity.name string The name of the entity whose data was determined to be anomalous. Identical to entityName. Example: Laura's coffee service. entityName string The name of the entity whose data was determined to be anomalous. Identical to entity.name. entity.type string The type of entity (currently only APPLICATION but will change with future functionality). evaluationType string This is always anomaly. event string Indicates whether it's the beginning (open) or end (close) of the anomalous data. openTime timestamp The time when the anomaly opened. Example: 1615303740000. signalType string The type of data that was analyzed. For example, error_rate or response_time.non_web. timestamp timestamp The time at which the event was written. title string Description of the anomaly. Example: Error rate was much higher than normal. Add anomalies as source in Incident Intelligence By integrating Incident Intelligence with your Proactive Detection anomalies, you can get context and correlations. To learn about doing this in Incident Intelligence, see Configure sources. You can also select Connect to Incident Intelligence from inside of a configuration. Webhook payload and examples Proactive Detection sends the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Proactive Detection, use these examples of the webhook body format and JSON schema. Attribute Description category enum The category of data that was analyzed. Categories include web throughput, non-web throughput, web transactions, non-web transactions, and error class. data list The time series data leading up to the detection. data[].timestamp number The timestamp of the data point in milliseconds since the Unix epoch. Example: 1584366819000 data[].unit string The unit describing the value of the data point. Data units include count, milliseconds, and error_rate. data[].value number The value of the data point. Example: 1.52 detectionType enum The type of data that was analyzed. Types include latency, throughput, and error_rate. entity object The entity that reported the unusual data. entity.accountId number The ID for the entity's account. entity.domain enum The domain for the entity. Example: APM. entity.domainId string The id used to uniquely identify the entity within the domain. entity.guid string The guid used to uniquely identify the entity across all products. entity.name string The name of the entity. Example: Laura’s coffee service entity.link string A link to view the entity. Example: https://rpm.newrelic.com/accounts/YOUR_ACCOUNT_ID/applications/987654321” Copy severity enum A description of how unusual of a change occurred, including NORMAL, WARNING, or CRITICAL. version string Version used to describe the data being provided. Example: v1 JSON schema example Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). Template: { \"version\": \"{{version}}\", \"entity\": { \"type\": \"{{entity.type}}\", \"name\": \"{{entity.name}}\", \"link\": \"{{entity.link}}\", \"entityGuid\": \"{{entity.entityGuid}}\", \"domainId\": \"{{entity.domainId}}\", \"domain\": \"{{entity.domain}}\", \"accountId\": {{entity.accountId}} }, \"detectionType\": \"{{detectionType}}\", \"category\": \"{{category}}\", \"data\": [{{#each data}} { \"value\": {{value}}, \"unit\": \"{{unit}}\", \"timestamp\": {{timestamp}} } {{#unless @last}},{{/unless}} {{/each}}] } Copy Sample payload: { \"version\": \"v1\", \"entity\": { \"type\": \"APPLICATION\", \"name\": \"My Application\", \"link\": \"https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/123\", \"entityGuid\": \"foo\", \"domainId\": \"123\", \"domain\": \"APM\", \"accountId\": YOUR_ACCOUNT_ID }, \"detectionType\": \"metric\", \"category\": \"web throughput\", \"severity\": \"CRITICAL\", \"data\": [ { \"value\": 100, \"unit\": \"count\", \"timestamp\": 1584047560917 } , { \"value\": 99, \"unit\": \"count\", \"timestamp\": 1584047620917 } , { \"value\": 0, \"unit\": \"count\", \"timestamp\": 1584047680917 } ] } Copy Data limits In addition to requirements, data limits include: Monitored APM applications: limited to 1,000 per configuration Slack configurations: limited to 200 per account Webhook configurations: limited to 200 per account Configurations without notifications: limited to 200 per account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.7961,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "sections": "<em>Proactive</em> <em>Detection</em> with <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ", at no additional cost. When an anomaly is detected, you can view it in the <em>Applied</em> <em>Intelligence</em> anomalies feed, or we&#x27;ll send notifications directly to your Slack channel or a webhook. How it works <em>Proactive</em> <em>Detection</em> uses the following methods to <em>detect</em> anomalies in your app data: <em>Proactive</em> <em>Detection</em>"
      },
      "id": "603e9d68196a67dc21a83dd2"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-09-02T05:05:30Z",
      "updated_at": "2021-07-27T08:59:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your New Relic APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.74615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your New Relic APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required"
      },
      "id": "603ea67c64441ffd1c4e8860"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.66458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    }
  ],
  "/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/proactive-detection-applied-intelligence": [
    {
      "sections": [
        "Expanded anomaly detection",
        "Requirements",
        "Why it matters",
        "Get started with anomaly detection",
        "Detect anomalies with a faceted NRQL query",
        "See your anomalies in one place",
        "Tip",
        "Query anomaly data",
        "Reduce the number of detected anomalies"
      ],
      "title": "Expanded anomaly detection",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Proactive detection"
      ],
      "external_id": "0b07c0b6ce27f39b5edb3e112a0f949835cbb8c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/proactive-detection/expanded-anomaly-detection/",
      "published_at": "2021-09-02T04:55:31Z",
      "updated_at": "2021-05-31T16:43:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We’ve expanded anomaly detection coverage beyond your APM applications. Configure anomaly detection for your browser applications, mobile applications, infrastructure hosts, and nearly anything you want to monitor. Requirements Expanded anomaly detection is available as a limited beta. You can request access here. Why it matters When starting to configure alert conditions for a variety of applications and hosts, it can be difficult to know what you’ll want to be notified about ahead of time. Anomaly detection helps you distinguish between what’s typical performance in your system and where you’re starting to have trouble. Instead of creating your alert conditions manually, you can simply tell us what you want to monitor. Anomaly detection will help you identify baseline performance in your system and flags anomalous activity in your system. Get started with anomaly detection To get started with expanded anomaly detection: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Select the account you want to use to record anomaly data, then select the workload or entities you’d like to monitor. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. Detect anomalies with a faceted NRQL query To detect anomalies with a faceted NRQL query: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab, and then click + Add a configuration. Click Use a query instead. You may need to select an account, if you have more than one. Add one or more queries with a FACET clause. Name the query and confirm the facets you want to monitor for anomalies. Select the detection sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name the configuration and save. See your anomalies in one place When you set up anomaly detection, New Relic starts analyzing the golden signals of your entities and workloads. Anomalies appear in your activity feeds throughout New Relic One and the Anomalies tab as soon as they’re detected. Click any anomaly to get more detail about it, including analysis and context for the anomaly. Tip For this limited release, anomaly detection won’t generate notifications. However, you can configure a NRQL alert condition for the NrAiAnomaly event. To view anomalies, from one.newrelic.com, go to Alerts & AI > Issues & activity > Anomalies. Query anomaly data Detected anomalies are written to the NrAiAnomaly event in your NRDB account. You can learn more about this event and how to query it here. Reduce the number of detected anomalies If you’re seeing too many anomalies, the first step is to make sure your sensitivity level is set to Low. If it’s already set to Low, you can define specific thresholds to distinguish between normal and anomalous behavior. To define custom thresholds: From one.newrelic.com, go to Alerts & AI > Proactive Detection > Settings. Click the Custom tab and the configuration you want to modify. Select an entity or workload, and then change the sensitivity level. You can use custom sensitivity to define specific thresholds for different entity types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.91168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Expanded anomaly <em>detection</em>",
        "sections": "Expanded anomaly <em>detection</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " the <em>detection</em> sensitivity. We recommend Low sensitivity so that you don’t see too many anomalies. Finally, name your configuration and save. <em>Detect</em> anomalies with a faceted NRQL query To <em>detect</em> anomalies with a faceted NRQL query: From one.newrelic.com, go to <em>Alerts</em> &amp; AI &gt; <em>Proactive</em> <em>Detection</em>"
      },
      "id": "60b5124064441ff965e2cb01"
    },
    {
      "sections": [
        "Introduction to Applied Intelligence",
        "Why use Applied Intelligence?",
        "Determine root causes with Incident Intelligence",
        "Find unknowns with Proactive Detection"
      ],
      "title": "Introduction to Applied Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "68af5032ebe9c91467f78169bb5d30976d7f67ee",
      "image": "https://docs.newrelic.com/static/c95c61f5a259d33c01781273aed8311d/30c92/diagram-applied-intelligence-workflow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/",
      "published_at": "2021-09-02T05:05:30Z",
      "updated_at": "2021-07-27T08:59:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Applied Intelligence (AI) is our AIOps solution for DevOps, site reliability engineers, and on-call teams. At its core, Applied Intelligence helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. By applying machine learning to your data and feedback, Applied Intelligence is designed to improve functionality and deliver smarter context over time. After connecting your data sources to Applied Intelligence, it looks for potential problems and improves based on your feedback. Why use Applied Intelligence? How you respond to an incident can mean thousands of dollars or clicks for your company. Applied Intelligence helps you solve problems faster. Feature Description Troubleshoot and respond to incidents Our solution helps you understand your incidents and gives you ideas for what to do next. Here are a few examples: Automatically classifies incidents based on the golden signals of site reliability engineering. Identifies entities in your stack that may relate to the underlying issue. Suggests responses for incidents based on historical context. Less noise, more focus As tools and systems become more complex, alert noise can overwhelm DevOps and SRE teams. Applied Intelligence correlates related incidents and suppresses noise, so you're only notified when human action is required. Incidents with a hybrid approach Applied Intelligence streamlines your incidents by combining its built-in inputs with your knowledge and feedback. Over time, the system delivers more accurate insights. For example: Our correlation and classification engine adjusts based on your feedback. The system automatically suggests new correlation rules based on your production data. You can create custom logic using the decision builder. Automatic anomaly detection Applied Intelligence provides automatic anomaly detection on all your New Relic APM-monitored applications. We detect anomalies in throughput, latency, and error rate, with no action required from you. Benefits include: No setup required. See anomalies surfaced automatically in the anomalies feed. See them in various New Relic activity streams (for example, on the New Relic One home page). Ability to run NRQL queries of anomalies and create custom dashboards with that data. Determine root causes with Incident Intelligence As part of Applied Intelligence, Incident Intelligence helps you correlate incident events and reduce noise in your environment. With it, you can get an overview of all your issues, see suggested responders, and configure your own correlation logic. To get started, see Incident Intelligence. Find unknowns with Proactive Detection Another feature of Applied Intelligence is Proactive Detection. Proactive Detection is, by default, always on and detecting anomalies. These anomalies are surfaced in the Applied Intelligence anomalies feed, New Relic One activity streams, and can be queried, alerted on, and added to dashboards. Anomalies can be sent to Slack or via webhooks, and/or added as a source for Incident Intelligence correlation and issue notification. Proactive Detection also provides automatic analysis of anomalies and alerts via the analysis page. To get started, see Proactive Detection.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.74615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "sections": "Introduction to <em>Applied</em> <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " on your production data. You can create custom logic using the decision builder. Automatic anomaly <em>detection</em> <em>Applied</em> <em>Intelligence</em> provides automatic anomaly <em>detection</em> on all your New Relic APM-monitored applications. We <em>detect</em> anomalies in throughput, latency, and error rate, with no action required"
      },
      "id": "603ea67c64441ffd1c4e8860"
    },
    {
      "sections": [
        "Get started with Incident Intelligence",
        "Set up Incident Intelligence",
        "1. Configure your environment (one-time)",
        "Tip",
        "2. Configure sources",
        "Alerts",
        "Algorithmia (MLOps)",
        "Connect your Algorithmia data to New Relic",
        "Monitor your machine learning models",
        "Anomalies",
        "AWS",
        "Grafana",
        "PagerDuty",
        "Prometheus Alertmanager",
        "REST API",
        "Splunk",
        "Important",
        "Splunk metadata",
        "3. Configure destinations (ServiceNow and others)",
        "Configure ServiceNow (example)",
        "Send data to ServiceNow",
        "Custom notification message",
        "Other destinations",
        "Send data to PagerDuty",
        "Send data via webhook",
        "4. Configure pathways",
        "What's next?"
      ],
      "title": "Get started with Incident Intelligence",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "8c4a5a914ca01cb42250908d2fb1a12ccc697e25",
      "image": "https://docs.newrelic.com/static/5cb28999dc618c6a5a2b8be1fa72e660/b97f6/image-%25281%2529_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/get-started-incident-intelligence/",
      "published_at": "2021-09-02T04:43:14Z",
      "updated_at": "2021-07-27T09:11:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As part of Applied Intelligence, Incident Intelligence helps you correlate your incidents and reduce noise in your environment. It gives you an overview of all your incidents, their sources, and related events. Set up Incident Intelligence Before setting up Incident Intelligence, note that the count of incident events is a billing factor. To enable Incident Intelligence, follow these four steps. Afterwards, issues should start to appear in your issue feed. 1. Configure your environment (one-time). 2. Configure sources. 3. Configure destinations. 4. Configure pathways. 1. Configure your environment (one-time) To set up an environment in Incident Intelligence, you need an administrator to select a New Relic account for it. This account should be the one your team is using. Who sets the environment? Only administrators, and only for accounts where they have admin privileges. Can administrators set more than one environment? They can set one environment per parent account and its child accounts. More than one can be set if an administrator has privileges for more than one parent account. Need to change the environment's associated account? Reach out to your account executive or our support team for help. Tip Incident Intelligence is a cross-account product. This means you can send in data from any New Relic account or external source to correlate events. 2. Configure sources After setting up your environment, determine your incident sources. These are your data inputs. You can get data from any of the following sources: Alerts By integrating Incident Intelligence with your alerts violations, you can get context and correlations from what you're monitoring. To get data from alerts: From one.newrelic.com, click Alerts. On the left under Incident Intelligence, click Sources and then click Alerts. Select the policies you want to connect to Applied Intelligence, and click Connect. You can add additional alerts policies or remove policies you've already connected in Sources > New Relic Alerts. Tip Adding alerts as a source will not affect your current configuration or notifications. Algorithmia (MLOps) By integrating Incident Intelligence with your Algorithmia machine-learning models, you can monitor your machine learning model performance. Connect your Algorithmia data to New Relic Start monitoring your Algorithmia event flows with New Relic. Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Configure Algorithmia Insights for New Relic Use Algorithmia's docs to configure Algorithmia Insights for New Relic. Create the New Relic connector algorithm Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Algorithmia's getting started guide. import Algorithmia import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Algorithmia.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key Add your New Relic API key to the Algorithmia secret store. Set up Algorithmia Event Flows with New Relic See Algorithmia's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models Step Details Get your API key From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Algorithmia Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } ``` Copy Set up alerts notifications Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions. Anomalies By integrating Incident Intelligence with your New Relic Proactive Detection anomalies, you can get context and correlations from what you're monitoring. To get data from New Relic Proactive Detection anomalies: From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Anomalies. Select the configurations you want to connect to Applied Intelligence by toggling to on (green). To add or remove alert policies, from Alerts & AI, click Sources, then Alerts. Tip Adding anomalies as a source won't affect your current Proactive Detection configurations or notifications. AWS You can integrate Incident Intelligence with Amazon CloudWatch to provide incident management for all of your AWS services. To integrate Amazon CloudWatch: Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Amazon Web Services. Copy the URL. Create a new Amazon SNS topic. Set CloudWatch to forward all Alarms state changes to that topic: In the Amazon CloudWatch UI, click Events > Event Pattern. Select Service Name > CloudWatch. Select Event Type > CloudWatch Alarm State Change. Select Targets > SNS Topic, and select your new Amazon SNS topic. Create a new subscription: In the Amazon AWS UI, click Create a Subscription. Select your new Amazon SNS topic. Select Protocol > choose HTTPS. In Endpoint, paste the URL you previously copied from the Applied Intelligence Sources. Grafana You can integrate Incident Intelligence with Grafana's notifications for insight into events across your applications and environment. Grafana's webhook notification is a simple way to send information over HTTP to a custom endpoint. To integrate Grafana as a new webhook: Log into your Grafana portal using Admin permissions, and choose Alerting. On the Grafana Notification Channels page, click New Channel > Webhook. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources, and then click Grafana. Copy the URL, and paste it into your new Grafana webhook. PagerDuty You can integrate Incident Intelligence directly with your PagerDuty services to ingest, process, and enhance all of your PagerDuty incidents. To get data from PagerDuty: Make sure your PagerDuty API key has write access. From one.newrelic.com, click Alerts & AI. On the left under Incident Intelligence, click Sources and then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. You can add additional services or remove services you've already connected in Sources > PagerDuty. Tip Connecting PagerDuty services to Applied Intelligence will not affect your current services or notifications. Prometheus Alertmanager By integrating Incident Intelligence with Prometheus Alertmanager, you can receive and correlate your Prometheus alerts with events from other sources. To integrate Prometheus Alertmanager: Set up your Alertmanager configuration file by running: ./alertmanager -config.file=simple.yml Copy Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Prometheus Alertmanager. Copy the Prometheus Alertmanager URL, and paste it into the <webhook_config>/url section of your Alertmanager config file. Reload the Prometheus Alertmanager configuration with one of the two methods: Send a SIGHUP to the process. Send an HTTP POST request to the /-/reload endpoint. REST API Incident Intelligence supports a dedicated REST API interface that lets you integrate with additional systems. The interface allows instrumentation of your code or other monitoring solutions to report any kind of metric or event. A metric can be a raw data point such as CPU, memory, disk utilization, or business KPI. An event can be a monitoring alert, deployment event, incident, exceptions or any other change in state that you want to describe. You can also send any type of data to Incident Intelligence straight from your own systems or applications. The REST API supports secure token-based authentication and accepts JSON content as input. For more information on authentication and the full API reference, see REST API for New Relic Applied Intelligence. Splunk By integrating Incident Intelligence with your Splunk log monitoring, you can: Use your environment's log data for searches and key term reports. Correlate alerts and search reports with your other metrics and incidents. Important Applied Intelligence supports Splunk Light, Splunk Cloud, and Splunk Enterprise version 6.3 and higher. To get data from Splunk: In your Splunk console, start a search for the relevant events. Save your search as an alert, configure your alert conditions, and then choose the webhook as the delivery method. Go to one.newrelic.com and click Alerts & AI. On the left under Incident Intelligence, click Sources and then click Splunk. Copy the collector URL, and paste it into the webhook endpoint in the Splunk console. Optional: Use Splunk tokens to enrich alert data with Splunk metadata. Splunk metadata To enrich alerts data with your Splunk metadata, use Splunk tokens. This helps you leverage your search data, which includes metadata and values from the first row of search results. If you want to... Do this... Access search data Use the format $<fieldname>$. For example, use $app$ for the app context for the search. Access field values To access field values from the first result row that a search returns, use the format $result.<fieldname>$. For example, use $result.host$ for the host value and $result.sourcetype$ for the source type. Use variables You can leverage any of the Selected fields in the Splunk search and add any unique fields to the Selected fields to make the data available as a variable. The following fields will automatically provide hints to the correlation engine: app: parsed as APPLICATION_NAME application:parsed as APPLICATION_NAME application_name: parsed as APPLICATION_NAME cluster: parsed as CLUSTER_NAME computer: parsed as HOST_NAME Dc: parsed as DATACENTER_NAME datacenter: parsed as DATACENTER_NAME host: parsed as HOST_NAME host_name: parsed as HOST_NAME hostname: parsed as HOST_NAME transaction: parsed as EVENT_ID Transaction_id: parsed as EVENT_ID user: parsed as USER_NAME 3. Configure destinations (ServiceNow and others) Now that you've set up your sources, you can configure your destinations. These are the data outputs where you view your incidents. Configure ServiceNow (example) Using ServiceNow as a destination enables you to push valuable violation data into new ServiceNow incident tickets. Send data to ServiceNow To configure Incident Intelligence to send data to ServiceNow: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click ServiceNow. Required: Enter a channel name. This is used internally in Applied Intelligence to identify the destination (for example, in Pathways). Required: Enter your ServiceNow credentials: Team domain (This must be unique. No two destinations can have the same domain). Username Password Follow the two-way integration on screen instructions: Open and download this XML file. In the ServiceNow sidebar menu, go to System Definition > Business Rule. Click the menu icon in one of the column headers, select Import XML, and upload the XML file you downloaded. The two way integration will allow the ServiceNow incident to be updated with changes to the Applied Intelligence issue. Closing a ServiceNow incident will close its corresponding New Relic issue. When a New Relic issue is resolved, the corresponding ServiceNow incident will be closed. Custom notification message Applied Intelligence uses a templating framework called Jinja2 in the customization section interface. The Value field must be in valid Jinja syntax. By default, the interface populates a set of default fields in ServiceNow. When you add a custom field, enter the ServiceNow field name you want to use. When you want to skip a selected field in an issue update, add the | skip_on_update string at the end of the value you've selected. Tip By default, ServiceNow adds u_ to the beginning of its custom values. When mapping to ServiceNow attributes, use the Column name value. Please note that the name needs to be lowercase separated by underscores. Go here to see the custom notification message attribute descriptions. Go here to see Jinja2 Useful Syntax. Other destinations You can also set PagerDuty as a destination, as well as any other destination compatible with webhook: Send data to PagerDuty Recommended: Create a new PagerDuty service to use as a destination. Because PagerDuty services can also be used as sources, this can help you distinguish your data input from your output. To create a PagerDuty destination: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click PagerDuty. Enter your PagerDuty API key. The key should be either a personal or general access key with write access. If it's created by a user, the user should be an admin. If you've configured a PagerDuty source with an API key, you can use the same key. Select the PagerDuty services you want to connect to Applied Intelligence, and click Connect. When you're ready, you can add policies for one or more PagerDuty destinations. You can also transfer the policies over from your existing services or leave them as sources if needed. From the Destinations > PagerDuty page, you can also: Review the permissions for your services. Click Authorize when you're done. Add or delete existing services from the PagerDuty destination. Edit permissions for any service. To configure your PagerDuty destinations, use the following settings: Configuration setting Description Trigger new incidents Required. Trigger correlated parent incidents so you can identify issues faster. Edit incident titles Required. Alter your incident titles to help you orient and understand issues. Add new integrations Required. Add integrations to enable incident creation for selected services. Add webhook extensions Add webhook extensions to sync user actions in PagerDuty to New Relic. This lets you update the correlated issue state. Auto-resolve correlated incidents When enabled, this will resolve and automatically close correlated parent/child incidents. Select a user to take actions in PagerDuty You need to select a user before you can enable deep integration with PagerDuty. Once you do, the user can: Add notes to incidents (required): Incident notes are used to enrich incidents with context. Acknowledge triggered incidents: When enabled, Applied Intelligence will acknowledge and correlate newly triggered incidents in PagerDuty before you're notified. Use the original escalation policy: When enabled, the escalation policy of the source service will be applied to each incident. Send data via webhook Incident Intelligence will send the event body in JSON format by HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). To configure Incident Intelligence to send data via webhook: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Destinations, then click Webhook. Required: Configure the unique webhook key, used in Applied Intelligence to refer to this webhook configuration and its specific settings. Required: Configure the destination endpoint where the webhook payload will be sent. Optional steps: Configure custom headers, which are key:value pairs of headers to be sent with the request. Example: \"Authentication\" \"Bearer\" <bearer token> Configure a custom payload template that can be used to map New Relic fields to match the destination tool's expected name and format. Configure priority mapping (critical, high, medium, or low), used to map New Relic's priorities to the priorities expected at the destination. Tip There’s a retry mechanism that is triggered a few times with exponential backoff for a couple of minutes once an error occurs. If we reach the retry limit, the Webhook will get auto-disabled. For examples of destination templates, webhook formats, and JSON schema, see the Incident Intelligence destination examples. 4. Configure pathways To control when and where you want to receive notifications from your incidents, you can configure pathways. To add a pathway: Go to one.newrelic.com, click Alerts & AI, in the left nav under Incident Intelligence click Pathways, then click Add a pathway. In the query builder box, select an attribute, such as application/name. This can be from the list of all attributes available in PagerDuty incidents and New Relic alerts violations, or you can add your own attributes. Select a logical operator. For example, contains. Enter a specific value to complete the logical expression. To include all issues created by your sources, select Send everything. (Use this if you only use one PagerDuty service to manage all incidents.) To build more complex logic, use the AND/OR operators. Select one or more of your destinations. To edit or remove existing pathways, mouse over the pathway's name on the Pathways page. What's next? Now that you've set up some sources and destinations for your incidents, read about how to use Incident Intelligence.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.66458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with Incident <em>Intelligence</em>",
        "sections": "Get started with Incident <em>Intelligence</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " anomalies: From one.newrelic.com, click <em>Alerts</em> &amp; AI. On the left under Incident <em>Intelligence</em>, click Sources and then click Anomalies. Select the configurations you want to connect to <em>Applied</em> <em>Intelligence</em> by toggling to on (green). To add or remove <em>alert</em> policies, from <em>Alerts</em> &amp; AI, click Sources"
      },
      "id": "603ea62e64441f119f4e883f"
    }
  ],
  "/docs/alerts-applied-intelligence/index": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1549.2676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " about. The threshold determines when you’ll be notified. Follow these steps to write your first <em>alerts</em> condition using a NRQL query and a threshold. Once you&#x27;re done, you&#x27;ll have a working <em>alert</em> condition. Step 1: Write your query You can use a NRQL query to return data about how your environment"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1549.0679,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition violations are closed",
        "sections": "How <em>alert</em> condition violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1548.7954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can use NRQL queries to create <em>alert</em> conditions. Once you&#x27;ve defined your signal, you can further define your warning and critical threshold levels. This determines when an <em>alerts</em> violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click <em>Alerts</em> &amp; AI"
      },
      "id": "603ef04864441fbc114e8883"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/alert-custom-violation-descriptions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.2066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload": [
    {
      "sections": [
        "Alerts concepts and workflow",
        "Introduction to important concepts",
        "Basic workflow",
        "What's next?"
      ],
      "title": "Alerts concepts and workflow",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "3b55e4e4b49e0734012ae9b0531651b03ceac1a8",
      "image": "https://docs.newrelic.com/static/9d0aa6988700b46be4f583d3db6f604a/c1b63/new-relic-alert-creation-workflow-diagram.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/alerts-concepts-workflow/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you create customized alerting solutions for monitoring your system. When you set up alerts, you can get notified about problems you're interested in. To help you get started, here are some alerts concepts and the workflow you'll follow. Introduction to important concepts To use alerts well, it will help you to understand the general flow of how the conditions and policies you create lead to violations and notifications. To use alerts well, it will help you to understand the terms we use: Alerts terminology Comments Policy A policy is a group of one or more alert conditions. You must create a policy before you can add conditions to it. A policy has two settings that apply to all of its conditions: incident preference and notification channels (explained more below). Condition A condition includes: a) a monitored data source and b) thresholds that define the behavior that's considered a violation. For example, a specific condition might be described in this way: \"If the response time for any page load in my app goes above 8 seconds and lasts for more than 5 minutes, that's a violation.\" Threshold A threshold is part of a condition; it defines the behavior that's considered a violation. When you create a condition, there's a required critical-level threshold. Optionally, you can set a secondary warning-level threshold. Violation A violation occurs when the value of a data source crosses a condition's threshold. This leads to the creation of a violation event, which is used to pass important information downstream. A violation doesn't directly generate a notification; a violation may lead to an incident, which in turn can generate notifications. Incident Incidents are what generate notifications. At the policy level, the incident preference determines how violations are handled and combined to generate incidents. For example, you may want to have every single violation generate an incident (many notifications) or you may want to have only a single incident open at a time across an entire alert policy (minimal notifications). Setting the incident preference gives you power over how notifications are created and helps prevent notification fatigue. Notification At the policy level, you choose what team members are notified when an incident occurs and how they're notified. We offer several notification channels, including webhooks, Slack rooms, email, etc. You can include charts about the incident to provide context, and share them with your team's notification. For in-depth definitions of these and other terms, see the glossary. Basic workflow Now that you understand some basic concepts and terms, let's look at a typical process for creating a policy and an associated condition: Create a policy. When you create a policy: Give it a meaningful name. For example: the group or team's name, or the set of resources or services the policy targets. Set the incident preference, which determines how violations become incidents. Set notification channels. Create a condition that will be attached to that policy. Steps involved in creating a condition include: Choose a data source that will be monitored (for example, an APM metric or a NRQL query). Set the thresholds that define what behavior will produce a violation. Optional: Include a runbook URL, which is used to share standard procedures for how to handle alert notifications. Optional: Add more conditions to that same policy. In addition to receiving notifications, you can view the alert incident or event details in New Relic One. What's next? To learn more about using alerts: Read our best practices. Learn about the API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> concepts <em>and</em> workflow",
        "sections": "<em>Alerts</em> concepts <em>and</em> workflow",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " URL, which is used to share standard procedures for how to handle <em>alert</em> <em>notifications</em>. Optional: Add more conditions to that same policy. In addition to receiving <em>notifications</em>, you can view the <em>alert</em> incident or event details in <em>New</em> <em>Relic</em> One. What&#x27;s next? To learn more about using <em>alerts</em>: Read our best practices. Learn about the API."
      },
      "id": "61305bef196a673eac4948d2"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-09-02T12:05:08Z",
      "updated_at": "2021-08-26T05:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for New Relic APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.5118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> condition",
        "sections": "Custom metric examples for <em>alert</em> <em>notifications</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> conditions page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    },
    {
      "sections": [
        "Missing alert notifications",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Missing alert notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Troubleshooting"
      ],
      "external_id": "e3e6a1978efcc2399b42d59211e5bc319a87934f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications/",
      "published_at": "2021-09-02T12:13:23Z",
      "updated_at": "2021-08-26T05:21:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’ve set up policies and conditions that generate violations, but you aren’t getting notifications for them. Solution Check your muting rules. The rules you define can mute specific violations or mute notifications altogether. If you turn off your muting rules and start getting notifications again, you may want to rewrite your rules. Check your incident preferences. By default, a single incident record is created per policy. This option sends you the fewest number of notifications. If you want more notifications for each condition or violation in a policy, change your preferences. If you’re still having issues with missing notifications, your email may be on our suppression list. This prevents us from sending emails to your email address. To get your email removed from the list or to troubleshoot any other notification issues, contact our support team at support.newrelic.com. Here are some tips to avoid being placed on our suppression list: Field Description Confirm real email accounts for new users Many email bounce-backs happen when a user is added, but before their email is confirmed. This causes the email to be added to our suppression list before the user can receive the confirmation email. Check your distribution lists When one email address on a distribution list fails, the entire distribution list is added to our suppression list. To avoid this, make sure invalid or outdated email addresses are removed from your distribution lists. Add your email to our allow list Many messages can end up in you or your company’s spam filter. To ensure your system recognizes emails sent by us, add noreply@newrelic.com and * @mailer-d.newrelic.com to your allow list or “Safe Senders” list as a trusted email source. Consider other delivery options In general, email isn’t the most reliable way to receive notifications. For your most important alerts, set up alternate means of communication as a backup. Cause We use an email service that manages all of the alerts notification emails. When our service provider receives an error after an email is sent, the address is added to our suppression list. This is done to stay in line with email delivery best practices, which keeps the newrelic.com domain off of email deny lists.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.01886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>alert</em> <em>notifications</em>",
        "sections": "Missing <em>alert</em> <em>notifications</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " isn’t the most reliable way to receive <em>notifications</em>. For your most important <em>alerts</em>, set up alternate means of communication as a backup. Cause We use an email service that manages all of the <em>alerts</em> notification emails. When our service provider receives an error after an email is sent, the address"
      },
      "id": "6130bfe3e7b9d2367fb6f225"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20648,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.1958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/multi-location-synthetic-monitoring-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1222,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/outlier-detection-nrql-alert": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/scope-alert-thresholds-specific-instances": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/select-product-targets-alert-condition": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.1954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.1954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products": [
    {
      "sections": [
        "Introduction to Alerts",
        "Build a comprehensive alerting solution",
        "Unique, intelligent features",
        "Data security and privacy",
        "What's next?"
      ],
      "title": "Introduction to Alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "f6106d47daa4f224a524fac942240bad22322f35",
      "image": "https://docs.newrelic.com/static/e3443ab0a75369f185c84676e46c0ee0/c1b63/new-relic-set-thresholds-example_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/introduction-alerts/",
      "published_at": "2021-09-02T05:07:49Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you set up robust and customizable alert policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive alerting solution Go to one.newrelic.com, then click Alerts & AI > Create condition: This shows the threshold-setting UI page when creating an alert condition. We give you control over every part of creating a robust alerting solution for your applications and architecture: Decision Steps Decide what to monitor. You can set up alert conditions for any monitored data source. Whether your architecture has just a few components or many, you'll be able to create an effective alerting solution. Define how it will be monitored. You can define exactly what data source behavior opens a violation. Unique features include: Extensive control over the time and frequency settings that opens a violation and a notification. Set critical thresholds for obvious performance problems and optional warning thresholds for when behavior is approaching critical. Baseline alert conditions that automatically adjust to your system's behavior. You decide how sensitive you want the thresholds to be. Decide how incidents are generated. To reduce notification fatigue, incident preference settings give you control over how notifications are created. For example, you may want to receive a notice for every violation or only want a single notification for a series of consecutive violations. Decide how notifications are sent. We offer customizable notification channels via many common services, including email, mobile push notifications, OpsGenie, Slack, and more. To see supported services, see Notification channels. Unique, intelligent features Besides the standard controls you'd expect from a complete alerting solution, we offer some unique and powerful features, including: Feature Details Self-adjusting monitoring Baseline alert conditions allow you to create intelligent, self-adjusting conditions. Anomaly detection An anomalous behavior indicator automatically detects when a violation has occurred within a few minutes of major changes in key database or external service activity. Detect outliers from group behavior Use outlier detection to detect when one or more data sources in a defined group deviate from the behavior you expect from that group. Custom query conditions Using our NRQL query language, create a customized query, and then monitor the results of that query for deviations over time. NerdGraph API Use our GraphQL NerdGraph API to interact with alerts. We recommend the NerdGraph API over the REST API because it has the latest features. Alerts REST API Use the REST API to return information about your alert settings or to create alert policies and conditions. We recommend you start with the NerdGraph API to see if it has the options you need. Webhooks Customizable webhooks allow you to define custom headers, basic authentication, custom payloads, and more. Incident scoping and rollups Every alert policy can be configured to use one of three violation grouping strategies to control the number of alert incidents created, and therefore the number of notifications sent. Cross-product events A dedicated Events page that shows operational events across all of your products. Data security and privacy By default, Alerts doesn't record any personal data. In addition, it automatically sets default permissions for individual account users and access levels within account structures. For more information about our security measures, see our security and privacy documentation, or visit our security website. What's next? If you're new to using Alerts and want to learn more, see: The basic process Best practices",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.78192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Alerts</em>",
        "sections": "Introduction to <em>Alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> lets you set up robust and customizable <em>alert</em> policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive"
      },
      "id": "61305c25196a675f364948f3"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.28403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition violations are closed",
        "sections": "How <em>alert</em> condition violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-alerts-policies": [
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-09-02T12:11:17Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples": [
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.2497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-09-02T12:11:17Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.2497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling": [
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-09-02T12:11:17Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.2497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our GraphQL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-09-02T12:10:16Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels": [
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.2497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: NRQL condition alerts",
        "Tip",
        "Steps to create a NRQL condition",
        "NRQL static condition",
        "NRQL baseline condition",
        "NRQL outlier condition",
        "Update a condition",
        "Update mutations",
        "List and filter NRQL conditions",
        "Use cursor pagination",
        "Request type-specific fields",
        "Filter NRQL conditions",
        "Singular NRQL condition queries",
        "Update the description",
        "Delete conditions"
      ],
      "title": "NerdGraph tutorial: NRQL condition alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "659649f52d58010ca215dada0648a74254d9d96c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts/",
      "published_at": "2021-09-02T12:11:17Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage alerts conditions using our GraphQL NerdGraph API. Here are some conditions queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. This document covers the following: Steps to create a NRQL condition NRQL static condition NRQL baseline condition NRQL outlier condition Update a condition Update mutations List and filter NRQL conditions Singular NRQL condition queries Create a description Delete conditions Steps to create a NRQL condition Follow these steps: Decide which condition type you want to create (see NRQL Condition threshold types). Find your relevant policyID by doing one of the following: Use the NerdGraph policies API. Go to one.newrelic.com, in the top nav click Alerts & AI, then click Policies. Choose a policy. Find the ID under the policy name. Provide the appropriate mutation for your NRQL condition type and the relevant values. Tip The NerdGraph GraphiQL explorer is the best place to find up-to-date documentation about the per-field specifics of the NerdGraph NRQL Conditions API. For example, questions like \"What does the valueFunction field accept?\" are best answered with the inline NerdGraph documentation. NRQL static condition Here's an example of creating a static condition: mutation { alertsNrqlConditionStaticCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 }) { id name } } Copy NRQL baseline condition Here's an example of creating a baseline condition: mutation { alertsNrqlConditionBaselineCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Baseline Condition\" enabled: true baselineDirection: UPPER_ONLY nrql: { query: \"SELECT average(duration) FROM Transaction\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 13 thresholdDuration: 180 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name baselineDirection } } Copy NRQL outlier condition Here's an example of creating an outlier condition: mutation { alertsNrqlConditionOutlierCreate(accountId: YOUR_ACCOUNT_ID, policyId: YOUR_POLICY_ID, condition: { name: \"Outlier Condition\" enabled: true expectedGroups: 4 openViolationOnGroupOverlap: false nrql: { query: \"SELECT average(duration) FROM Transaction FACET httpResponseCode\" } signal: { aggregationWindow: 60 evaluationOffset: 3 } terms: { threshold: 1 thresholdDuration: 300 thresholdOccurrences: ALL operator: ABOVE priority: CRITICAL } violationTimeLimitSeconds: 86400 }) { id name expectedGroups openViolationOnGroupOverlap } } Copy Update a condition Complete the following: Determine the type of your existing condition by requesting the type field in a nrqlConditionsSearch query like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id type } } } } } } Copy Tip The type returned is what you use for your update mutation. For example, if the type returned is STATIC, use alertsNrqlConditionStaticUpdate. If the type returned is BASELINE, use alertsNrqlConditionBaselineUpdate. If the type returned is OUTLIER, use alertsNrqlConditionOutlierUpdate. Provide the id of your condition to your relevant condition type mutation. Note that you can only update conditions of the relevant type. Only provide update mutations for the fields you want to update. Fields you don't provide in the update are not touched. Update mutations Only fields that you provide in the update are changed. In the following example, baselineDirection returns unchanged, but name is updated. mutation { alertsNrqlConditionBaselineUpdate(id: YOUR_CONDITION_ID, accountId: YOUR_ACCOUNT_ID, condition: { name: \"Your updated name\" }) { id name baselineDirection } } Copy List and filter NRQL conditions To list or filter your NRQL conditions, use the nrqlConditionsSearch query in NerdGraph. Use cursor pagination The basic of list functionality for NRQL conditions allows you to paginate through your NRQL conditions as well as request the total count of conditions per account. The nrqlConditionsSearch query utilizes cursor pagination to paginate through resources. The idea behind cursor pagination is that the client will request a cursor in a programmatic loop until the cursor comes back empty. An initial list response will look something like this: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy This example returns a JSON response like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nextCursor\": \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", \"nrqlConditions\": [ { \"id\": \"4432\", \"name\": \"Baseline Condition\", \"type\": \"BASELINE\" }, { \"id\": \"443\", \"name\": \"A static condition\", \"type\": \"STATIC\" }, // more conditions here in reality ], \"totalCount\": 435 } } } } }, } Copy In order to paginate through conditions in the response, have the client request the cursor to be returned until the nextCursor returns from the response as null: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(cursor: \"WOwfJ4+TWm9QTFeKMGyg+w==:QqkI8S4+Wwnpno6z+uk8kQ==\", ) { nextCursor nrqlConditions { id name type } totalCount } } } } } Copy Request type-specific fields Certain fields are only available on specific NRQL condition types. The main reason that mutations are split between the different condition types is because they have minor differences between the fields they accept. For example, valueFunction is only relevant for static NRQL conditions and baselineDirection is only relevant on baseline NRQL conditions. But if these fields are only available on these certain condition types, how do we return them in a list of all of our condition types? The answer is a GraphQL convention known as inline fragments. Inline fragments allow you to access the data on a specific type of NRQL condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch { nrqlConditions { id name type ...on AlertsNrqlStaticCondition { valueFunction } ...on AlertsNrqlBaselineCondition { baselineDirection } ...on AlertsNrqlOutlierCondition { expectedGroups } } } } } } } Copy In the previous example query, we are asking GraphQL to do the hard work for us to determine which NRQL conditions are the correct type. So, when the returned type is a static condition, it will return the valueFunction in the object. When the returned type is a baseline condition, it will return baselineDirection instead, and when the type is an outlier condition, it will return expectedGroups. Here is an example response: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlConditionsSearch\": { \"nrqlConditions\": [ { \"baselineDirection\": \"UPPER_ONLY\", \"id\": \"342\", \"name\": \"My baseline condition\", \"type\": \"BASELINE\" }, { \"id\": \"553\", \"name\": \"My static condition\", \"type\": \"STATIC\", \"valueFunction\": \"SINGLE_VALUE\" }, { \"expectedGroups\": 4, \"id\": \"802\", \"name\": \"My outlier condition\", \"type\": \"OUTLIER\" } ] } } } } } } Copy Filter NRQL conditions You can filter NRQL conditions with the searchCriteria argument of the nrqlConditionsSearch query: Here's an example of filtering NRQL conditions with matching by name. This query returns NRQL conditions that match the provided name. Note that this match is case insensitive. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditionsSearch(searchCriteria: { name: \"Baseline Condition\" }) { nrqlConditions { id name type } } } } } } Copy Singular NRQL condition queries You can use the NRQL condition API to query for a singular condition. Run the nrqlCondition query in the alerts namespace. Similar to type specific fields on the nrqlConditionSearch query, you can also use these inline fragments to request fields that are restricted to a NRQL condition type. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: YOUR_CONDITION_ID) { id name ...on AlertsNrqlStaticCondition { valueFunction } } } } } } Copy Update the description This will walk you through the procedure to create a description for a NRQL alert condition. Get all the conditions for a policy: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlConditions(policyId: YOUR_POLICY_ID) { nextCursor results { id name description enabled nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { duration operator priority timeFunction threshold } type violationTimeLimitSeconds } } } } } } Copy Get the details for a single condition: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: \"YOUR_CONDITION_ID\") { description id enabled name nrql { query } signal { aggregationWindow evaluationOffset } policyId runbookUrl terms { operator priority threshold thresholdDuration thresholdOccurrences } type violationTimeLimitSeconds } } } } } Copy Create a mutation with the description. Here's an empty mutation template: mutation { alertsNrqlConditionStaticUpdate(accountId: YOUR_ACCOUNT_ID, id: \"YOUR_CONDITION_ID\", condition: {description: \"\"}) { description } } Copy Here's an example mutation with an included example description: mutation { alertsNrqlConditionStaticUpdate(accountId: 123456, id: \"123456\", condition: {description: \"timestamp : {{timestamp}} \\n accountId : {{accountId}} \\n type : {{type}} \\n event : {{event}} \\n description : {{description}} \\n policyId : {{policyId}} \\n policyName: {{policyName}} \\n conditionName : {{conditionName}} \\n conditionId : {{conditionId}} \\n product : {{product}} \\n conditionType : {{conditionType}} \\n RunbookUrl : {{runbookUrl}} \\n nrqlQuery : {{nrqlQuery}} \\n nrqlEventType : {{nrqlEventType}} \\n targetID : {{targetId}} \\n targetName : {{targetName}} \\n commandLine : {{tag.commandLine}} \\n entityGuid : {{tag.entityGuid}} \\n entityName : {{tag.entityName}} \\n fullHostname : {{tag.fullHostname}} \\n instanceType : {{tag.instanceType}} \\n processDisplayName : {{tag.processDisplayName}}\"}) { description } } Copy Delete conditions You can use the alertsConditionDelete mutation to delete any type of condition. You can only request the id field on a delete mutation; for example: mutation { alertsConditionDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CONDITION_ID) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.2497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "sections": "<em>NerdGraph</em> tutorial: NRQL condition <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage <em>alerts</em> conditions using our <em>Graph</em>QL <em>NerdGraph</em> API. Here are some conditions queries and mutations you can develop in our <em>NerdGraph</em> API explorer. Tip See the <em>NerdGraph</em> introduction for help getting started with <em>NerdGraph</em> API explorer. This document covers the following: Steps"
      },
      "id": "6130bf6528ccbcb0d856a821"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-09-02T12:10:16Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our <em>Graph</em>QL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-nrql-condition-alerts": [
    {
      "sections": [
        "NerdGraph tutorial: Loss of signal and gap filling",
        "Tip",
        "Customize your loss of signal detection",
        "View loss of signal settings for an existing condition",
        "Create a new condition with loss of signal settings",
        "Update the loss of signal settings of a condition",
        "Customize gap filling",
        "Important"
      ],
      "title": "NerdGraph tutorial: Loss of signal and gap filling",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "2389c7a91a09c2175c1f13c3cad5962389571b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:44:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Loss of signal occurs when New Relic stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up alerts. Gap filling can help you solve issues caused by lost data points. When gaps are detected between valid data points, we automatically fill those gaps with replacement values, such as the last known values or a static value. Gap filling can prevent alerts from triggering or resolving when they shouldn't. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. You can customize loss of signal detection and gap filling using NerdGraph. For example, you can configure how long to wait before considering the signal lost, or what value should be used for filling gaps in the time series. Here are some queries and examples you can use in our NerdGraph API explorer. In this guide we cover the following: Customize loss of signal detection Customize gap filling Customize your loss of signal detection Loss of signal detection opens or closes violations if no data is received after a certain amount of time. For example, if you set the duration of the expiration period to 60 seconds and an integration doesn't seem to send data for more than a minute, a loss of signal violation would be triggered. You can configure the duration of the signal loss and whether to open a violation or close it by using these three fields in NerdGraph: expiration.expirationDuration: How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives at our platform and not on data timestamps. The default is to leave this null, and therefore this wouldn't enable Loss of Signal Detection. expiration.openViolationOnExpiration: If true, a new violation is opened when a signal is lost. Default is false. To use this field, a duration must be specified. expiration.closeViolationsOnExpiration: If true, open violations related to the signal are closed on expiration. Default is false. To use this field, a duration must be specified. View loss of signal settings for an existing condition Existing NRQL conditions may have their loss of signal settings already configured. To view the existing condition settings, select the fields under nrqlCondition > expiration: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { nrqlCondition(id: NRQL_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name nrql { query } expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } } } } } Copy You should see a result like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"nrqlCondition\": { \"expiration\": { \" closeViolationsOnExpiration \": false, \" expirationDuration \": 300, \" openViolationOnExpiration \": true }, \"id\": \"YOUR_ACCOUNT_ID\", \"name\": \"Any less than - Extrapolation\", \"nrql\": { \"query\": \"SELECT average(value) FROM AlertsSmokeTestSignals WHERE wave_type IN ('min-max', 'single-gap') FACET wave_type\" } } } } } }, ... Copy Create a new condition with loss of signal settings Let's say that you want to create a new create a NRQL static condition that triggers a loss of signal violation after no data is received for two minutes. You would set expirationDuration to 120 seconds and set openViolationOnExpiration to true, like in the example below. mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { name: \"Low Host Count - Catastrophic\" enabled: true nrql: { query: \"SELECT uniqueCount(host) from Transaction where appName='my-app-name'\" } signal { aggregationWindow: 60 evaluationOffset: 3 } terms: [{ threshold: 2 thresholdOccurrences: AT_LEAST_ONCE thresholdDuration: 600 operator: BELOW priority: CRITICAL }] valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 86400 expiration : { expirationDuration : 120 openViolationOnExpiration : true } } ) { id name } } Copy Update the loss of signal settings of a condition What if you want to update loss of signal parameters for an alert condition? The following mutation allows you to update a NRQL static condition with new expiration values. mutation { alertsNrqlConditionStaticUpdate( accountId: YOUR_ACCOUNT_ID id: YOUR_STATIC_CONDITION_ID condition: { expiration: { closeViolationsOnExpiration : BOOLEAN expirationDuration : DURATION_IN_SECONDS openViolationOnExpiration : BOOLEAN } } ) { id expiration { closeViolationsOnExpiration expirationDuration openViolationOnExpiration } } } Copy Customize gap filling Gap filling replaces gap values in a time series with either the last value found or a static, arbitrary value of your choice. We fill gaps only after another data point has been received after the gaps in signal (after data reception has been restored). You can configure both the type of filling and the value, if the type is set to static: signal.fillOption: Type of replacement value for lost data points. Values can be: NONE: Gap filling is disabled. LAST_VALUE: The last value seen in the time series. STATIC: An arbitrary value, defined in fillValue. signal.fillValue: Value to use for replacing lost data points when fillOption is set to STATIC. Important Gap filling is also affected by expiration.expirationDuration. When a gap is longer than the expiration duration, the signal is considered expired and the gap will no longer be filled. For example, here's how to create a static NRQL condition with gap filling configured: mutation { alertsNrqlConditionStaticCreate( accountId: YOUR_ACCOUNT_ID policyId: YOUR_POLICY_ID condition: { enabled: true name: \"Example Gap Filling Condition\" nrql: { query: \"select count(*) from Transaction\" } terms: { operator: ABOVE priority: CRITICAL threshold: 1000 thresholdDuration: 300 thresholdOccurrences: ALL } valueFunction: SINGLE_VALUE violationTimeLimitSeconds: 28800 signal: { aggregationWindow: 60, evaluationOffset: 3, fillOption: STATIC, fillValue: 1 } } ) { id } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "sections": "<em>NerdGraph</em> tutorial: Loss of signal <em>and</em> gap filling",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Loss of signal occurs when <em>New</em> <em>Relic</em> stops receiving data for a while; technically, we detect loss of signal after a significant amount of time has elapsed since data was last received in a time series. Loss of signal can be used to trigger or resolve a violation, which you can use to set up <em>alerts</em>"
      },
      "id": "6130bf9c196a676b034948b3"
    },
    {
      "sections": [
        "NerdGraph tutorial: Notification channels",
        "Tip",
        "Get notification channels",
        "List all notification channels for an account",
        "Paginate through notification channels with cursor pagination",
        "Find a specific notification channel by id",
        "Create a notification channel",
        "Caution",
        "Create an email notification channel",
        "Create an OpsGenie notification channel",
        "Create a PagerDuty notification channel",
        "Create a Slack notification channel",
        "Create a VictorOps notification channel",
        "Create a Webhook notification channel",
        "Create an xMatters notification channel",
        "Update a notification channel",
        "Update an email notification channel",
        "Update an OpsGenie notification channel",
        "Update a PagerDuty notification channel",
        "Update a Slack notification channel",
        "Update a VictorOps notification channel",
        "Update a Webhook notification channel",
        "Update an xMatters notification channel",
        "Delete a notification channel",
        "Associate channels to a policy",
        "Dissociate a channel from a policy"
      ],
      "title": "NerdGraph tutorial: Notification channels",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and NerdGraph"
      ],
      "external_id": "d62b37e04d0601fec177951123d72e13f57458a0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-notification-channels/",
      "published_at": "2021-09-02T12:12:12Z",
      "updated_at": "2021-08-26T05:43:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your alert notification channels using our GraphQL NerdGraph API. Here are some queries and mutations you can develop in our NerdGraph API explorer. Tip See the NerdGraph introduction for help getting started with NerdGraph API explorer. Get notification channels The notificationChannels query allows you to paginate through all of your notification channels per account. You can also use the notificationChannel query to get a specific notification channel by its ID. Tip Note that certain secret fields (for example passwords or API keys) are obfuscated in the returned fields. List all notification channels for an account This example returns every field for every notification channel on the supplied account ID, up to the page limit of 200. Note how we use inline fragments to refer to the specific fields on the concrete types implementing the AlertsNotificationChannel interface. { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type ... on AlertsXMattersNotificationChannel { config { integrationUrl } } ... on AlertsWebhookNotificationChannel { config { baseUrl basicAuth { password username } customHttpHeaders { name value } customPayloadBody customPayloadType } } ... on AlertsVictorOpsNotificationChannel { config { key routeKey } } ... on AlertsUserNotificationChannel { config { userId } } ... on AlertsSlackNotificationChannel { config { teamChannel url } } ... on AlertsPagerDutyNotificationChannel { config { apiKey } } ... on AlertsOpsGenieNotificationChannel { config { apiKey dataCenterRegion recipients tags teams } } ... on AlertsHipChatNotificationChannel { config { authToken baseUrl roomId } } ... on AlertsEmailNotificationChannel { config { emails includeJson } } ... on AlertsCampfireNotificationChannel { config { room subdomain token } } } totalCount nextCursor } } } } } Copy Paginate through notification channels with cursor pagination If a given account's list of notification channels exceeds the 200 channel page limit, you can use the pagination cursor to retrieve additional pages. With cursor pagination, you continue to request additional pages using the nextCursor until that field returns empty in the response. An empty nextCursor signals that you have reached the end of the result set. Here's an example: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels { channels { id name type } totalCount nextCursor } } } } } Copy The code above returns a set of results like this: { \"data\": { \"actor\": { \"account\": { \"alerts\": { \"notificationChannels\": { \"channels\": [ { \"id\": \"250\", \"name\": \"Channel 1\", \"type\": \"SLACK\" }, { \"id\": \"713\", \"name\": \"Channel 2\", \"type\": \"WEBHOOK\" }, // ... +198 more notification channels in reality ], \"nextCursor\": \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\", \"totalCount\": 268 } } } } } } Copy In your next request, provide the cursor like so, updating each subsequent request to return the updated cursor, until the cursor is empty: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannels(cursor: \"Wh4LK9JYzfACVlNkyvf7Rg==:I5VbSEpgx3UWNA5AOVsUPv4=\") { channels { id name type } totalCount nextCursor } } } } } Copy Find a specific notification channel by id If you have a specific notification channel's ID, the API allows you to look it up directly. Note that because the specific channel is a concrete type implementing the AlertsNotificationChannel interface, you may need to specify certain fields using the ... on syntax for inline fragments. In this example, we are retrieving a Slack channel: { actor { account(id: YOUR_ACCOUNT_ID) { alerts { notificationChannel(id: YOUR_CHANNEL_ID) { id name type ... on AlertsSlackNotificationChannel { config { teamChannel url } } } } } } } Copy Create a notification channel In order to create an alert notification channel, you need to know the specific type of notification channel you want to create (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Once a notification channel has been created, it can be associated with one or more alert policies. Once associated, those channels will receive notifications from those policies when conditions are violated. Caution While you can query for any existing notification channel type, you can only create a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Create an email notification channel An example create mutation for an email notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { email: { emails: [\"email@example.com\"], includeJson: true, name: \"Some Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type config { emails includeJson } } } error { description errorType } } } Copy Create an OpsGenie notification channel An example create mutation for an OpsGenie notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { opsGenie: { apiKey: \"api-key-from-opsgenie\", dataCenterRegion: US, name: \"OpsGenie notification channel name\", recipients: [\"user@example.com\"], tags: [\"tag1\", \"tag2\"], teams: [\"team1\", \"team2\"] } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type config { apiKey teams tags recipients dataCenterRegion } } } error { description errorType } } } Copy Create a PagerDuty notification channel An example create mutation for a PagerDuty notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty notification channel name\", apiKey: \"api-key-from-pagerduty\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type config { apiKey } } } error { description errorType } } } Copy Create a Slack notification channel An example create mutation for a Slack notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { slack: { name: \"Slack notification channel name\", teamChannel: \"#team-channel\", url: \"https://hooks.slack.com/services/FAKE/MOREFAKE/IMAGINARYEXAMPLEURLCHUNK\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type config { teamChannel url } } } error { description errorType } } } Copy Create a VictorOps notification channel An example create mutation for a VictorOps notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { victorOps: { key: \"example-api-key-from-victorops\", name: \"VictorOps notification channel name\", routeKey: \"example-route-key\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type config { key routeKey } } } error { description errorType } } } Copy Create a Webhook notification channel An example create mutation for a Webhook notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { webhook: { baseUrl: \"https://example.com/webhook\", basicAuth: { password: \"t0t4lly-s3cr3t-p455w0rd\", username: \"webhook-user\" }, customHttpHeaders: [ {name: \"X-Api-Key\", value: \"100%-real-api-key\"}, {name: \"X-Calling-Service\", value: \"New Relic Alerts\"} ], customPayloadBody: \"{ \\\"account_id\\\": \\\"$ACCOUNT_ID\\\", \\\"account_name\\\": \\\"$ACCOUNT_NAME\\\", \\\"closed_violations_count_critical\\\": \\\"$CLOSED_VIOLATIONS_COUNT_CRITICAL\\\", \\\"closed_violations_count_warning\\\": \\\"$CLOSED_VIOLATIONS_COUNT_WARNING\\\", \\\"condition_description\\\": \\\"$DESCRIPTION\\\", \\\"condition_family_id\\\": \\\"$CONDITION_FAMILY_ID\\\", \\\"condition_name\\\": \\\"$CONDITION_NAME\\\", \\\"current_state\\\": \\\"$EVENT_STATE\\\", \\\"details\\\": \\\"$EVENT_DETAILS\\\", \\\"duration\\\": \\\"$DURATION\\\", \\\"event_type\\\": \\\"$EVENT_TYPE\\\", \\\"incident_acknowledge_url\\\": \\\"$INCIDENT_ACKNOWLEDGE_URL\\\", \\\"incident_id\\\": \\\"$INCIDENT_ID\\\", \\\"incident_url\\\": \\\"$INCIDENT_URL\\\", \\\"metadata\\\": \\\"$METADATA\\\", \\\"open_violations_count_critical\\\": \\\"$OPEN_VIOLATIONS_COUNT_CRITICAL\\\", \\\"open_violations_count_warning\\\": \\\"$OPEN_VIOLATIONS_COUNT_WARNING\\\", \\\"owner\\\": \\\"$EVENT_OWNER\\\", \\\"policy_name\\\": \\\"$POLICY_NAME\\\", \\\"policy_url\\\": \\\"$POLICY_URL\\\", \\\"runbook_url\\\": \\\"$RUNBOOK_URL\\\", \\\"severity\\\": \\\"$SEVERITY\\\", \\\"targets\\\": \\\"$TARGETS\\\", \\\"timestamp\\\": \\\"$TIMESTAMP\\\", \\\"timestamp_utc_string\\\": \\\"$TIMESTAMP_UTC_STRING\\\", \\\"violation_callback_url\\\": \\\"$VIOLATION_CALLBACK_URL\\\", \\\"violation_chart_url\\\": \\\"$VIOLATION_CHART_URL\\\" }\", customPayloadType: JSON, name: \"Webhook notification channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type config { customPayloadType customPayloadBody customHttpHeaders { value name } basicAuth { password username } baseUrl } } } error { description errorType } } } Copy Create an xMatters notification channel An example create mutation for an xMatters notification channel: mutation { alertsNotificationChannelCreate(accountId: YOUR_ACCOUNT_ID, notificationChannel: { xMatters: { integrationUrl: \"https://company.instance.xmatters.com/api/xm/v<version>/...\", name: \"xMatters notification channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type config { integrationUrl } } } error { description errorType } } } Copy Update a notification channel In order to update an alert notification channel, you need to know the specific type of notification channel you want to change (for example email, Slack, etc.), as well as the details necessary to configure it (which will depend on the channel type). Consistent with other GraphQL APIs, you can update a single field on the channel without knowing anything other than the channel's ID. Caution While you can query for any existing notification channel type, you can only update a subset of them. Specifically, the user channel type has no editable fields, and the Campfire and HipChat channel types are both deprecated. Update an email notification channel An example update mutation for an email notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { email: { name: \"Updated Name <email@example.com>\" } }) { notificationChannel { ... on AlertsEmailNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an OpsGenie notification channel An example update mutation for an OpsGenie notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { opsGenie: { name: \"OpsGenie updated channel name\" } }) { notificationChannel { ... on AlertsOpsGenieNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a PagerDuty notification channel An example update mutation for a PagerDuty notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { pagerDuty: { name: \"PagerDuty updated channel name\" } }) { notificationChannel { ... on AlertsPagerDutyNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Slack notification channel An example update mutation for a Slack notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { slack: { name: \"Slack updated channel name\" } }) { notificationChannel { ... on AlertsSlackNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a VictorOps notification channel An example update mutation for a VictorOps notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, id: YOUR_CHANNEL_ID, notificationChannel: { victorOps: { name: \"VictorOps updated channel name\" } }) { notificationChannel { ... on AlertsVictorOpsNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update a Webhook notification channel An example update mutation for a Webhook notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { webhook: { name: \"Webhook updated channel name\" } }) { notificationChannel { ... on AlertsWebhookNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Update an xMatters notification channel An example update mutation for an xMatters notification channel where we're updating only the name: mutation { alertsNotificationChannelUpdate(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID, notificationChannel: { xMatters: { name: \"xMatters updated channel name\" } }) { notificationChannel { ... on AlertsXMattersNotificationChannel { id name type } } error { description errorType notificationChannelId } } } Copy Delete a notification channel You can delete a notification channel with only the account ID and the channel ID. Note that deleting a channel dissociates it from all policies, meaning that no further notifications will be sent to that channel. mutation { alertsNotificationChannelDelete(accountId: YOUR_ACCOUNT_ID, id: YOUR_CHANNEL_ID) { id error { description errorType notificationChannelId } } } Copy Associate channels to a policy Creating an alert notification channel is not enough: Once the channel has been created, it needs to be associated to one or more policies. Once associated to a policy, the channel can recieve alert notifications when conditions on that policy go into violation. In this example, we associate two channels with a policy: mutation { alertsNotificationChannelsAddToPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Dissociate a channel from a policy In those instances where a notification channel has outlived its usefulness (for example, an email list that has been retired), the time has come to dissociate that channel from the policy (or policies) that are sending alert notifications to it. This API call leaves the channel itself intact, but removes it from the specified policy. In this example, we are removing two channels from a policy (leaving any others in place), and getting back confirmation that those two channel IDs have been removed: mutation { alertsNotificationChannelsRemoveFromPolicy(accountId: YOUR_ACCOUNT_ID, notificationChannelIds: [FIRST_CHANNEL_ID, SECOND_CHANNEL_ID], policyId: YOUR_POLICY_ID ) { notificationChannels { id } policyId errors { description errorType notificationChannelId } } } Copy Tip Removing an alert notification channel from a policy does not delete the policy because it might be used by other policies. On the other hand, deleting a channel will cause all associated channels to stop sending alert notifications to that channel.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraph</em> tutorial: Notification channels",
        "sections": "<em>NerdGraph</em> tutorial: Notification channels",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ": { password: &quot;t0t4lly-s3cr3t-p455w0rd&quot;, username: &quot;webhook-user&quot; }, customHttpHeaders: [ {name: &quot;X-Api-Key&quot;, value: &quot;100%-real-api-key&quot;}, {name: &quot;X-Calling-Service&quot;, value: &quot;<em>New</em> <em>Relic</em> <em>Alerts</em>&quot;} ], customPayloadBody: &quot;{ \\&quot;account_id\\&quot;: \\&quot;$ACCOUNT_ID\\&quot;, \\&quot;account_name\\&quot;: \\&quot;$ACCOUNT_NAME"
      },
      "id": "6130bf9c28ccbc027d56a863"
    },
    {
      "sections": [
        "Intro to using Alerts via NerdGraph API",
        "Alerts features you can manage with NerdGraph",
        "NerdGraph API explorer",
        "Tip",
        "Queries",
        "Mutations"
      ],
      "title": "Intro to using Alerts via NerdGraph API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alerts and Nerdgraph"
      ],
      "external_id": "031187ecde8810e8695a74624f70344ac59d1006",
      "image": "https://docs.newrelic.com/static/6551638ff382e1ef38324cd82dca1214/e2c15/alerts_query_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/alerts-nerdgraph/nerdgraph-api-examples/",
      "published_at": "2021-09-02T12:10:16Z",
      "updated_at": "2021-08-26T05:43:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL NerdGraph API. This is a powerful alternative to managing them in New Relic One or through the REST API. Alerts features you can manage with NerdGraph Here's what you can do in NerdGraph: Manage policies Use NRQL conditions Add muting rules to suppress notifications Manage notification channels Customize loss of signal and gap filling The easiest way to discover alerts queries and mutations is through the NerdGraph API explorer. NerdGraph API explorer Our NerdGraph API explorer is a GraphiQL editor where you can prototype queries and mutations. Here are some examples showing how to find fields for queries and mutations. Tip For general information about NerdGraph, see Introduction to NerdGraph. Queries To explore the various queries, look for the available queries under the actor.account.alerts namespace in NerdGraph API explorer: Mutations To explore various mutations, look in the alerts dropdown in the NerdGraph API explorer:",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.24619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "sections": "Intro to using <em>Alerts</em> via <em>NerdGraph</em> API",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can manage your policies, conditions, and muting rules programmatically using our GraphQL <em>NerdGraph</em> API. This is a powerful alternative to managing them in <em>New</em> <em>Relic</em> One or through the REST API. <em>Alerts</em> features you can manage with <em>NerdGraph</em> Here&#x27;s what you can do in <em>NerdGraph</em>: Manage policies"
      },
      "id": "6130bf2964441fd35942438f"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/apm-metric-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/other-condition-types/create-baseline-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20547,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19489,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-09-02T12:19:16Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.8505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-09-02T12:12:13Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-09-02T11:29:04Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.83792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-09-02T12:19:16Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-09-02T12:13:23Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-09-02T11:29:04Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.83786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions": [
    {
      "sections": [
        "REST API calls for alerts",
        "Important",
        "Available data and functions via API",
        "Conditions excluded from the REST API",
        "Alert policies",
        "Create new policies",
        "Update policies",
        "Delete existing policies",
        "List existing policies",
        "Notification channels",
        "Create new notification channels",
        "Email channel",
        "OpsGenie channel",
        "Slack channel",
        "VictorOps channel",
        "PagerDuty channel",
        "Webhook (json) channel",
        "Webhook (x-www-form-urlencoded) channel",
        "Delete existing notification channels",
        "List existing notification channels",
        "Update notification channels associated with policies",
        "Delete notification channels associated with policies",
        "Conditions for APM, browser, mobile",
        "Create conditions for policies",
        "Update conditions for policies",
        "Delete conditions from policies",
        "List existing conditions for policies",
        "Conditions for NRQL",
        "Create NRQL conditions for policies",
        "Update NRQL conditions for policies",
        "Delete NRQL conditions for policies",
        "List existing NRQL conditions for policies",
        "Conditions for external services",
        "External services: Create conditions for policies",
        "External services: Update conditions for policies",
        "External services: Delete conditions from policies",
        "External services: List existing conditions for policies",
        "Conditions for Synthetic monitoring",
        "Synthetics: Create conditions for policies",
        "Synthetic monitoring: Update conditions for policies",
        "Synthetic monitoring: Delete conditions from policies",
        "Synthetic monitoring: List existing conditions for policies",
        "Conditions for plugins",
        "Plugins: Create conditions for policies",
        "Plugins: Update conditions for policies",
        "Plugins: Delete conditions from policies",
        "Plugins: List existing conditions for policies",
        "Alert activity: Events, violations, incidents",
        "List Events",
        "List Violations",
        "Tip",
        "List Incidents",
        "Show Incident",
        "Acknowledge Incident",
        "Close Incident",
        "Alert entity conditions",
        "List condition by entity",
        "Add an entity to a condition",
        "Remove an entity from a condition"
      ],
      "title": "REST API calls for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "af566e5c2f0a695c1146b5531849bb49248ea0ec",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts/",
      "published_at": "2021-09-02T12:19:16Z",
      "updated_at": "2021-08-26T05:52:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our REST API (v2) allows you to configure settings for alerts. The API Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available API calls. You can also create alert conditions in the UI. Important For infrastructure alerting, see REST API for infrastructure monitoring alerts. Available data and functions via API REST API functions Comments View account data In general, any role can use a user key or REST API key with GET > List functions to view alerts data. The account Owner and Admins may use their API key. List output will be paginated. Available functions include: Alert policies Notification channels Conditions for APM, browser, and mobile (Some limitations apply.) Conditions for external services Conditions for Synthetic monitoring Conditions for NRQL (Some limitations apply.) Events Violations Incidents Maintain account data You may have an Owner or Admin role in your account and a user key or have a custom role that grants permissions to manage Alerts and a user key in order to use any maintenance function, including POST > Create, PUT > Add, PUT > Update, and DELETE. Conditions excluded from the REST API These types of conditions do not have available endpoints in the API: APM: Web transaction percentiles, conditions targeting labels, and baselines NRQL: Baselines Alert policies These API functions include links to the API Explorer, where you can create, delete, or list policies. Important If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Create new policies To add new policies, use your user key and include these two values in the API call: Required values Definition Incident incident_preference Determines how Alerts will create incidents and group violations. This must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name The policy name is required. Leaving it unchanged will create a policy called string. API Explorer: Alerts Policies > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Update policies Use this API to update an existing policy's name and incident_preference. You'll need your user key. Required values Definition id Required. To find a policy's ID, use either of these options: From the UI: On a policy's UI page, find the ID under the policy name. With the API: Use the List policies API. Incident incident_preference Determines how alerts will create incidents and group violations. Must be one of the following: PER_POLICY (default): Roll up by policy. PER_CONDITION: Roll up by condition. PER_CONDITION_AND_TARGET: Roll up by target and condition. Policy name Required. If you do not change the name, it defaults to a policy called string. To find a policy's exact name, use the List policies API. API Explorer: Alerts Policies > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policies/{id}.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"policy\": { \"incident_preference\": \"string\", \"name\": \"string\" } }' Copy Delete existing policies To delete an existing policy, use your user key, and include the policy_id (available from API Explorer: Alerts Policies > GET > List) in the API call: API Explorer: Alerts Policies > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing policies To view a list of existing policies for your account, use your user key, and include these optional values in the API call: Optional policy name filter Optional pagination value API Explorer: Alerts Policies > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i Copy Notification channels These API functions include links to the API Explorer, where you can create, delete, or list Alerts notification channels. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create new notification channels To add new notification channels, use your user key and include these values in the API call: New channel's name Type of channel Configuration values The API Explorer shows the format for required configuration values for each type of notification channel. API Explorer: Alerts Channels > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"channel\": { \"name\": \"string\", \"type\": \"string\", \"configuration\": \"hash\" } }' Copy The \"hash\" place holder in this example must be replaced by one of the following JSON blocks with the appropriate values substituted: Email channel { \"recipients\" : \"test@google.com\", \"include_json_attachment\" : true } Copy OpsGenie channel { \"api_key\": \"abc123\", \"teams\": \"team1\", \"tags\": \"tag1\", \"recipients\": \"me@me.com\" } Copy Slack channel { \"url\": \"http://example.com\", \"channel\": \"channel1\" } Copy VictorOps channel { \"key\": \"mykey\", \"route_key\": \"theroute\" } Copy PagerDuty channel { \"service_key\": \"myservicekey\" } Copy Webhook (json) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/json\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" } \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Webhook (x-www-form-urlencoded) channel This example shows the default payload inserted. (The payload attribute is optional.) The payload can be customized to have different keys than the ones shown and will be sent with the $ prefixed attributes interpolated prior to delivery. Important The condition_id is deprecated. Instead, use condition_family_id. { \"base_url\": \"http://example.com\", \"auth_username\": \"username\", \"auth_password\": \"password\", \"payload_type\": \"application/x-www-form-urlencoded\", \"headers\": { \"header1\": \"test\", \"header2\": \"test\" }, \"payload\": { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\" } } Copy Delete existing notification channels To delete an existing notification channels, use your user key, and include the channel_id (available from API Explorer: Alerts Channels > GET > List) in the API call: API Explorer: Alerts Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_channels/{channel_id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing notification channels To view a list of existing notification channels for your account, use your user key and an optional pagination value in the API call. API Explorer: Alerts Channels > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_channels.json' \\ -H 'Api-Key:$API_KEY' -i Copy Update notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more policies. To add notification channels to policies, use your user key and these values in the API call: A policy_id value (available from API Explorer: Alerts Policies > GET > List) One or more channel_id values in an array, separated by commas or a new line (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'policy_id=$POLICY_ID&channel_ids=channel_id' Copy Delete notification channels associated with policies You can associate a policy with one or more notification channels. You can also associate a notification channel with one or more alert policies. To remove a policy from a channel, or to remove a channel from a policy, use your user key and these values in the API call: The policy_id (available from API Explorer: Alerts Policies > GET > List) The channel_id (available from API Explorer: Alerts Channels > GET > List) API Explorer: Alerts Policy Channels > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_policy_channels.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'channel_id=CHANNEL_ID&policy_id=POLICY_ID' Copy Conditions for APM, browser, mobile These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions with these types of entities: APM: Apps and key transactions Browser: Apps and key transactions Mobile: Mobile apps Exception: The following APM conditions are not available from this API endpoint: Conditions targeting labels (dynamic targeting) Web transaction percentile conditions Baseline conditions Important The API Explorer provides information about other types of conditions using separate endpoints, including external services (APM and mobile), and synthetic monitoring. Consider all types of alert conditions when searching or updating. If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create conditions for policies To add conditions to policies, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Conditions > GET > List. Update conditions for policies To update conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric\": \"string\", \"metric\": \"string\", \"gc_metric\": \"string\", \"condition_scope\": \"string\", \"violation_close_timer\": integer, \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"user_defined\": { \"metric\": \"string\", \"value_function\": \"string\" } } }' Copy Delete conditions from policies To delete conditions from policies, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Conditions > GET > List) API Explorer: Alerts Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing conditions for policies To view a list of existing conditions for your policy, use your REST API key or user key, and the associated policy_id in the API call. API Explorer: Alerts Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for NRQL These API functions include links to the API Explorer, where you can create, update, delete, or list NRQL conditions for your policies. Exception: NRQL baseline conditions are not available from this endpoint. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Create NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This equates to the Evaluation Offset value in the Alerts Condition UI. API Explorer: Alerts Nrql Conditions > POST > Create To create NRQL conditions for policies: curl -X POST 'https://api.newrelic.com/v2/alerts_nrql_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"type\": \"string\", \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" }, \"signal\": { \"aggregation_window\": \"string\", \"evaluation_offset\": \"string\", \"fill_option\": \"string\", \"fill_value\": \"string\" }, \"expiration\": { \"expiration_duration\": \"string\", \"open_violation_on_expiration\": boolean, \"close_violations_on_expiration\": boolean } } }' Copy If you set nrql[since_value] to 3 and nrql[query] to SELECT count FROM myEvent, New Relic evaluates the following query against the terms[threshold] value once per minute: SELECT count FROM myEvent SINCE 3 minutes ago UNTIL 2 minutes ago Copy If you set type as outlier, you can omit the value_function. However, two additional fields are required: expected_groups and ignore_overlap. For more information, see Alerts Conditions API field names. If you omit type or set it as static, it will default to standard NRQL alerting. Update NRQL conditions for policies Recommendation: Due to the way NRQL data is aggregated, set the nrql[since_value] to 3 or higher to prevent false positives. This allows three minutes to aggregate data, and equates to the Evaluation Offset value in the Alerts Condition UI. To update NRQL conditions for policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) The required condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Nrql Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"nrql_condition\": { \"name\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean, \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"value_function\": \"string\", \"nrql\": { \"query\": \"string\", \"since_value\": \"string\" } } }' Copy Delete NRQL conditions for policies To delete NRQL conditions from policies, include these values in the API call: Your user key The condition's id (available from API Explorer: Alerts Nrql Conditions > GET > List) API Explorer: Alerts Nrql Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_nrql_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy List existing NRQL conditions for policies To view a list of existing conditions for your alert policy, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Nrql Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_nrql_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for external services These API functions include links to the API Explorer, where you can create, update, delete, or list policy conditions. These calls are for conditions for external services. The API calls can be used with APM and mobile monitoring apps. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. External services: Create conditions for policies To add conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_external_service_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts External Service Conditions > GET > List. External services: Update conditions for policies To update conditions for external services to policies that have APM or mobile monitoring apps, include these values in the API call: Your user key The external service condition's id (available from API Explorer: Alerts External Service Conditions > GET > List) The required external_service_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts External Service Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"external_service_condition\": { \"type\": \"string\", \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"external_service_url\": \"string\", \"metric\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ] } }' Copy External services: Delete conditions from policies To delete conditions for external services from policies with APM or mobile monitoring apps, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts External Service Conditions > GET > List) API Explorer: Alerts External Service Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_external_service_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy External services: List existing conditions for policies To view a list of existing conditions for policies with external service apps (APM or mobile monitoring), use your user key or REST API key and the associated policy_id in the API call. API Explorer: Alerts External Service Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_external_service_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for Synthetic monitoring These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with Synthetic monitoring. Synthetics: Create conditions for policies To add conditions to policies for Synthetic monitoring, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_synthetics_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Synthetics Conditions > GET > List. Synthetic monitoring: Update conditions for policies To update policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Synthetics Conditions > GET > List) The required synthetics_condition values in the API call (described in the API Explorer page to create alert conditions for Synthetics and in the Alerts conditions API glossary) API Explorer: Alerts Synthetics Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"synthetics_condition\": { \"name\": \"string\", \"monitor_id\": \"string\", \"runbook_url\": \"string\", \"enabled\": boolean } }' Copy Synthetic monitoring: Delete conditions from policies To delete policy conditions for Synthetic monitoring, include these values in the API call: Your user key The condition_id (available from API Explorer: Alerts Synthetics Conditions > GET > List) API Explorer: Alerts Synthetics Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_synthetics_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Synthetic monitoring: List existing conditions for policies To view a list of existing policy conditions for Synthetic monitoring, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Synthetics Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_synthetics_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Conditions for plugins These API functions include links to the API Explorer, where you can create, update, delete, or list conditions for your alert policies. The API calls can be used with plugins from New Relic's Plugin Central. Plugins: Create conditions for policies To add conditions to policies for plugin components or instances, include these values in the API call: Your user key The policy_id (available from API Explorer: Alerts Policies > GET > List) The required plugins_condition values in the API call (described in the API Explorer page and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > POST > Create curl -X POST 'https://api.newrelic.com/v2/alerts_plugins_conditions/policies/$POLICY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy The JSON response returns a condition id, which you will need to update or delete the condition. You can also view the condition id from API Explorer: Alerts Plugins Conditions > GET > List. Plugins: Update conditions for policies To update policy conditions for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) The required plugins_condition values in the API call (described in the API Explorer page to create alert conditions for plugins and in the Alerts conditions API glossary) API Explorer: Alerts Plugins Conditions > PUT > Update curl -X PUT 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"plugins_condition\": { \"name\": \"string\", \"enabled\": boolean, \"entities\": [ integer ], \"metric_description\": \"string\", \"metric\": \"string\", \"value_function\": \"string\", \"runbook_url\": \"string\", \"terms\": [ { \"duration\": \"string\", \"operator\": \"string\", \"priority\": \"string\", \"threshold\": \"string\", \"time_function\": \"string\" } ], \"plugin\": { \"id\": \"string\", \"guid\": \"string\" } } }' Copy Plugins: Delete conditions from policies To delete conditions from policies for plugin components or instances, include these values in the API call: Your user key The condition id (available from API Explorer: Alerts Plugins Conditions > GET > List) API Explorer: Alerts Plugins Conditions > DELETE > Delete curl -X DELETE 'https://api.newrelic.com/v2/alerts_plugins_conditions/$CONDITION_ID.json' \\ -H 'Api-Key:$API_KEY' -i Copy Plugins: List existing conditions for policies To view a list of existing conditions for policies with plugin components or instances, use your user key or REST API key, and the associated policy_id in the API call. API Explorer: Alerts Plugins Conditions > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_plugins_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'policy_id=$POLICY_ID' Copy Alert activity: Events, violations, incidents These API functions include links to the API Explorer, where you can view information about events, violations, and incidents for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List Events To view events for entities monitored by APM, browser, mobile, synthetic monitoring, and alerts, include these values in the API call: Your user key or REST API key Other optional values to use as filters (described in the API Explorer page) that depend on the type of product (browser monitoring, mobile monitoring, etc.), entity (as apps or key transactions for APM, synthetic monitoring, etc.), and type of event (notification, deployment, instrumentation, etc.) An optional pagination value API Explorer: Alerts Events > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_events.json' \\ -H 'Api-Key:$API_KEY' -i Copy List Violations To view violations for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those violations that are currently open An optional pagination value API Explorer: Alerts Violations > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_violations.json' \\ -H 'Api-Key:$API_KEY' -i Copy Tip To find policy, condition, and incident information: take the IDs found in the links section in the violations property and place them into the URLs contained in the outer links property of the payload. List Incidents To view incidents for any entity monitored for your account, include these values in the API call: Your user key or REST API key An optional flag to show only those incidents that are currently open An optional flag to exclude violation data from response An optional pagination value API Explorer: Alerts Incidents > GET > List curl -X GET 'https://api.newrelic.com/v2/alerts_incidents.json' \\ -H 'Api-Key:$API_KEY' -i Copy Show Incident To show a single incident associated with your account, include these values in the API call: Your user key or REST API key An incident ID API Explorer: Alerts Incidents > GET > Show curl -X GET 'https://api.newrelic.com/v2/alerts_incidents/{id}.json' \\ -H 'Api-Key:$API_KEY' -i Copy Acknowledge Incident To acknowledge an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Acknowledge curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/acknowledge.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Close Incident To close an incident associated with your account, include these values in the API call: Your user key An incident ID API Explorer: Alerts Incidents > PUT > Close curl -X PUT 'https://api.newrelic.com/v2/alerts_incidents/{id}/close.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' Copy Alert entity conditions These API functions include links to the API Explorer, where you can list, add and remove entities in the conditions for your alert policies. Important If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. List condition by entity To view the conditions an entity is part of for APM, browser, mobile, key transactions, and Plugins, include these values in the API call: Your user key or REST API key The entity_id This is the specific entity (alert target) to be monitored. The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > GET > list curl -X GET 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_TYPE' Copy Add an entity to a condition To add an entity to a condition, include these values in the API call: Your user key The entity_id This is the entity (alert target) to be monitored. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > PUT > Add curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=$ENTITY_TYPE&condition_id=$CONDITION_ID' Copy Remove an entity from a condition To remove an entity being monitored from a condition, include these values in the API call: Your user key The entity_id This is the specific monitored entity (alert target) to be removed. It is the numeric ID for the APM application, browser app, key transaction, or mobile app. The condition_id (available from API Explorer: Alerts Conditions > GET > List) The entity_type, which must be one of the following: Application BrowserApplication MobileApplication KeyTransaction Plugin API Explorer: Alerts Entity Conditions > DELETE > Remove curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/$ENTITY_ID.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=$ENTITY_ID&condition_id=$CONDITION_ID' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "sections": "<em>REST</em> <em>API</em> calls for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Our <em>REST</em> <em>API</em> (v2) allows you to configure settings for <em>alerts</em>. The <em>API</em> Explorer also includes the curl request format, available parameters, potential response status codes, and JSON response structure for each of the available <em>API</em> calls. You can also create <em>alert</em> conditions in the UI. Important"
      },
      "id": "6130c144e7b9d2d160b6f25d"
    },
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-09-02T12:12:13Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-09-02T12:13:23Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.85037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/rest-api-calls-alerts": [
    {
      "sections": [
        "Disable and enable alerts conditions using the API",
        "Requirements",
        "Enable and disable a condition",
        "Details on searching for condition ID",
        "Details on Update API requests",
        "Tip",
        "Example: Disable an APM condition",
        "For more help"
      ],
      "title": "Disable and enable alerts conditions using the API",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "4ffe50fd7e1a38a9dee007fe10cb63d28b955a8e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/disable-enable-alerts-conditions-using-api/",
      "published_at": "2021-09-02T12:12:13Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In a policy, a condition identifies what triggers an alert. You can use the REST API to disable and enable conditions. You can also disable and enable conditions in New Relic One. Policies can't be enabled or disabled, whether via the API or the UI. Policies can only be created, deleted, or have their conditions changed. Requirements Modifying any attribute in a condition using the API requires: An API key and permissions to manage Alerts The condition's id (available from API Explorer: Alerts Conditions > GET > List) If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. Enable and disable a condition The process for disabling or enabling a condition is the same general process for changing any attribute in a condition. A more detailed example comes after this general procedure: Find the ID for the policy that contains the condition you want to change. If the policy's ID is unknown, use the policy's name or type to make an API call and find the policy's ID. For more on this process, see List a single policy. With the policy ID, make an API call that returns the conditions associated with that policy. There are four different condition categories. If you don't know the category, this may require making up to four API calls in order to find the condition. Details on searching for condition ID If you don't know the category of the condition you want to change, you must search for it by making API calls using the four condition categories. Here are the different API call formats for the various condition categories. APM, browser, and mobile monitoring Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer link Get>List External services Conditions available: apm_external_service, mobile_external_service API Explorer link Get>List Synthetic monitoring API Explorer link Get>List Plugins API Explorer link Get>List For the returned JSON, find the JSON object of the condition you want to change. Copy and paste the condition's JSON in a text editor of your choice and edit the JSON. To enable the condition, set \"enabled\" to true. To disable the condition, set \"enabled\" to false. Update the condition by submitting your edited JSON via an Update API request. Our different products require different API requests. Details on Update API requests Use the Update API request that corresponds to the product in question: Conditions for APM, browser, and mobile Conditions available: apm_app_metric, apm_kt_metric, browser_metric, and mobile_metric API Explorer PUT>Update link Conditions for external services Conditions available: apm_external_service, mobile_external_service API Explorer PUT>Update Conditions for Synthetic monitoring) API Explorer PUT>Update Conditions for Plugins API Explorer PUT>Update Tip An Update API request can only change one condition at a time, it cannot update a vector of objects. For example, to change three conditions, you will have to make three separate requests. Example: Disable an APM condition The following example shows how to disable a condition for an apm_app_metric condition. With the exception of the types of API calls required, the process is similar to the process for changing other condition types. Obtain the policy_id of the policy you want to update. For an imaginary policy named Logjam Alert, the command would be: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G --data-urlencode 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy The output for this request might look like: { \"policies\": [ { \"id\": 85, <---<<< $POLICY_ID \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 } ] } Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy The output for this request might look like: { \"conditions\": [ { \"id\": 12345, <---<<< $CONDITION_ID \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": true, <---<<< Note the condition is enabled \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] }, { \"id\": 2468, <---<<< another condition_id \"type\": \"apm_app_metric\", \"name\": \"Throughput (Low)\", ... } ] } Copy Copy the JSON for only the condition in question and paste it in a text editor. Change \"enabled\": true to \"enabled\": false. The edited JSON would look like: curl -X PUT 'https://api.newrelic.com/v2/alerts_conditions/12345.json' \\ -H 'X-Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -d \\ '{ \"condition\": { \"type\": \"apm_app_metric\", \"name\": \"Apdex (Low)\", \"enabled\": false, <---<<< Changed to false \"entities\": [ \"8288171\" ], \"metric\": \"apdex\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"below\", \"priority\": \"critical\", \"threshold\": \"1\", \"time_function\": \"any\" } ] } }' Copy Update the condition by submitting the edited condition JSON via an Update API request. For this specific condition, you would follow the steps in Update conditions for APM policies. Other product conditions would have other API requests, as detailed in Update API requests. For more help Additional documentation resources include: API calls for alerts (list of all API calls available) Using the API Explorer (using the API Explorer's user interface to get data in and data out of New Relic) Parts of the API Explorer (a quick reference for how to use each section of the API Explorer)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.8503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "sections": "Disable <em>and</em> enable <em>alerts</em> conditions using the <em>API</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In a policy, a condition identifies what triggers an <em>alert</em>. You can use the <em>REST</em> <em>API</em> to disable and enable conditions. You can also disable and enable conditions in <em>New</em> <em>Relic</em> One. Policies can&#x27;t be enabled or disabled, whether via the <em>API</em> or the UI. Policies can only be created, deleted, or have"
      },
      "id": "6130bf9d28ccbc076856a85b"
    },
    {
      "sections": [
        "Alerts conditions API field names",
        "Required and optional fields",
        "Field definitions",
        "aggregation_window",
        "close_violations_on_expiration",
        "condition_scope",
        "enabled",
        "entities",
        "evaluation_offset",
        "expected_groups",
        "expiration_duration",
        "external_service_url",
        "fill_option",
        "fill_value",
        "ignore_overlap",
        "metric",
        "Alerts plugin conditions",
        "Alerts conditions",
        "Alerts external service conditions",
        "metric_description",
        "monitor_id",
        "name",
        "nrql[query]",
        "nrql[since_value]",
        "open_violation_on_expiration",
        "plugin[guid]",
        "plugin[id]",
        "runbook_url",
        "terms[duration]",
        "terms[operator]",
        "terms[priority]",
        "terms[threshold]",
        "terms[time_function]",
        "type",
        "user_defined[metric] (optional)",
        "user_defined[value_function] (optional)",
        "value_function",
        "violation_time_limit_seconds",
        "violation_close_timer"
      ],
      "title": "Alerts conditions API field names",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "38efca7019e641c456e58b27829b8dfb98fb7e59",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/alerts-conditions-api-field-names/",
      "published_at": "2021-09-02T12:13:23Z",
      "updated_at": "2021-08-26T05:52:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The REST API endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The API includes four types of New Relic Alerts conditions: APM External services Synthetic monitoring Plugins All of the fields used with a specific condition type are required except for these optional fields: enabled (defaults to false) runbook_url user_defined Field definitions Not every field listed in this glossary is required for every condition type. The condition type for which a field must be used is listed in each description. aggregation_window Streaming alerts gathers data together into specific amounts of time before running the function in the NRQL query. These windows of time are customizable. The default is 1 minute. The maximum is 15 minutes. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. In the UI, under Advanced signal settings, this is the Aggregation window field. close_violations_on_expiration When true, this closes all currently open violations when no signal is heard within the expiration_duration time. The default is False. condition_scope This field allows you to scope a condition to either a JVM instance or to a whole application. This may be one of the strings: instance application Used for: Conditions Entity conditions For instance-based and JVM health metrics, see also violation_close_timer. enabled This is the status of your alert condition and is optional. The default is false. This field may be used to enable or disable a condition for maintenance or testing periods. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions entities This is an array of entity IDs identifying the objects which will be monitored with your condition. These may be application IDs, browser IDs, plugin IDs, key transaction IDs, external service IDs, etc. These are entered as a series of comma separated integers if there is more than one. Used for: Conditions External service conditions Plugin conditions evaluation_offset The offset is how long we wait for late data before evaluating each aggregation window. Waiting longer gives a more accurate signal but increases latency. The default is 3 minutes. In the UI, under Advanced signal settings, this is the Offset evaluation by field. expected_groups This is the number of groups you expect to see at any given time. It is used in combination with the ignore_overlap option. Used for: NRQL outlier conditions expiration_duration How long to wait, in seconds, after the last data point is received by our platform before considering the signal as lost. This is based on the time when data arrives and not on data timestamps. The default is null. Add a value to enable loss of signal detection. external_service_url This is the URL of the external service to be monitored. This string must not include the protocol. For example, use example.com, not https://example.com. Used for: External service conditions fill_option For sporadic data, you can avoid false alerts by filling the gaps (empty windows) with synthetic data. none: (Default) Use this if you don’t want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won’t be in violation. static: Use this if you’d like to insert a custom static value into the empty aggregation windows before they’re evaluated. This option has an additional, required parameter of fillValue that specifies what static value should be used. This defaults to 0. last_value: Use this to insert the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. In the UI, under Advanced signal settings, this is the Fill data gaps with field. fill_value This is the value used by the fill_option custom value. The default is 0. ignore_overlap If disabled, this looks for a convergence (or overlapping) of groups. If the condition is looking for two or more groups, and the returned values can't be separated into that number of distinct groups, then that will also produce a violation. This type of overlap event is represented on a chart by group bands touching. Used for: NRQL outlier conditions metric The metric field is used for three alert categories. The exact parameters available for use depend on the setting in the type field. These are listed below according to their alert type field. Alerts plugin conditions For Plugin conditions this is the metric, which has been defined in a plugin, that will be used to trigger a notification. Alerts conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_app_metric apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_kt_metric apdex error_percentage error_count response_time throughput browser_metric end_user_apdex total_page_load page_rendering web_application network dom_processing request_queuing ajax_response_time page_views_with_js_errors page_view_throughput ajax_throughput user_defined browser_metric_baseline page_view_throughput average_response_time ajax_response_time ajax_application_time mobile_metric database images json, network view_loading network_error_percentage status_error_percentage user_defined Alerts external service conditions The value specified in the type field controls which of the parameters may be specified. The type field and corresponding available parameter names are listed in the following table. Only one may be specified. type Parameter apm_external_service apdex error_percentage response_time_web response_time_background throughput_web throughput_background user_defined apm_app_metric_baseline external_service_transaction_time error_count database_transaction_time throughput_web response_time_web non_web_transaction_time web_transaction_database_time non_web_transaction_database_time mobile_external_service response_time_average response_time_minimum response_time_maximum throughput network_failure_percentage http_status_error_percentage metric_description This is a title for the metric which is displayed in notifications. Make this descriptive and unique so the reader will understand the nature of plugin metric being used to trigger an alert. Used for: Plugin conditions monitor_id This is the GUID of the Synthetic monitoring to alert on. Used for: Synthetic monitoring conditions name This condition title will allow to you identify it in the UI. Follow the guidelines for making this descriptive but short. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions nrql[query] This is the NRQL query that alerts monitors as part of a NRQL condition. Used for: NRQL conditions nrql[since_value] This is the timeframe (in minutes) in which to evaluate the specified NRQL query. since_value must be between 1 and 20. Used for: NRQL conditions open_violation_on_expiration When true, this opens a loss of signal violation when no signal within the expiration_duration time. The default is False. plugin[guid] This is the GUID of the plugin for which the trigger is being defined. Used for: Plugin conditions plugin[id] This is the ID of the plugin for which the trigger is being defined. Used for: Plugin conditions runbook_url The runbook URL to display in notifications. This field is optional. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions terms[duration] This is the time (in minutes) for the condition to persist before triggering an event. It corresponds to the duration set when adding a threshold in the UI. Used for: Conditions terms[operator] This determines what comparison will be used between the value_function and the terms [ threshold] value to trigger an event. It corresponds to the operation selected when adding a threshold in the UI. It must be one of the following strings: above below equal Used for: Conditions External service conditions Plugin conditions terms[priority] This corresponds to the severity level selected when setting the threshold values for the condition in the UI. This must be one of the following strings: critical warning Used for: Conditions External service conditions Plugin conditions terms[threshold] This is the threshold that the value_function must be compared to using the terms [ operator] for an event to be triggered. It corresponds to the numeric value specified in the UI when adding the threshold values. This is a numeric value and must be 0 (zero) or greater. Used for: Conditions External service conditions Plugin conditions terms[time_function] This corresponds to the settings made in the UI when adding the threshold values. The choices are: all (corresponding to for at least in the UI) any (corresponding to at least once in in the UI) Used for: Conditions External service conditions Plugin conditions type This defines the type of metric that will be used for the alert. Allowable content for the metric field depends on the type value chosen. There are two product categories : Alerts conditions For this category, type is set to one of the following strings indicating the type of alerts condition. type Use apm_app_metric APM application metric will trigger an alert. apm_app_metric_baseline APM application metric will trigger an alert (using a baseline threshold). apm_kt_metric APM key transaction metric will trigger an alert. browser_metric Browser metric will trigger an alert. browser_metric_baseline Browser metric will trigger an alert (using a baseline threshold). mobile_metric Mobile metric will trigger an alert. Used for: Conditions Alerts external service conditions For this category, type is set to one of the following strings indicating the type of external service condition. type Use apm_external_service APM external metric will trigger an alert. mobile_external_service Mobile external metric will trigger an alert. Used for: External service conditions user_defined[metric] (optional) This is the name of a user defined custom metric to be used to determine if an event should be triggered. The user_defined [ value_function] associated with the metric is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. Used for: Conditions External service conditions Synthetic monitoring conditions Plugin conditions user_defined[value_function] (optional) This is the numeric value obtained from the custom metric specified by user_defined [ metric]. It is compared with the terms [ threshold] value when evaluating if an incident should be triggered. The comparison is performed using the operator defined by terms [ operator]. One of these value functions must be specified: average min max total sample_size Used for: Conditions value_function This is the value function used from the plugin metric. This may be one of the strings: min max average sample_size total percent Used for: Plugin conditions When used for a NRQL condition, the options are: single_value (condition is evaluated based on each query's returned value) sum (condition is evaluated based on the sum of each query's returned values over the specified duration) violation_time_limit_seconds Use to automatically close instance-based violations after the number of seconds specified. Must be one of these values: 3600 7200 14400 28800 43200 86400 Used for: Location conditions NRQL conditions violation_close_timer Use to automatically close instance-based violations, including JVM health metric violations, after the number of hours specified. Must be one of these values: 1 2 4 8 12 24 Used for: apm_app_metric (with condition_scope set to instance) apm_jvm_metric",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.8503,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> conditions <em>API</em> field names",
        "sections": "<em>Alerts</em> conditions <em>API</em> field names",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "The <em>REST</em> <em>API</em> endpoints allow you to create conditions for your policies. This glossary contains the names and descriptions of each of the fields that you can use to define or update a condition. Required and optional fields The <em>API</em> includes four types of <em>New</em> <em>Relic</em> <em>Alerts</em> conditions: APM External"
      },
      "id": "6130bfe3e7b9d22fd0b6f258"
    },
    {
      "sections": [
        "Manage entities in alerts conditions",
        "Requirements",
        "General procedure",
        "Important",
        "Example: Add/remove an entity"
      ],
      "title": "Manage entities in alerts conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "REST API alerts"
      ],
      "external_id": "7a33e56e9410082971e69e27422d4646cebb7180",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/rest-api-alerts/manage-entities-alerts-conditions/",
      "published_at": "2021-09-02T11:29:04Z",
      "updated_at": "2021-08-26T05:48:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In alerts, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The alerts UI shows available entities that you can select. You can also use the REST API and API Explorer to add or remove entities for a condition. Requirements Modifying the list of entities in a condition requires you to know: Your API key The { entity_ID} of the entity you want to monitor The { condition_ID} of the condition you want to modify General procedure To update the entity list for a condition: Locate the appropriate entity ID; for example, Application ID and browser ID. Identify the policy ID by name or type. Get the list of conditions associated with the policy and choose the one you want to modify for the appropriate category: APM, browser, and mobile External services Synthetic monitoring Plugins Modify the condition using the add or remove API requests. Important Follow the requirements for the minimum and maximum number of entities you can add to conditions. Example: Add/remove an entity The following example shows how to add a Ruby application named TimberTime in a condition and how to remove an entity from that same condition. Only the first step in this example is unique to choosing the Ruby app as the entity. The remaining steps will be the same for whichever entity you choose. Get the entity_id; for example, {application_id}: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i Copy OR If you know the application name, use this command and specify the app_name: curl -X GET 'https://api.newrelic.com/v2/applications.json' \\ -H 'Api-Key:$API_KEY' -i \\ -d 'filter[name]=TimberTime' Copy Review the output to find the {application_id}, and use it as the {entity_id}: { \"applications\": [ { \"id\": 12345, <---<<< {application_id} == {entity_id} \"name\": \"TimberTime\", \"language\": \"ruby\", \"health_status\": \"gray\", ... }, Copy Get the policy_id you want to update; for example, the TimberTime app's Logjam Alert policy. To get the policy_id, use this command: curl -X GET 'https://api.newrelic.com/v2/alerts_policies.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'filter[name]= Logjam Alert' <---<<< {policy_name} Copy Review the policy output; for example: { \"policies\": [ { \"id\": 85, <---<<< {policy_id} \"incident_preference\": \"PER_POLICY\", \"name\": \"Logjam Alert\", \"created_at\": 1461176510393, \"updated_at\": 1461176510393 }, Copy List all of this policy's conditions and locate the {condition_id}: curl -X GET 'https://api.newrelic.com/v2/alerts_conditions.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'policy_id=85' Copy Review the policy conditions; for example: { \"conditions\": [ { \"id\": 234567, <---<<< {condition_id} \"type\": \"apm_app_metric\", \"name\": \"Throughput (web) (High)\", \"enabled\": true, \"entities\": [ \"8288171\" <---<<< Entity currently included in the policy ], \"metric\": \"response_time_web\", \"terms\": [ { \"duration\": \"5\", \"operator\": \"above\", \"priority\": \"critical\", \"threshold\": \"500\", \"time_function\": \"all\" } ] } ] } Copy Use API requests to add entities to or remove entities from the policy's condition: To add {entity_id} 12345 to {condition_id} 234567, with {entity_type} set as application: curl -X PUT 'https://api.newrelic.com/v2/alerts_entity_conditions/12345.json' \\ -H 'Api-Key:$API_KEY' -i \\ -H 'Content-Type: application/json' \\ -G -d 'entity_type=Application&condition_id=234567' Copy To remove {entity_id} 8288171 from {condition_id} 234567, with {entity_type} set as application: curl -X DELETE 'https://api.newrelic.com/v2/alerts_entity_conditions/8288171.json' \\ -H 'Api-Key:$API_KEY' -i \\ -G -d 'entity_type=Application&condition_id=234567' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.8378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage entities in <em>alerts</em> conditions",
        "sections": "Manage entities in <em>alerts</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "In <em>alerts</em>, an entity is defined as any target for monitoring, such as an application, a browser, or a plugin. The <em>alerts</em> UI shows available entities that you can select. You can also use the <em>REST</em> <em>API</em> and <em>API</em> Explorer to add or remove entities for a condition. Requirements Modifying the list"
      },
      "id": "6130b580196a67eab24948fb"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications": [
    {
      "sections": [
        "Tag information not showing up for entity in Infra alert condition",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Tag information not showing up for entity in Infra alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Troubleshooting"
      ],
      "external_id": "eea5c8af1006f893c8ba812e3768124ca408a3e1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/tag-information-not-showing-entity-infra-alert-condition/",
      "published_at": "2021-09-02T12:14:22Z",
      "updated_at": "2021-08-26T05:26:12Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Custom violation description tags are not being replaced by the values from the event. Solution Tags are only available for events that are indexed by New Relic. The easiest way to know whether an event is indexed is to run the query SELECT nr.entityType FROM ${EventSampleName}, replacing ${EventSampleName} with the name of the event in question. If there are values in the column nr.entity Type of the result, then the event is indexed. Otherwise it is not. Cause It is not possible to add a description to any sample that does not get indexed in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.24478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tag information not showing up for entity in Infra <em>alert</em> condition",
        "sections": "Tag information not showing up for entity in Infra <em>alert</em> condition",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Problem Custom violation description tags are not being replaced by the values from the event. Solution Tags are only available for events that are indexed by <em>New</em> <em>Relic</em>. The easiest way to know whether an event is indexed is to run the query SELECT nr.entityType FROM ${EventSampleName}, replacing"
      },
      "id": "6130c01ee7b9d2528bb6f226"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.76614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/tag-information-not-showing-entity-infra-alert-condition": [
    {
      "sections": [
        "Missing alert notifications",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Missing alert notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Troubleshooting"
      ],
      "external_id": "e3e6a1978efcc2399b42d59211e5bc319a87934f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/troubleshooting/missing-alert-notifications/",
      "published_at": "2021-09-02T12:13:23Z",
      "updated_at": "2021-08-26T05:21:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’ve set up policies and conditions that generate violations, but you aren’t getting notifications for them. Solution Check your muting rules. The rules you define can mute specific violations or mute notifications altogether. If you turn off your muting rules and start getting notifications again, you may want to rewrite your rules. Check your incident preferences. By default, a single incident record is created per policy. This option sends you the fewest number of notifications. If you want more notifications for each condition or violation in a policy, change your preferences. If you’re still having issues with missing notifications, your email may be on our suppression list. This prevents us from sending emails to your email address. To get your email removed from the list or to troubleshoot any other notification issues, contact our support team at support.newrelic.com. Here are some tips to avoid being placed on our suppression list: Field Description Confirm real email accounts for new users Many email bounce-backs happen when a user is added, but before their email is confirmed. This causes the email to be added to our suppression list before the user can receive the confirmation email. Check your distribution lists When one email address on a distribution list fails, the entire distribution list is added to our suppression list. To avoid this, make sure invalid or outdated email addresses are removed from your distribution lists. Add your email to our allow list Many messages can end up in you or your company’s spam filter. To ensure your system recognizes emails sent by us, add noreply@newrelic.com and * @mailer-d.newrelic.com to your allow list or “Safe Senders” list as a trusted email source. Consider other delivery options In general, email isn’t the most reliable way to receive notifications. For your most important alerts, set up alternate means of communication as a backup. Cause We use an email service that manages all of the alerts notification emails. When our service provider receives an error after an email is sent, the address is added to our suppression list. This is done to stay in line with email delivery best practices, which keeps the newrelic.com domain off of email deny lists.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.23111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>alert</em> notifications",
        "sections": "Missing <em>alert</em> notifications",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ". If you’re still having issues with missing notifications, your email may be on our suppression list. This prevents us from sending emails to your email address. To get your email removed from the list or to <em>troubleshoot</em> any other notification issues, contact our support team at support.newrelic.com"
      },
      "id": "6130bfe3e7b9d2367fb6f225"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.76605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> conditions",
        "sections": "<em>Alert</em> conditions <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " a NRQL <em>alert</em> condition for a policy: On one.newrelic.com, in the header click <em>Alerts</em> &amp; AI, then in the left sidebar click Policies. Select an existing policy or click <em>New</em> <em>alert</em> policy to create a <em>new</em> policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/provide-runbook-instructions-alert-activity": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts": [
    {
      "sections": [
        "Introduction to Alerts",
        "Build a comprehensive alerting solution",
        "Unique, intelligent features",
        "Data security and privacy",
        "What's next?"
      ],
      "title": "Introduction to Alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "f6106d47daa4f224a524fac942240bad22322f35",
      "image": "https://docs.newrelic.com/static/e3443ab0a75369f185c84676e46c0ee0/c1b63/new-relic-set-thresholds-example_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/introduction-alerts/",
      "published_at": "2021-09-02T05:07:49Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you set up robust and customizable alert policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive alerting solution Go to one.newrelic.com, then click Alerts & AI > Create condition: This shows the threshold-setting UI page when creating an alert condition. We give you control over every part of creating a robust alerting solution for your applications and architecture: Decision Steps Decide what to monitor. You can set up alert conditions for any monitored data source. Whether your architecture has just a few components or many, you'll be able to create an effective alerting solution. Define how it will be monitored. You can define exactly what data source behavior opens a violation. Unique features include: Extensive control over the time and frequency settings that opens a violation and a notification. Set critical thresholds for obvious performance problems and optional warning thresholds for when behavior is approaching critical. Baseline alert conditions that automatically adjust to your system's behavior. You decide how sensitive you want the thresholds to be. Decide how incidents are generated. To reduce notification fatigue, incident preference settings give you control over how notifications are created. For example, you may want to receive a notice for every violation or only want a single notification for a series of consecutive violations. Decide how notifications are sent. We offer customizable notification channels via many common services, including email, mobile push notifications, OpsGenie, Slack, and more. To see supported services, see Notification channels. Unique, intelligent features Besides the standard controls you'd expect from a complete alerting solution, we offer some unique and powerful features, including: Feature Details Self-adjusting monitoring Baseline alert conditions allow you to create intelligent, self-adjusting conditions. Anomaly detection An anomalous behavior indicator automatically detects when a violation has occurred within a few minutes of major changes in key database or external service activity. Detect outliers from group behavior Use outlier detection to detect when one or more data sources in a defined group deviate from the behavior you expect from that group. Custom query conditions Using our NRQL query language, create a customized query, and then monitor the results of that query for deviations over time. NerdGraph API Use our GraphQL NerdGraph API to interact with alerts. We recommend the NerdGraph API over the REST API because it has the latest features. Alerts REST API Use the REST API to return information about your alert settings or to create alert policies and conditions. We recommend you start with the NerdGraph API to see if it has the options you need. Webhooks Customizable webhooks allow you to define custom headers, basic authentication, custom payloads, and more. Incident scoping and rollups Every alert policy can be configured to use one of three violation grouping strategies to control the number of alert incidents created, and therefore the number of notifications sent. Cross-product events A dedicated Events page that shows operational events across all of your products. Data security and privacy By default, Alerts doesn't record any personal data. In addition, it automatically sets default permissions for individual account users and access levels within account structures. For more information about our security measures, see our security and privacy documentation, or visit our security website. What's next? If you're new to using Alerts and want to learn more, see: The basic process Best practices",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.11261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Alerts</em>",
        "sections": "Introduction to <em>Alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " API over the REST API because it has the latest features. <em>Alerts</em> REST API Use the REST API to return information about your <em>alert</em> settings or to create <em>alert</em> policies and conditions. We recommend you <em>start</em> with the NerdGraph API to see if it has the options you need. Webhooks Customizable webhooks"
      },
      "id": "61305c25196a675f364948f3"
    },
    {
      "sections": [
        "Alerts concepts and workflow",
        "Introduction to important concepts",
        "Basic workflow",
        "What's next?"
      ],
      "title": "Alerts concepts and workflow",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "3b55e4e4b49e0734012ae9b0531651b03ceac1a8",
      "image": "https://docs.newrelic.com/static/9d0aa6988700b46be4f583d3db6f604a/c1b63/new-relic-alert-creation-workflow-diagram.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/alerts-concepts-workflow/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you create customized alerting solutions for monitoring your system. When you set up alerts, you can get notified about problems you're interested in. To help you get started, here are some alerts concepts and the workflow you'll follow. Introduction to important concepts To use alerts well, it will help you to understand the general flow of how the conditions and policies you create lead to violations and notifications. To use alerts well, it will help you to understand the terms we use: Alerts terminology Comments Policy A policy is a group of one or more alert conditions. You must create a policy before you can add conditions to it. A policy has two settings that apply to all of its conditions: incident preference and notification channels (explained more below). Condition A condition includes: a) a monitored data source and b) thresholds that define the behavior that's considered a violation. For example, a specific condition might be described in this way: \"If the response time for any page load in my app goes above 8 seconds and lasts for more than 5 minutes, that's a violation.\" Threshold A threshold is part of a condition; it defines the behavior that's considered a violation. When you create a condition, there's a required critical-level threshold. Optionally, you can set a secondary warning-level threshold. Violation A violation occurs when the value of a data source crosses a condition's threshold. This leads to the creation of a violation event, which is used to pass important information downstream. A violation doesn't directly generate a notification; a violation may lead to an incident, which in turn can generate notifications. Incident Incidents are what generate notifications. At the policy level, the incident preference determines how violations are handled and combined to generate incidents. For example, you may want to have every single violation generate an incident (many notifications) or you may want to have only a single incident open at a time across an entire alert policy (minimal notifications). Setting the incident preference gives you power over how notifications are created and helps prevent notification fatigue. Notification At the policy level, you choose what team members are notified when an incident occurs and how they're notified. We offer several notification channels, including webhooks, Slack rooms, email, etc. You can include charts about the incident to provide context, and share them with your team's notification. For in-depth definitions of these and other terms, see the glossary. Basic workflow Now that you understand some basic concepts and terms, let's look at a typical process for creating a policy and an associated condition: Create a policy. When you create a policy: Give it a meaningful name. For example: the group or team's name, or the set of resources or services the policy targets. Set the incident preference, which determines how violations become incidents. Set notification channels. Create a condition that will be attached to that policy. Steps involved in creating a condition include: Choose a data source that will be monitored (for example, an APM metric or a NRQL query). Set the thresholds that define what behavior will produce a violation. Optional: Include a runbook URL, which is used to share standard procedures for how to handle alert notifications. Optional: Add more conditions to that same policy. In addition to receiving notifications, you can view the alert incident or event details in New Relic One. What's next? To learn more about using alerts: Read our best practices. Learn about the API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.11261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> concepts <em>and</em> workflow",
        "sections": "<em>Alerts</em> concepts <em>and</em> workflow",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " URL, which is used to share standard procedures for how to handle <em>alert</em> notifications. Optional: Add more conditions to that same policy. In addition to receiving notifications, you can view the <em>alert</em> incident or event details in <em>New</em> <em>Relic</em> One. What&#x27;s next? To learn more about using <em>alerts</em>: Read our best practices. Learn about the API."
      },
      "id": "61305bef196a673eac4948d2"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.44681,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.2049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.12073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/violation-event-attributes": [
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.46808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> condition <em>violations</em> are closed",
        "sections": "How <em>alert</em> condition <em>violations</em> are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> <em>violations</em> will have a violation time limit <em>applied</em> to them. Most <em>alert</em> conditions will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    },
    {
      "sections": [
        "View entity health status and find entities without alert conditions",
        "Important",
        "Exceptions",
        "Color-coded health status",
        "Health status transitions",
        "Example: App without conditions",
        "Example: App with conditions",
        "Tip"
      ],
      "title": "View entity health status and find entities without alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "b2826e95805df46a371e48e17c2439cf566240e8",
      "image": "https://docs.newrelic.com/static/e9ca85d8e1b3cf5d1ab549e0a3955990/38cea/032715crop-events-no-v3_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/view-entity-health-status-find-entities-without-alert-conditions/",
      "published_at": "2021-09-02T12:14:22Z",
      "updated_at": "2021-08-26T05:25:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With alerts you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current alert violations, mouse over its health status indicator. If no, its health status indicator on the selected index will appear grey. Important To learn more about how conditions and policies work together, see Introduction to important concepts. Exceptions The health status indicator doesn't apply for: NRQL alert conditions Infrastructure entities Dashboards Entities targeted by labels Color-coded health status The index automatically appears when you select the product from the New Relic menu bar. For example, to view the index of APM apps, go to one.newrelic.com, then click APM. The Applications index lists all APM product entities and their current health status. Color Health status Green The entity is operational. We are collecting data that you can view in the appropriate UI. No alert violations are currently reported for it. Yellow The entity is degraded. A warning threshold has been violated. Red A critical threshold has been violated: Notifications have been sent based on the selected incident rollup preference. The incident appears in the Incidents index. Gray The entity's status is unknown. We're not receiving alerts data for the entity. This could mean alerts are muted, not set up, or the reporting system is down. Health status transitions The following table describes the different health status transitions an entity can endure: From... To... Transition explanation Gray Green The entity is evaluated for at least one condition, and the results show there are no violations present. Green / Red Gray Possible explanations: The last condition associated to the entity has been deleted and therefore there's no status to report. The last condition associated to the entity has been disabled and therefore there's no status to report. The entity has stopped reporting data. There's a New Relic platform issue. Check the New Relic status page for updates. Green Yellow / Red There's at least one open violation at the time the entity is undergoing the evaluation. Yellow / Red Green The last open violation associated to the entity has been closed. Example: App without conditions Here's an example of an app listed on the APM index that is not associated with any conditions. Its color-coded health status is light grey, which indicates no alert conditions are set up for that entity. Go to one.newrelic.com, then click Explorer: This example shows an app that currently isn't associated with any alerts conditions. Its grey status icon means it doesn't have any conditions. Follow standard procedures to add it to an existing condition or to create a new condition for it. Example: App with conditions Here's an example of an app listed on the APM index that is associated with one or more conditions. Its color-coded health status is green, because we are collecting data for it, and currently there are no Warning (yellow) or Critical (red) violations. Go to one.newrelic.com, then click Explorer: This example shows an app that has one or more conditions. Its color-coded health status (green) shows the app hasn't reached any threshold violations. Tip To view the index listing currently open incidents across all products, not just this entity, select View all violations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.45268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View entity health status <em>and</em> find entities without <em>alert</em> conditions",
        "sections": "View entity health status <em>and</em> find entities without <em>alert</em> conditions",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "With <em>alerts</em> you can easily tell whether an entity (the target for the notification) has one or more conditions associated with it: If yes, its health status indicator on the selected index (APM, browser, etc.) will be color-coded to the current state. To view a summary of current <em>alert</em> <em>violations</em>"
      },
      "id": "6130c01e196a679fa84948f5"
    },
    {
      "sections": [
        "Rules and limits for alerts",
        "Permission levels",
        "New Relic One pricing plan",
        "Original pricing plan",
        "Limits",
        "Tip"
      ],
      "title": "Rules and limits for alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Rules, limits, and glossary"
      ],
      "external_id": "21a79b6a8acf57efc16c3fae83e5167367b82452",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/rules-limits-alerts/",
      "published_at": "2021-09-02T05:07:49Z",
      "updated_at": "2021-08-26T05:49:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains some technical rules and limits for alerts. Permission levels Permissions differ depending on whether you're on our original product-based pricing plan or our New Relic One pricing plan: New Relic One pricing plan See Users and roles. Original pricing plan For accounts on our original product-based pricing plan, the user role determines the Alerts features available: Owner and Admins can add, change, disable, and delete alert policies, conditions, and channels. Users and Restricted Users can only view alert policies and conditions and their settings. Any user role can acknowledge an incident or close a violation. Limits If your organization has a parent/child account structure, child accounts do not inherit a parent account's alert policies: You must create policies separately for all child accounts. The following rules apply both to the New Relic One user interface and to the REST API (v2). New Relic Alerts Minimum value Maximum value Alert policies: Alert policy name 1 character 64 characters Policies per account n/a 10000 policies Products per policy any New Relic product (APM, mobile monitoring, synthetic monitoring, etc.) any New Relic product Alert conditions: Condition name 1 character 128 characters Conditions per policy 0 conditions 500 conditions Infrastructure alert conditions 0 conditions 3700 conditions NRQL query conditions OR Web app response percentiles per account 0 conditions 4000 conditions Targets (product entities) per condition 1 target 1000 targets from 1 or more products Thresholds per condition 0 Warnings, 1 Critical 1 Warning, 1 Critical Alert violations: Custom violation descriptions 4000 characters Duration for condition violation 5 minutes Exception: 1 minute for at least once conditions, because the violation could occur during the first minute (or any minute). 2 hours Violations per incident 1 violation 10,000 violations Violations beyond this limit will not be persisted. Violation Search API - Page Size 1 page (less than or equal to 25 violations) 1000 pages (25K violations) Tip Only use the only-open parameter to retrieve all open violations. If you have more than 25K open violations and need to retrieve them via the REST API, please contact New Relic Support. Notification channels: Notification channel name 1 character 64 characters Channels per account n/a 2500 channels per type Exception: No limits for user channels Channel limitations Depends on channel Depends on channel",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.6369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rules <em>and</em> limits for <em>alerts</em>",
        "sections": "Rules <em>and</em> limits for <em>alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " interface and to the REST API (v2). <em>New</em> <em>Relic</em> <em>Alerts</em> Minimum value Maximum value <em>Alert</em> policies: <em>Alert</em> policy name 1 character 64 characters Policies per account n&#x2F;a 10000 policies Products per policy any <em>New</em> <em>Relic</em> product (APM, mobile monitoring, synthetic monitoring, etc.) any <em>New</em> <em>Relic</em> product <em>Alert</em>"
      },
      "id": "60442974196a678217960f33"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "Create NRQL alert conditions",
        "Tip",
        "Create a NRQL alert condition",
        "Create a condition from a chart",
        "Caution",
        "NRQL alert syntax",
        "Important",
        "Reformatting incompatible NRQL",
        "NRQL alert threshold examples",
        "Alert on specific segments of your data",
        "Alert on Nth percentile of your data",
        "Alert on max, min, avg of your data",
        "Alert on a percentage of your data",
        "Alert on Apdex with any T-value",
        "Alert conditions and query order of operations",
        "Example: null value returned",
        "Example: zero value returned",
        "Nested aggregation NRQL alerts",
        "Nested queries with a non-faceted innermost query are not currently supported",
        "Queries at all levels must have the same aggregation window size",
        "Signal loss is not yet supported for nested queries",
        "Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported",
        "NRQL condition creation tips",
        "Alert threshold types",
        "Sum of query results (limited or intermittent data)",
        "Set the loss of signal threshold",
        "Advanced signal settings",
        "Aggregation window",
        "Evaluation offset",
        "Fill data gaps"
      ],
      "title": "Create NRQL alert conditions",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "2872f770a5fc8a802f99b9f848906f7e351ad761",
      "image": "https://docs.newrelic.com/static/eb8e1b2d826f9fd9cf46fe3dd5455217/c1b63/nr1_nrql_alert_conditions.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/",
      "published_at": "2021-09-02T04:57:07Z",
      "updated_at": "2021-09-02T04:57:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use NRQL queries to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts violation is created. Read on to learn more about how to do this. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Click NRQL, and then Next, define thresholds. Tip For more information on key concepts relating to NRQL alert conditions and streaming alerts, see Streaming alerts: key terms and concepts. Create a NRQL alert condition To create a NRQL alert condition for a policy: On one.newrelic.com, in the header click Alerts & AI, then in the left sidebar click Policies. Select an existing policy or click New alert policy to create a new policy. Click Add a condition. Under Select a product click NRQL, and then click Next, define thresholds. Create a condition from a chart You can use a chart to create a NRQL alert condition. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Caution A small number of our older charts don't include the option to create an alert condition. NRQL alert syntax Here's the basic syntax for creating all NRQL alert conditions. The FACET clause is required for outlier threshold types. It's optional for static and baseline. SELECT function(attribute) FROM Event WHERE attribute [comparison] [AND|OR ...] Copy Clause Notes SELECT function(attribute) Required Supported functions that return numbers include: apdex average count latest max min percentage percentile sum uniqueCount Tip If you use the percentile aggregator in a faceted alert condition with many facets, this may cause the following error to appear: An error occurred while fetching chart data. If you see this error, use average instead. FROM data type Required Only one data type can be targeted. Supported data types: Event Metric (RAW data points will be returned) WHERE attribute [comparison] [AND|OR ...] Use the WHERE clause to specify a series of one or more conditions. All the operators are supported. FACET attribute Required for outlier conditions Include an optional FACET clause in your NRQL syntax depending on the threshold type: static or baseline. Use the FACET clause to separate your results by attribute and alert on each attribute independently. No LIMIT clause is allowed, but all queries will receive the maximum number of facets possible. Faceted queries can return a maximum of 5000 values for static and baseline conditions and a maximum of 500 values for outlier conditions. Important If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values. Reformatting incompatible NRQL Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect. Element Notes SINCE and UNTIL Example: SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday Copy NRQL Alerting produces a never-ending stream of windowed query results, so the SINCE and UNTIL keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip SINCE and UNTIL from a query when creating a NRQL Alert Condition from the context of a chart. TIMESERIES In NRQL queries, the TIMESERIES clause is used to return data as a time series broken out by a specified period of time. For NRQL alerts, the equivalent property of a signal is the aggregation window. histogram() The histogram() aggregation function is used to generate histograms. histogram() is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (e.g. 95th percentile), use the percentile() aggregation function. Multiple Aggregation Functions Each alert condition can only target a single aggregated stream of data. To alert on multiple streams simultaneously, you’ll need to decompose them into individual conditions within the same policy. Original Query: SELECT count(foo), average(bar), max(baz) from Transaction Copy Decomposed: SELECT count(foo) from Transaction SELECT average(bar) from Transaction SELECT max(baz) from Transaction Copy COMPARE WITH The COMPARE WITH clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a Baseline Alert Condition to dynamically detect deviations for a particular signal. SLIDE BY The SLIDE BY clause supports a feature known as sliding windows. With sliding windows, SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. Sliding windows are not currently supported in NRQL alerts. LIMIT In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set. NRQL alert threshold examples Here are some common use cases for NRQL alert conditions. These queries will work for static and baseline threshold types. The outlier threshold type will require additional FACET clauses. Alert on specific segments of your data Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the WHERE clause to define those conditions. SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230) Copy SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%' Copy Alert on Nth percentile of your data Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query in one-minute time windows, percentiles will be calculated for each minute separately. SELECT percentile(duration, 95) FROM Transaction Copy SELECT percentile(databaseDuration, 75) FROM Transaction Copy Alert on max, min, avg of your data Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold. SELECT max(duration) FROM Transaction Copy SELECT average(duration) FROM Transaction Copy Alert on a percentage of your data Create alerts when a proportion of your data goes above or below a certain threshold. SELECT percentage(count(*), WHERE duration > 2) FROM Transaction Copy SELECT percentage(count(*), WHERE httpResponseCode = '500') FROM Transaction Copy Alert on Apdex with any T-value Create alerts on Apdex, applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8. SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%' Copy Alert conditions and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL alert condition’s query. The query is parsed and executed by our systems in the following order: FROM clause – which event type needs to be grabbed? WHERE clause – what can be filtered out? SELECT clause – what information needs to be returned from the now-filtered data set? Example: null value returned Let's say this is your alert condition query: SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE' Copy If there are no failures for the aggregation window: The system will execute the FROM clause by grabbing all SyntheticCheck events on your account. Then it will execute the WHERE clause to filter through those events by looking only for the ones that match the monitor name and result specified. If there are still events left to scan through after completing the FROM and WHERE operations, the SELECT clause will be executed. If there are no remainig events, the SELECT clause will not be executed. This means that aggregators like count() and uniqueCount() will never return a zero value. When there is a count of 0, the SELECT clause is ignored and no data is returned, resulting in a value of NULL. Example: zero value returned If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values. Let's say this is your alert condition query, and that MyCoolEvent is an attribute that can sometimes return a zero value. SELECT average(MyCoolAttribute) FROM MyCoolEvent Copy If, in the aggregation window being evaluated, there's at least one instance of MyCoolEvent and if the average value of all MyCoolAttribute attributes from that window is equal to zero, then a 0 value will be returned. If there are no MyCoolEvent events during that minute, then a NULL will be returned due to the order of operations. Tip For more information about this topic, you can check out our blog post on troubleshooting for zero versus null values. Tip You can determine how null values will be handled by adjusting loss of signal and gap filling settings in the Alert Conditions UI. Tip You can avoid NULL values entirely with a query order of operations shortcut. Do this by using a filter sub-clause, then including all filter elements within that sub-clause. The main body of the query will run and return data, at which point the SELECT clause will then run and apply the filter elements. The query will return a value of 0 if the filter elements result in no matching data. Here's an example: SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck Copy Nested aggregation NRQL alerts Nested aggregation queries are a powerful way to query your data. However, they have a few restrictions that are important to note. Nested queries with a non-faceted innermost query are not currently supported Without a FACET, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu) ​​​​​ Copy Queries at all levels must have the same aggregation window size With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported. SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​ Copy Signal loss is not yet supported for nested queries For more information on signal loss, see NerdGraph API: Loss of signal and gap filling. Nested queries containing 'WITH METRIC_FORMAT' in the inner query are not currently supported You can't use a nested query containing the WITH METRIC_FORMAT in the inner query to create NRQL alert conditions. NRQL condition creation tips Here are some tips for creating and using a NRQL condition: Topic Tips Condition threshold types NRQL condition threshold types include static, baseline, and outlier. Create a description For NRQL conditions, you can create a custom description to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation. For details, see Description Query results Queries must return a number. The condition evaluates the returned number against the thresholds you've set. Time period As with all alert conditions, NRQL conditions evaluate one single minute at a time. The implicit SINCE ... UNTIL clause specifying which minute to evaluate is controlled by your Evaluation offset setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for: Applications that run on multiple hosts. SyntheticCheck data: Timeouts can take 3 minutes, so 5 minutes or more is recommended. Also, if a query will generate intermittent data, consider using the sum of query results option. Lost signal threshold (loss of signal detection) You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in. Advanced signal settings These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window, the evaluation offset, and an option for filling data gaps. For more on using these, see Advanced signal settings. Condition settings Use the Condition settings to: Create a concise, descriptive condition name. Provide a custom violation description for the condition that will be included in violations and notifications. Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the custom violation description. Limits on conditions See the maximum values. Health status NRQL alert conditions don't affect an entity's health status display. Examples For more information, see: Expected NRQL syntax Examples of NRQL condition queries Alert threshold types When you create a NRQL alert, you can choose from different types of thresholds: NRQL alert threshold types Description Static This is the simplest type of NRQL threshold. It allows you to create a condition based on a NRQL query that returns a numeric value. Optional: Include a FACET clause. Baseline (Dynamic) Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type. Outlier Looks for group behavior and values that are outliers from those groups. Uses the same NRQL query form as the static type, but requires a FACET clause. Sum of query results (limited or intermittent data) Important Available only for static (basic) threshold types. If a query returns intermittent or limited data, it may be difficult to set a meaningful threshold. Missing or limited data will sometimes generate false positives or false negatives. You can use loss of signal, aggregation duration, and gap filling settings to minimize these false notifications. To avoid this problem when using the static threshold type, you can set the selector to sum of query results. This lets you set the alert on an aggregated sum instead of a value from a single harvest cycle. Up to two hours of one-minute data checks can be aggregated. The duration you select determines the width of the rolling sum and the preview chart will update accordingly. Set the loss of signal threshold Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and and also what happens when the threshold is crossed. Go to one.newrelic.com, click Alerts & AI, in the left sidebar click Policies, select a policy, then Add a condition. Loss of signal is only available for NRQL conditions. You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific GraphQL API examples. Loss of signal settings: Loss of signal settings include a time duration and two possible actions. Signal loss expiration time UI label: Signal is lost after: GraphQL Node: expiration.expirationDuration Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the WHERE clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires. The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes. Loss of signal actions Once a signal is considered lost, you can close open violations, open new violations, or both. Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is \"closeViolationsOnExpiration\" Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is \"openViolationOnExpiration\" When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal. To create a NRQL alert configured with loss of signal detection in the UI: For a policy, when you create a condition, under Select a product, click NRQL, then click Next, define thresholds. Write a NRQL query that returns the values you want to alert on. For Threshold type, select Static or Baseline. Click + Add lost signal threshold, then set the signal expiration duration time in minutes or seconds in the Signal is lost after field. Choose what you want to happen when the signal is lost. You can check one or both of Close all current open violations and Open new \"lost signal\" violation. These control how loss of signal violations will be handled for the condition. Make sure you name your condition before you save it. Violations open due to loss of signal close when the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated. the condition they belong to expires. By default, conditions expire after 3 days. you manually close the violation with the Close all current open violations option. Tip Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries. Advanced signal settings When creating a NRQL alert condition, the advanced signal settings gives you better control over streaming alert data and helps you avoid false alarms. When creating a NRQL condition, there are several advanced signal settings: Aggregation window Evaluation offset Fill data gaps To read an explanation of what these settings are and how they relate to each other, see Streaming alerts concepts. Below are instructions and tips on how to configure them. Aggregation window You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between one second and 15 minutes. The default is one minute. Tip Baseline alert condition thresholds don't support editing the aggregation window. They use the 1 minute default. Evaluation offset You can adjust the evaluation offset to coordinate our streaming alerting algorithm with your data's latency. If it takes a while for your data to arrive, then you may need to increase the evaluation offset. The total supported latency is the product of the aggregation window duration multiplied by the evaluation offset. In the example screenshot above, the supported latency is 3 minutes (a 1-minute aggregation window multiplied by three windows). If the data type comes from an APM language agent and is aggregated from many app instances (for example, Transactions, TransactionErrors, etc.), we recommend using an evaluation offset of 3 with 1 minute aggregation windows. Important When creating NRQL conditions for data collected from Infrastructure Cloud Integrations such as AWS Cloudwatch or Azure, we recommend that you start with an evaluation offset of 15 minutes, then adjust up or down depending on how long it takes to collect your data. Fill data gaps Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings: None: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation. Custom static value: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of fillValue (as named in the API) that specifies what static value should be used. This defaults to 0. Last known value: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours. Tip The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals. To learn more about signal loss, gap filling, and how to request access to these features, see this Explorers Hub post. Options for editing data gap settings: In the NRQL conditions UI, go to Condition settings > Advanced signal settings > fill data gaps with and choose an option. If using our Nerdgraph API (preferred), this node is located at: actor : account : alerts : nrqlCondition : signal : fillOption | fillValue NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the \"signal\" section of the Alert NRQL conditions API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.1206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create NRQL <em>alert</em> <em>conditions</em>",
        "sections": "<em>Alert</em> <em>conditions</em> <em>and</em> query order of operations",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") FROM Transaction WHERE appName like &#x27;%prod%&#x27; Copy <em>Alert</em> <em>conditions</em> and query order of operations By default, the aggregation window is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, <em>New</em> <em>Relic</em> will collect data for that window using the function"
      },
      "id": "603ef04864441fbc114e8883"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions": [
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.20477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> <em>conditions</em> with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    },
    {
      "sections": [
        "How alert condition violations are closed",
        "How violations automatically close",
        "Manually close a violation",
        "Important",
        "Set a time limit for long-lasting violations"
      ],
      "title": "How alert condition violations are closed",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert violations"
      ],
      "external_id": "41e9d59a43c91f2364ae832f472f4c395986c355",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-violations/how-alert-condition-violations-are-closed/",
      "published_at": "2021-09-02T05:02:46Z",
      "updated_at": "2021-09-02T05:02:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains the different ways violations can be closed. How violations automatically close A violation will automatically close when the targeted signal returns to a non-violating state for the time period indicated in the condition's thresholds. This wait time is called the recovery period. For example: If the violating behavior is \"Apdex score below 0.80 at least once in 5 minutes,\" then the violation will automatically close when the Apdex score is equal to or higher than .80 for 5 consecutive minutes. The same applies to a \"for at least x minutes\" threshold: x minutes of non-violating behavior are required to automatically close the violation. When a violation closes automatically: The closing timestamp is backdated to the start of the recovery period. The evaluation resets and restarts from when the previous violation ended. All conditions have a violation time limit setting that will automatically force-close a long-lasting violation. Manually close a violation You can manually close an open violation. This is useful, for example, when a signal has violated the threshold, but it no longer exists and also doesn't have a violation time limit. (A time limit would automatically close a long-lasting violation.) To close a violation: Go to the open violation you want to close. Click Manually close violation. To close all violations associated with a condition: Go to the condition you want to close. Disable the condition and then re-enable it. Important An incident will close automatically when all of its associated critical violations have been closed. Set a time limit for long-lasting violations The violation time limit setting will automatically force-close a long-lasting violation after the number of days/hours you select. This is most useful for ephemeral entities that, when they disappear, cause a continual violation that won't automatically close. Limits and Defaults All alert violations will have a violation time limit applied to them. Most alert conditions will allow you to edit this field. The default value, if one is not supplied during configuration, is 3 days (24 hours for Infrastructure conditions). The violation time limit for non-Infrastructure conditions can be set as low as 5 minutes, and as high as 30 days. If, for some reason, the signal is still violating in 30 days, the violation will close, and a new violation will open. Infrastructure conditions can be set to the following hours: 1, 2, 4, 8, 12, 24, 48, or 72. Examples: You set the violation time limit to 12 hours. If that violation lasts for 12 hours, it will be closed at 12 hours and the condition's evaluation of that entity will be reset. Your JVM has a CPU spike and this creates a violation. The JVM then crashes and is replaced by a new JVM. If you have not set a violation time limit, the crashed JVM’s violation will never close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.19421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How <em>alert</em> <em>condition</em> violations are closed",
        "sections": "How <em>alert</em> <em>condition</em> violations are closed",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " for ephemeral entities that, when they disappear, cause a continual violation that won&#x27;t automatically close. Limits and Defaults All <em>alert</em> violations will have a violation time limit <em>applied</em> to them. Most <em>alert</em> <em>conditions</em> will allow you to edit this field. The default value, if one is not supplied during"
      },
      "id": "6043fcf2196a67dcce960f80"
    },
    {
      "sections": [
        "Monitor scheduled jobs",
        "What you need to know",
        "How it works",
        "Monitor a scheduled job"
      ],
      "title": "Monitor scheduled jobs",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "7035557029eaf95569b8a1abec0e2ccf749fceee",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/monitor-scheduled-jobs/",
      "published_at": "2021-09-02T12:06:07Z",
      "updated_at": "2021-08-29T12:07:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use critical thresholds and loss of signal settings to monitor scheduled jobs and be notified when they don't happen. For example, if your system has scheduled maintenance every 24 hours, you'd like to know when that maintenance doesn't happen. This technique only works for regularly scheduled jobs that occur more frequently than the maximum loss of signal threshold time of 48 hours. What you need to know In order to get the most out of this procedure, you'll need to know how to create a condition. This only works for Static or Baseline threshold types. How it works Typically, conditions use critical thresholds to trigger violations. However, you can also trigger violations with a loss of signal. To monitor a scheduled job and be notified if it doesn't happen, set your condition's threshold high or low enough so that it won't trigger a violation. That way, only a loss of signal will trigger a violation. Monitor a scheduled job Create a condition related to the job you want to monitor. In Set your condition thresholds, set the Critical threshold above or below where it would ever trigger. Click + Add lost signal threshold, then set the signal expiration duration time longer than your monitored job's scheduled cycle. Check Open new \"lost signal\" violation. Make sure you name your condition before you save it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.86026,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ", <em>conditions</em> use critical thresholds to trigger violations. However, you can also trigger violations with a loss of signal. To monitor a scheduled job and be notified if it doesn&#x27;t happen, set your condition&#x27;s threshold high or low enough so that it won&#x27;t trigger a violation. That way, only a loss of signal"
      },
      "id": "612b786ce7b9d2d569b6f241"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents": [
    {
      "sections": [
        "View events from their products",
        "View health status from product entities (targets)",
        "View events and activity lists from products",
        "Tip",
        "View event violations",
        "View all event types"
      ],
      "title": "View events from their products",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert incidents"
      ],
      "external_id": "4451bca9fa3a3dc738fafd0099409c8e90df4658",
      "image": "https://docs.newrelic.com/static/17ca06d35c7d290e100b436c4e9dbe9d/8c557/crop-apm-index-health_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products/",
      "published_at": "2021-09-02T12:09:16Z",
      "updated_at": "2021-08-26T05:37:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can view events and other activity for a specific entity from the New Relic One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity list. For instructions on how to view these details in Infrastructure, see the Infrastructure documentation. View health status from product entities (targets) To view information about the current status for an entity (alert condition target): From the menu bar, select the product (APM, Browser, etc.). The right side of the screen shows all of the violations for the entities listed. one.newrelic.com > APM : This example shows the violations for all of the APM applications for a specific account. The color-coded health states indicate Critical (red) conditions. View events and activity lists from products You can view a list of events and other activity from the index for the selected product. By selecting an event from the list, you can go directly to the selected entity's Summary page, where you can view detailed information. one.newrelic.com: Here's an example of a Summary of Application activity. It includes errors and violations. Depending on the product, the recent events and activity list also may appear on the selected entity's Overview page. Tip Exception: The index for dashboards and Synthetic monitoring doesn't include a list of recent events and other activity. View event violations To view an index of events resulting in condition violations across all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click Violations. The Violations index provides summary information about alerting events across all products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation (if available), select the Target. To view the condition that triggered the violation, select the Condition. To view incident details, select the Incident ID. View all event types To view an index of events for all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click All events. The All events index provides summary information about alerting events across available products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation, select its name from the Description. To view the condition that triggered the violation, select the condition's name from the Description. To view incident details, select the Incident ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.14703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View events <em>and</em> activity lists from products",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can view events and other activity for a specific entity from the <em>New</em> <em>Relic</em> One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity"
      },
      "id": "6130beec28ccbc673b56a861"
    },
    {
      "sections": [
        "Introduction to Alerts",
        "Build a comprehensive alerting solution",
        "Unique, intelligent features",
        "Data security and privacy",
        "What's next?"
      ],
      "title": "Introduction to Alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "f6106d47daa4f224a524fac942240bad22322f35",
      "image": "https://docs.newrelic.com/static/e3443ab0a75369f185c84676e46c0ee0/c1b63/new-relic-set-thresholds-example_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/introduction-alerts/",
      "published_at": "2021-09-02T05:07:49Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you set up robust and customizable alert policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive alerting solution Go to one.newrelic.com, then click Alerts & AI > Create condition: This shows the threshold-setting UI page when creating an alert condition. We give you control over every part of creating a robust alerting solution for your applications and architecture: Decision Steps Decide what to monitor. You can set up alert conditions for any monitored data source. Whether your architecture has just a few components or many, you'll be able to create an effective alerting solution. Define how it will be monitored. You can define exactly what data source behavior opens a violation. Unique features include: Extensive control over the time and frequency settings that opens a violation and a notification. Set critical thresholds for obvious performance problems and optional warning thresholds for when behavior is approaching critical. Baseline alert conditions that automatically adjust to your system's behavior. You decide how sensitive you want the thresholds to be. Decide how incidents are generated. To reduce notification fatigue, incident preference settings give you control over how notifications are created. For example, you may want to receive a notice for every violation or only want a single notification for a series of consecutive violations. Decide how notifications are sent. We offer customizable notification channels via many common services, including email, mobile push notifications, OpsGenie, Slack, and more. To see supported services, see Notification channels. Unique, intelligent features Besides the standard controls you'd expect from a complete alerting solution, we offer some unique and powerful features, including: Feature Details Self-adjusting monitoring Baseline alert conditions allow you to create intelligent, self-adjusting conditions. Anomaly detection An anomalous behavior indicator automatically detects when a violation has occurred within a few minutes of major changes in key database or external service activity. Detect outliers from group behavior Use outlier detection to detect when one or more data sources in a defined group deviate from the behavior you expect from that group. Custom query conditions Using our NRQL query language, create a customized query, and then monitor the results of that query for deviations over time. NerdGraph API Use our GraphQL NerdGraph API to interact with alerts. We recommend the NerdGraph API over the REST API because it has the latest features. Alerts REST API Use the REST API to return information about your alert settings or to create alert policies and conditions. We recommend you start with the NerdGraph API to see if it has the options you need. Webhooks Customizable webhooks allow you to define custom headers, basic authentication, custom payloads, and more. Incident scoping and rollups Every alert policy can be configured to use one of three violation grouping strategies to control the number of alert incidents created, and therefore the number of notifications sent. Cross-product events A dedicated Events page that shows operational events across all of your products. Data security and privacy By default, Alerts doesn't record any personal data. In addition, it automatically sets default permissions for individual account users and access levels within account structures. For more information about our security measures, see our security and privacy documentation, or visit our security website. What's next? If you're new to using Alerts and want to learn more, see: The basic process Best practices",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.78148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Alerts</em>",
        "sections": "Introduction to <em>Alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> lets you set up robust and customizable <em>alert</em> policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive"
      },
      "id": "61305c25196a675f364948f3"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/view-violation-event-details-incidents": [
    {
      "sections": [
        "View events from their products",
        "View health status from product entities (targets)",
        "View events and activity lists from products",
        "Tip",
        "View event violations",
        "View all event types"
      ],
      "title": "View events from their products",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert incidents"
      ],
      "external_id": "4451bca9fa3a3dc738fafd0099409c8e90df4658",
      "image": "https://docs.newrelic.com/static/17ca06d35c7d290e100b436c4e9dbe9d/8c557/crop-apm-index-health_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/view-events-their-products/",
      "published_at": "2021-09-02T12:09:16Z",
      "updated_at": "2021-08-26T05:37:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can view events and other activity for a specific entity from the New Relic One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity list. For instructions on how to view these details in Infrastructure, see the Infrastructure documentation. View health status from product entities (targets) To view information about the current status for an entity (alert condition target): From the menu bar, select the product (APM, Browser, etc.). The right side of the screen shows all of the violations for the entities listed. one.newrelic.com > APM : This example shows the violations for all of the APM applications for a specific account. The color-coded health states indicate Critical (red) conditions. View events and activity lists from products You can view a list of events and other activity from the index for the selected product. By selecting an event from the list, you can go directly to the selected entity's Summary page, where you can view detailed information. one.newrelic.com: Here's an example of a Summary of Application activity. It includes errors and violations. Depending on the product, the recent events and activity list also may appear on the selected entity's Overview page. Tip Exception: The index for dashboards and Synthetic monitoring doesn't include a list of recent events and other activity. View event violations To view an index of events resulting in condition violations across all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click Violations. The Violations index provides summary information about alerting events across all products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation (if available), select the Target. To view the condition that triggered the violation, select the Condition. To view incident details, select the Incident ID. View all event types To view an index of events for all available products: Go to one.newrelic.com, in the top nav click Alerts & AI, click Events, then click All events. The All events index provides summary information about alerting events across available products. From here, follow standard procedures to sort any column or select available links on any row to view drill-down details. For example: To view the Overview page for the entity associated with the violation, select its name from the Description. To view the condition that triggered the violation, select the condition's name from the Description. To view incident details, select the Incident ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.14703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View events <em>and</em> activity lists from products",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "You can view events and other activity for a specific entity from the <em>New</em> <em>Relic</em> One product index. For example, to find more information about a specific app in APM: Go to one.newrelic.com, in the top nav click APM, then mouse over the listed apps, or select an event from the Applications activity"
      },
      "id": "6130beec28ccbc673b56a861"
    },
    {
      "sections": [
        "Introduction to Alerts",
        "Build a comprehensive alerting solution",
        "Unique, intelligent features",
        "Data security and privacy",
        "What's next?"
      ],
      "title": "Introduction to Alerts",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "f6106d47daa4f224a524fac942240bad22322f35",
      "image": "https://docs.newrelic.com/static/e3443ab0a75369f185c84676e46c0ee0/c1b63/new-relic-set-thresholds-example_0.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/introduction-alerts/",
      "published_at": "2021-09-02T05:07:49Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you set up robust and customizable alert policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive alerting solution Go to one.newrelic.com, then click Alerts & AI > Create condition: This shows the threshold-setting UI page when creating an alert condition. We give you control over every part of creating a robust alerting solution for your applications and architecture: Decision Steps Decide what to monitor. You can set up alert conditions for any monitored data source. Whether your architecture has just a few components or many, you'll be able to create an effective alerting solution. Define how it will be monitored. You can define exactly what data source behavior opens a violation. Unique features include: Extensive control over the time and frequency settings that opens a violation and a notification. Set critical thresholds for obvious performance problems and optional warning thresholds for when behavior is approaching critical. Baseline alert conditions that automatically adjust to your system's behavior. You decide how sensitive you want the thresholds to be. Decide how incidents are generated. To reduce notification fatigue, incident preference settings give you control over how notifications are created. For example, you may want to receive a notice for every violation or only want a single notification for a series of consecutive violations. Decide how notifications are sent. We offer customizable notification channels via many common services, including email, mobile push notifications, OpsGenie, Slack, and more. To see supported services, see Notification channels. Unique, intelligent features Besides the standard controls you'd expect from a complete alerting solution, we offer some unique and powerful features, including: Feature Details Self-adjusting monitoring Baseline alert conditions allow you to create intelligent, self-adjusting conditions. Anomaly detection An anomalous behavior indicator automatically detects when a violation has occurred within a few minutes of major changes in key database or external service activity. Detect outliers from group behavior Use outlier detection to detect when one or more data sources in a defined group deviate from the behavior you expect from that group. Custom query conditions Using our NRQL query language, create a customized query, and then monitor the results of that query for deviations over time. NerdGraph API Use our GraphQL NerdGraph API to interact with alerts. We recommend the NerdGraph API over the REST API because it has the latest features. Alerts REST API Use the REST API to return information about your alert settings or to create alert policies and conditions. We recommend you start with the NerdGraph API to see if it has the options you need. Webhooks Customizable webhooks allow you to define custom headers, basic authentication, custom payloads, and more. Incident scoping and rollups Every alert policy can be configured to use one of three violation grouping strategies to control the number of alert incidents created, and therefore the number of notifications sent. Cross-product events A dedicated Events page that shows operational events across all of your products. Data security and privacy By default, Alerts doesn't record any personal data. In addition, it automatically sets default permissions for individual account users and access levels within account structures. For more information about our security measures, see our security and privacy documentation, or visit our security website. What's next? If you're new to using Alerts and want to learn more, see: The basic process Best practices",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.78148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Alerts</em>",
        "sections": "Introduction to <em>Alerts</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "<em>Alerts</em> lets you set up robust and customizable <em>alert</em> policies for anything that you can monitor. Receive notifications for fluctuations in key performance metrics as data streams in from all of our products, including APM, infrastructure, browser, mobile, and NRQL queries. Build a comprehensive"
      },
      "id": "61305c25196a675f364948f3"
    },
    {
      "sections": [
        "Create your first alert",
        "Step 1: Write your query",
        "Step 2: Name your NRQL condition",
        "Step 3: Set your condition thresholds",
        "Step 4: Create a policy",
        "What's next?"
      ],
      "title": "Create your first alert",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions",
        "NRQL"
      ],
      "external_id": "9fa48ac38d206d032db15f3b14e2db3163254bdb",
      "image": "https://docs.newrelic.com/static/de4c97b1a0e749c84cc1c7d5148fb691/22d0a/nrql-create-policy.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-09-02T05:06:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use our New Relic query language (NRQL) to create alerts conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that's important to you, and determines what you want to be notified about. The threshold determines when you’ll be notified. Follow these steps to write your first alerts condition using a NRQL query and a threshold. Once you're done, you'll have a working alert condition. Step 1: Write your query You can use a NRQL query to return data about how your environment is performing. Then, you can create a condition from that query. In this example, a condition is created for each host's CPU utilization (query), which will trigger a notification when the CPU utilization is above the 0.7% (threshold). Generally, you won't use thresholds below 1%, but this example simply shows you how to set up a threshold. Find the NRQL query builder at the top of the UI. Click the Query your data button to open the query builder and start writing a NRQL query. Once you've written a valid query, you can create a condition from it. The condition shows each host’s CPU utilization. Use this NRQL query, or something similar that's relevant to what you're monitoring, to create a condition. This query finds the average CPU utilization in an environment and then breaks it down (facets) by individual host names. Once you've created a valid NRQL query, click Create alert. Learn more about the NRQL syntax to create other useful queries. Step 2: Name your NRQL condition Give your NRQL condition a name that's meaningful to you. Step 3: Set your condition thresholds Set critical and warning thresholds to determine when you’re notified about your environment's performance. A critical threshold is required for your alerts condition. A warning threshold is optional. These thresholds don't create an incident or notify you like the critical threshold does. If a critical threshold opens an incident and notifies you, warning threshold violations created afterwards will be included in the report. In this example from the Set your condition thresholds section, our critical threshold (red) checks for any hosts with CPU utilization over 0.7% for at least 5 minutes. A warning threshold (yellow) is also added showing when any host's CPU utilization goes over 0.67% for at least 5 minutes. After you enter threshold values, you can see the threshold lines on the graph: Step 4: Create a policy Finally, add your condition to an existing policy or create a new one. When you create a new policy, you can group your violations by policy, condition, or by violation (this creates an incident for each violation). These incident preferences settings determine how frequently you're notified when there's a violation. What's next? Now that you've created your first condition, set up your incident preferences and notification channels. For a detailed, comprehensive overview of NRQL conditions, see Create NRQL alert conditions",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.30777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create your first <em>alert</em>",
        "sections": "Create your first <em>alert</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "Use our <em>New</em> <em>Relic</em> query language (NRQL) to create <em>alerts</em> conditions with ease. Your condition describes what you want to be notified about, and only requires two attributes: a query and a threshold. The query defines the data that&#x27;s important to you, and determines what you want to be notified"
      },
      "id": "61208dbb28ccbcc0bbf9abcc"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/delete-alert-notification-channels": [
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-09-02T12:07:14Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.97055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    },
    {
      "sections": [
        "Alerts concepts and workflow",
        "Introduction to important concepts",
        "Basic workflow",
        "What's next?"
      ],
      "title": "Alerts concepts and workflow",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "3b55e4e4b49e0734012ae9b0531651b03ceac1a8",
      "image": "https://docs.newrelic.com/static/9d0aa6988700b46be4f583d3db6f604a/c1b63/new-relic-alert-creation-workflow-diagram.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/alerts-concepts-workflow/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you create customized alerting solutions for monitoring your system. When you set up alerts, you can get notified about problems you're interested in. To help you get started, here are some alerts concepts and the workflow you'll follow. Introduction to important concepts To use alerts well, it will help you to understand the general flow of how the conditions and policies you create lead to violations and notifications. To use alerts well, it will help you to understand the terms we use: Alerts terminology Comments Policy A policy is a group of one or more alert conditions. You must create a policy before you can add conditions to it. A policy has two settings that apply to all of its conditions: incident preference and notification channels (explained more below). Condition A condition includes: a) a monitored data source and b) thresholds that define the behavior that's considered a violation. For example, a specific condition might be described in this way: \"If the response time for any page load in my app goes above 8 seconds and lasts for more than 5 minutes, that's a violation.\" Threshold A threshold is part of a condition; it defines the behavior that's considered a violation. When you create a condition, there's a required critical-level threshold. Optionally, you can set a secondary warning-level threshold. Violation A violation occurs when the value of a data source crosses a condition's threshold. This leads to the creation of a violation event, which is used to pass important information downstream. A violation doesn't directly generate a notification; a violation may lead to an incident, which in turn can generate notifications. Incident Incidents are what generate notifications. At the policy level, the incident preference determines how violations are handled and combined to generate incidents. For example, you may want to have every single violation generate an incident (many notifications) or you may want to have only a single incident open at a time across an entire alert policy (minimal notifications). Setting the incident preference gives you power over how notifications are created and helps prevent notification fatigue. Notification At the policy level, you choose what team members are notified when an incident occurs and how they're notified. We offer several notification channels, including webhooks, Slack rooms, email, etc. You can include charts about the incident to provide context, and share them with your team's notification. For in-depth definitions of these and other terms, see the glossary. Basic workflow Now that you understand some basic concepts and terms, let's look at a typical process for creating a policy and an associated condition: Create a policy. When you create a policy: Give it a meaningful name. For example: the group or team's name, or the set of resources or services the policy targets. Set the incident preference, which determines how violations become incidents. Set notification channels. Create a condition that will be attached to that policy. Steps involved in creating a condition include: Choose a data source that will be monitored (for example, an APM metric or a NRQL query). Set the thresholds that define what behavior will produce a violation. Optional: Include a runbook URL, which is used to share standard procedures for how to handle alert notifications. Optional: Add more conditions to that same policy. In addition to receiving notifications, you can view the alert incident or event details in New Relic One. What's next? To learn more about using alerts: Read our best practices. Learn about the API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.19223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> concepts <em>and</em> workflow",
        "sections": "<em>Alerts</em> concepts <em>and</em> workflow",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " URL, which is used to share standard procedures for how to handle <em>alert</em> <em>notifications</em>. Optional: Add more conditions to that same policy. In addition to receiving <em>notifications</em>, you can view the <em>alert</em> incident or event details in <em>New</em> <em>Relic</em> One. What&#x27;s next? To learn more about using <em>alerts</em>: Read our best practices. Learn about the API."
      },
      "id": "61305bef196a673eac4948d2"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-09-02T12:05:08Z",
      "updated_at": "2021-08-26T05:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for New Relic APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.51108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> condition",
        "sections": "Custom metric examples for <em>alert</em> <em>notifications</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> conditions page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ],
  "/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications": [
    {
      "sections": [
        "Customize your webhook payload",
        "Define webhooks",
        "Webhook values",
        "Targets values",
        "Webhook format example",
        "JSON webhook example",
        "Important",
        "Form webhook example",
        "Plain text output",
        "Microsoft Teams example"
      ],
      "title": "Customize your webhook payload",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert notifications"
      ],
      "external_id": "771a90b704617dff744104e22f88a06da9bcae9b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/customize-your-webhook-payload/",
      "published_at": "2021-09-02T12:07:14Z",
      "updated_at": "2021-08-27T08:29:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use webhooks as your alerts notification channel, you can use the default values. You can also customize the payload in the POST message for further integration into your system. Define webhooks When defining JSON webhooks, use the format \"name\":\"value\",. For example: \"current_state\":\"acknowledged\", Copy When defining static webhook variables in a form payload, use the format name=\"value\". For example: current_state=\"acknowledged\" Copy Do not include any custom, self-signed SSL certificates in your webhook. Our agents enable SSL by default. Due to our security policy, custom SSL certificates will not be imported into our Trust store. Webhooks with the $METADATA variable for Synthetics multi-location failure conditions are currently not supported. Webhook values We support these default dynamic webhook values. For your convenience, they are listed in alphabetical order, but you can define your webhook values in any order. You may also add custom variables by using your own key/value pairs. Key Variable \"account_id\" $ACCOUNT_ID Possible values: New Relic account ID (string) \"account_name\" $ACCOUNT_NAME Possible values: New Relic account name (string) \"closed_violations_count_critical\" $CLOSED_VIOLATIONS_COUNT_CRITICAL \"closed_violations_count_warning\" $CLOSED_VIOLATIONS_COUNT_WARNING \"condition_id\" $CONDITION_ID \"condition_description\" $DESCRIPTION This includes the description field from the alert condition, if there is one. \"condition_name\" $CONDITION_NAME Possible values: (user-defined string) \"current_state\" $EVENT_STATE Possible values: [open|acknowledged|closed] \"details\" $EVENT_DETAILS \"duration\" $DURATION \"event_type\" $EVENT_TYPE Possible values: [INCIDENT] \"incident_acknowledge_url\" $INCIDENT_ACKNOWLEDGE_URL \"incident_id\" $INCIDENT_ID \"incident_url\" $INCIDENT_URL \"metadata\" $METADATA Currently used only for Synthetic monitoring multi-location failure conditions. \"open_violations_count_critical\" $OPEN_VIOLATIONS_COUNT_CRITICAL \"open_violations_count_warning\" $OPEN_VIOLATIONS_COUNT_WARNING \"owner\" $EVENT_OWNER \"policy_name\" $POLICY_NAME Possible values: (user-defined string) \"policy_url\" $POLICY_URL \"runbook_url\" $RUNBOOK_URL \"severity\" $SEVERITY Possible values: [CRITICAL] \"targets\" $TARGETS The $TARGETS variable cannot be used with FORM data, but is compatible with JSON data. For static NRQL faceted alerts, the name of the facet that triggered the alert will be populated in the target’s name field. For a description of the available fields, see Target values. \"timestamp\" $TIMESTAMP \"timestamp_utc_string\" $TIMESTAMP_UTC_STRING A human-readable timestamp in the YYYY-MM-DD, HH:MM UTC format. \"version\" $VERSION \"violation_callback_url\" $VIOLATION_CALLBACK_URL \"violation_chart_url\" $VIOLATION_CHART_URL Targets values This section describes the $TARGETS field in your webhook. This data is not customizable and is provided here for reference. Your $TARGETS contain a list of zero or more targets (entities). Each target is described by a JSON object with the following fields. Key Variable \"id\" ID of the target or entity \"name\" Name of the target or entity \"labels\" Combined entity tags and NRQL facets that are derived from the condition evaluation and available entity tags. \"link\" URL link to this target or entity. \"product\" Type of product for this target or entity; for example, APM \"type\" Type of target or entity under product; for example, Application Webhook format example The following examples show a webhook payload using both the default dynamic variables and a custom variable. You can use some or all of the dynamic variables, along with any custom variables, to define your own payload. JSON webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. The \"team\": \"DevOps\" line is an example of a custom variable. { \"account_id\": \"$ACCOUNT_ID\", \"account_name\": \"$ACCOUNT_NAME\", \"closed_violations_count_critical\": \"$CLOSED_VIOLATIONS_COUNT_CRITICAL\", \"closed_violations_count_warning\": \"$CLOSED_VIOLATIONS_COUNT_WARNING\", \"condition_family_id\": \"$CONDITION_FAMILY_ID\", \"condition_id\": \"$CONDITION_ID\", \"condition_name\": \"$CONDITION_NAME\", \"current_state\": \"$EVENT_STATE\", \"details\": \"$EVENT_DETAILS\", \"duration\": \"$DURATION\", \"event_type\": \"$EVENT_TYPE\", \"incident_acknowledge_url\": \"$INCIDENT_ACKNOWLEDGE_URL\", \"incident_id\": \"$INCIDENT_ID\", \"incident_url\": \"$INCIDENT_URL\", \"open_violations_count_critical\": \"$OPEN_VIOLATIONS_COUNT_CRITICAL\", \"open_violations_count_warning\": \"$OPEN_VIOLATIONS_COUNT_WARNING\", \"owner\": \"$EVENT_OWNER\", \"policy_name\": \"$POLICY_NAME\", \"policy_url\": \"$POLICY_URL\", \"runbook_url\": \"$RUNBOOK_URL\", \"severity\": \"$SEVERITY\", \"targets\": \"$TARGETS\", \"timestamp\": \"$TIMESTAMP\", \"timestamp_utc_string\": \"$TIMESTAMP_UTC_STRING\", \"violation_callback_url\": \"$VIOLATION_CALLBACK_URL\", \"violation_chart_url\": \"$VIOLATION_CHART_URL\", \"team\": \"DevOps\" } Copy Form webhook example Important The following webhook example has extra spaces and line breaks for readability. Actual webhook responses are delivered as one continuous line of text. account_id=$ACCOUNT_ID account_name=$ACCOUNT_NAME closed_violations_count_critical=$CLOSED_VIOLATIONS_COUNT_CRITICAL closed_violations_count_warning=$CLOSED_VIOLATIONS_COUNT_WARNING condition_family_id=$CONDITION_FAMILY_ID condition_id=$CONDITION_ID condition_name=$CONDITION_NAME current_state=$EVENT_STATE details=$EVENT_DETAILS duration=$DURATION event_type=$EVENT_TYPE incident_acknowledge_url=$INCIDENT_ACKNOWLEDGE_URL incident_id=$INCIDENT_ID incident_url=$INCIDENT_URL open_violations_count_critical=$OPEN_VIOLATIONS_COUNT_CRITICAL open_violations_count_warning=$OPEN_VIOLATIONS_COUNT_WARNING owner=$EVENT_OWNER policy_name=$POLICY_NAME policy_url=$POLICY_URL runbook_url=$RUNBOOK_URL severity=$SEVERITY timestamp=$TIMESTAMP timestamp_utc_string=$TIMESTAMP_UTC_STRING violation_callback_url=$VIOLATION_CALLBACK_URL violation_chart_url=$VIOLATION_CHART_URL team=\"DevOps\" <--[example of custom variable] Copy Plain text output New Relic Alert Incident open: CPU > 50% for 5 minutes Policy: http://alerts.newrelic.com/accounts/1234/policies/5678 Chart URL: http://gorgon.nr-assets.net/image/12345678-abcd-efgh-ijkl-1234567890 For more details, see: http://alerts.newrelic.com/accounts/1234/incidents/3456 Copy Microsoft Teams example { \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"summary\": \"$CONDITION_NAME\", \"sections\": [{ \"activityTitle\": \"$CONDITION_NAME\", \"activitySubtitle\": \"$POLICY_NAME\", \"activityImage\": \"https://newrelic.com/themes/custom/curio/assets/mediakit/NR_logo_Horizontal_Rev.png\", \"facts\": [{ \"name\": \"Timestamp\", \"value\": \"$TIMESTAMP_UTC_STRING\" }, { \"name\": \"Account ID\", \"value\": \"$ACCOUNT_ID\" }, { \"name\": \"Account Name\", \"value\": \"$ACCOUNT_NAME\" }, { \"name\": \"Severity\", \"value\": \"$SEVERITY\" }, { \"name\": \"State\", \"value\": \"$EVENT_STATE\" }, { \"name\": \"Duration\", \"value\": \"$DURATION\" }, { \"name\": \"Details\", \"value\": \"$EVENT_DETAILS\" }], \"markdown\": true }, { \"text\": \"$METADATA<p><img src=\\\"$VIOLATION_CHART_URL\\\" alt=\\\"Incident Chart\\\"></img></p>\" }], \"potentialAction\": [{ \"@type\": \"OpenUri\", \"name\": \"View Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Acknowledge Incident\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$INCIDENT_ACKNOWLEDGE_URL\" }] }, { \"@type\": \"OpenUri\", \"name\": \"Open Runbook\", \"targets\": [{ \"os\": \"default\", \"uri\": \"$RUNBOOK_URL\" }] }] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.97055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": "=$VIOLATION_CHART_URL team=&quot;DevOps&quot; &lt;--[example of custom variable] Copy Plain text output <em>New</em> <em>Relic</em> <em>Alert</em> Incident open: CPU &gt; 50% for 5 minutes Policy: http:&#x2F;&#x2F;<em>alerts</em>.newrelic.com&#x2F;accounts&#x2F;1234&#x2F;policies&#x2F;5678 Chart URL: http:&#x2F;&#x2F;gorgon.nr-assets.net&#x2F;image&#x2F;12345678-abcd-efgh-ijkl-1234567890 For more details"
      },
      "id": "6128a26a196a671aa500b327"
    },
    {
      "sections": [
        "Alerts concepts and workflow",
        "Introduction to important concepts",
        "Basic workflow",
        "What's next?"
      ],
      "title": "Alerts concepts and workflow",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Get started"
      ],
      "external_id": "3b55e4e4b49e0734012ae9b0531651b03ceac1a8",
      "image": "https://docs.newrelic.com/static/9d0aa6988700b46be4f583d3db6f604a/c1b63/new-relic-alert-creation-workflow-diagram.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/learn-alerts/alerts-concepts-workflow/",
      "published_at": "2021-09-02T05:06:55Z",
      "updated_at": "2021-08-26T05:47:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Alerts lets you create customized alerting solutions for monitoring your system. When you set up alerts, you can get notified about problems you're interested in. To help you get started, here are some alerts concepts and the workflow you'll follow. Introduction to important concepts To use alerts well, it will help you to understand the general flow of how the conditions and policies you create lead to violations and notifications. To use alerts well, it will help you to understand the terms we use: Alerts terminology Comments Policy A policy is a group of one or more alert conditions. You must create a policy before you can add conditions to it. A policy has two settings that apply to all of its conditions: incident preference and notification channels (explained more below). Condition A condition includes: a) a monitored data source and b) thresholds that define the behavior that's considered a violation. For example, a specific condition might be described in this way: \"If the response time for any page load in my app goes above 8 seconds and lasts for more than 5 minutes, that's a violation.\" Threshold A threshold is part of a condition; it defines the behavior that's considered a violation. When you create a condition, there's a required critical-level threshold. Optionally, you can set a secondary warning-level threshold. Violation A violation occurs when the value of a data source crosses a condition's threshold. This leads to the creation of a violation event, which is used to pass important information downstream. A violation doesn't directly generate a notification; a violation may lead to an incident, which in turn can generate notifications. Incident Incidents are what generate notifications. At the policy level, the incident preference determines how violations are handled and combined to generate incidents. For example, you may want to have every single violation generate an incident (many notifications) or you may want to have only a single incident open at a time across an entire alert policy (minimal notifications). Setting the incident preference gives you power over how notifications are created and helps prevent notification fatigue. Notification At the policy level, you choose what team members are notified when an incident occurs and how they're notified. We offer several notification channels, including webhooks, Slack rooms, email, etc. You can include charts about the incident to provide context, and share them with your team's notification. For in-depth definitions of these and other terms, see the glossary. Basic workflow Now that you understand some basic concepts and terms, let's look at a typical process for creating a policy and an associated condition: Create a policy. When you create a policy: Give it a meaningful name. For example: the group or team's name, or the set of resources or services the policy targets. Set the incident preference, which determines how violations become incidents. Set notification channels. Create a condition that will be attached to that policy. Steps involved in creating a condition include: Choose a data source that will be monitored (for example, an APM metric or a NRQL query). Set the thresholds that define what behavior will produce a violation. Optional: Include a runbook URL, which is used to share standard procedures for how to handle alert notifications. Optional: Add more conditions to that same policy. In addition to receiving notifications, you can view the alert incident or event details in New Relic One. What's next? To learn more about using alerts: Read our best practices. Learn about the API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.19223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> concepts <em>and</em> workflow",
        "sections": "<em>Alerts</em> concepts <em>and</em> workflow",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": " URL, which is used to share standard procedures for how to handle <em>alert</em> <em>notifications</em>. Optional: Add more conditions to that same policy. In addition to receiving <em>notifications</em>, you can view the <em>alert</em> incident or event details in <em>New</em> <em>Relic</em> One. What&#x27;s next? To learn more about using <em>alerts</em>: Read our best practices. Learn about the API."
      },
      "id": "61305bef196a673eac4948d2"
    },
    {
      "sections": [
        "Define custom metrics for an alert condition",
        "Requirements for custom metrics",
        "Create a custom metric condition",
        "Tip",
        "View or update custom metric conditions",
        "Custom metric examples for alert notifications"
      ],
      "title": "Define custom metrics for an alert condition",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "New Relic Alerts",
        "Alert conditions"
      ],
      "external_id": "482f099e7b03c251b5165f3e647959db37788650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/define-custom-metrics-alert-condition/",
      "published_at": "2021-09-02T12:05:08Z",
      "updated_at": "2021-08-26T05:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To alert on custom metrics, follow standard procedures to add a condition to a policy. The condition's Thresholds section includes the option to select Custom > Search metric name, where you define your specific metric values. You can start typing the custom metric name or select from the list that automatically appears. Requirements for custom metrics Use the policy's Thresholds section to define the custom metric values. These include: The exact custom metric name for the selected product category and targets. Note: wildcard characters are not allowed. Selected threshold value function. The options are average, minimum, maximum, count, and rate. Selected threshold level. The options are above, below, and equal to. Critical (required) and Warning (optional) threshold value and duration that will open a violation. For example, 5 units for at least 5 minutes. Condition name (required) for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy) or add a new alert policy. From the policy's Alert conditions page, click Add a condition. From the Categorize section, select the product and type of condition for the custom metric. From the Select entities section, add one or more targets (entities) that use your custom metric. From the Define thresholds > When target application section, select Custom > Search metric name, and begin typing the custom metric name, select from the list, or type the exact metric name. Tip Exception: The custom metric search is not enabled for: Labels for New Relic APM apps New Relic Plugins To find the metric name in these situations, use the Data explorer. Then type the exact metric name in the Alerts Define thresholds page. Provide the required threshold values for your custom metric. From the Define thresholds > Condition name section, provide a meaningful name for your custom metric condition, maximum 100 characters. Optional: Include the URL with runbook instructions for handling the situation. Click Create condition. Repeat these steps as necessary to create additional conditions for custom metrics. View or update custom metric conditions After you save the condition, you can view the selected policy's Alert conditions page with a list of each condition. From here you can follow standard procedures to select and update the custom metric condition. The Condition name does not appear in the Thresholds section for a saved condition. If you want to change the condition name for a custom metric, edit it from the selected policy's Alert conditions page: In the one.newrelic.com top nav, click Alerts & AI, click Alert policies, then (select a policy). Click a condition name to edit it, and then type a meaningful name for the condition. Custom metric examples for alert notifications If you have created a plugin or custom dashboard for your custom metric, you can view your custom metric name there. For other ideas about how to apply custom metrics (for example, to alert on received and transmitted network stats), visit the New Relic Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.51108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Define custom metrics for an <em>alert</em> condition",
        "sections": "Custom metric examples for <em>alert</em> <em>notifications</em>",
        "tags": "<em>Alerts</em> <em>and</em> <em>Applied</em> <em>Intelligence</em>",
        "body": ") for the custom metric. Create a custom metric condition To define the custom metric values for your condition: In the one.newrelic.com top nav, click <em>Alerts</em> &amp; AI, click <em>Alert</em> policies, then (select a policy) or add a <em>new</em> <em>alert</em> policy. From the policy&#x27;s <em>Alert</em> conditions page, click Add a condition"
      },
      "id": "6130bdf428ccbceda556a826"
    }
  ]
}